{
  "name": "Updated_project_change_log",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// Process GitHub Tree API Response\nconst tree = $input.first().json.tree;\n\n// Filter for files only (not trees/directories)\nconst files = tree.filter(item => item.type === 'blob');\n\n// Transform to match the format expected by your workflow\nconst formattedFiles = files.map(file => ({\n  json: {\n    name: file.path.split('/').pop(),\n    path: file.path,\n    sha: file.sha,\n    size: file.size,\n    type: 'file',\n    download_url: `https://raw.githubusercontent.com/ShahzaibAli-1/Automation_Documentation_Project/main/${file.path}`\n  }\n}));\n\nreturn formattedFiles;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1040,
        544
      ],
      "id": "452e2d4c-22d6-4b07-9772-1e998f6a33d9",
      "name": "Process Tree Response"
    },
    {
      "parameters": {
        "jsCode": "// Get all items from GitHub API\nconst items = $input.all();\nconst documents = [];\n\n// Filter for document files\nfor (const item of items) {\n  if (item.json.type === 'file') {\n    const name = item.json.name;\n    const ext = name.split('.').pop().toLowerCase();\n    \n    // Check if it's a document type we support\n    if (['pdf', 'md', 'docx', 'txt'].includes(ext)) {\n      documents.push({\n        name: name,\n        path: item.json.path,\n        sha: item.json.sha,  // ‚Üê THIS WAS MISSING!\n        download_url: item.json.download_url,\n        type: ext,\n        size: item.json.size\n      });\n    }\n  }\n}\n\nreturn documents.map(doc => ({ json: doc }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -832,
        544
      ],
      "id": "a25df948-2981-43a3-9954-eab70348d49e",
      "name": "Filter_Documents1"
    },
    {
      "parameters": {
        "url": "={{ $json.download_url }}",
        "options": {
          "response": {
            "response": {}
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1552,
        48
      ],
      "id": "81978851-49b4-4384-ada5-bbad86775bdf",
      "name": "HTTP Request1"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        1568,
        288
      ],
      "id": "3ff62324-9394-4d72-af04-5cea1790ce6e",
      "name": "Loop Over Items1"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "name": "Replace Me1",
      "typeVersion": 1,
      "position": [
        1344,
        48
      ],
      "id": "8f7e3808-c2ed-4516-bdef-09bef59d20ed"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1792,
        400
      ],
      "id": "409330bc-492d-41dc-8623-21e83efaf54b",
      "name": "Embeddings OpenAI1",
      "credentials": {
        "openAiApi": {
          "id": "bhBOpGB6JIUeu4NX",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "metadata": {
            "metadataValues": [
              {
                "name": "File_Name",
                "value": "={{ $('Filter_Documents').item.json.download_url }}"
              }
            ]
          }
        }
      },
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [
        2064,
        416
      ],
      "id": "3ef0c7d5-0220-4292-aa1f-e8d1ade98bd9",
      "name": "Default Data Loader1"
    },
    {
      "parameters": {
        "mode": "insert",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "options": {
          "clearNamespace": "=false"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        1888,
        112
      ],
      "id": "d4e775aa-68b4-4b46-94b4-fcf7aa5d5b3e",
      "name": "Vector_Store_Insert1",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "ef60323d-7edf-4715-9624-50de217b5be5",
              "leftValue": "={{ $json.isFirstRun }}",
              "rightValue": "true",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -368,
        544
      ],
      "id": "65ebeb48-e0a2-4957-8aba-2d8267df8a58",
      "name": "Is_First_Run"
    },
    {
      "parameters": {
        "url": "https://api.github.com/repos/ShahzaibAli-1/Automation_Documentation_Project/git/trees/main?recursive=1",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1232,
        544
      ],
      "id": "656704fb-7e4f-4ace-a542-9243998cd563",
      "name": "Github Api GetTree"
    },
    {
      "parameters": {
        "jsCode": "const tree = $input.first().json.tree;\nconst repoInfo = $('Extract_Selected_Repo').first().json;\n\n// Filter for files only (not trees/directories)\nconst files = tree.filter(item => item.type === 'blob');\n\n// Transform to include dynamic repo info\nconst formattedFiles = files.map(file => ({\n  json: {\n    name: file.path.split('/').pop(),\n    path: file.path,\n    sha: file.sha,\n    size: file.size,\n    type: 'file',\n    download_url: `https://raw.githubusercontent.com/${repoInfo.repoFullName}/${repoInfo.branch}/${file.path}`,\n    repository: repoInfo.repoFullName,\n    owner: repoInfo.owner,\n    repoName: repoInfo.repoName\n  }\n}));\n\nreturn formattedFiles;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        960,
        288
      ],
      "id": "7845ec5f-6838-4706-9ea1-3e6f386b8956",
      "name": "Process Tree Response1"
    },
    {
      "parameters": {
        "jsCode": "// Get all items from GitHub API\nconst items = $input.all();\nconst documents = [];\n\n// Filter for document files\nfor (const item of items) {\n  if (item.json.type === 'file') {\n    const name = item.json.name;\n    const ext = name.split('.').pop().toLowerCase();\n    \n    // Check if it's a document type we support\n    if (['pdf', 'md', 'docx', 'txt'].includes(ext)) {\n      documents.push({\n        name: name,\n        path: item.json.path,\n        sha: item.json.sha,  // ‚Üê THIS WAS MISSING!\n        download_url: item.json.download_url,\n        type: ext,\n        size: item.json.size\n      });\n    }\n  }\n}\n\nreturn documents.map(doc => ({ json: doc }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1168,
        288
      ],
      "id": "3116b070-4635-416c-9836-823bc2592a0d",
      "name": "Filter_Documents"
    },
    {
      "parameters": {
        "jsCode": "const response = $input.first().json;\n\ntry {\n  if (response.content) {\n    const decoded = Buffer.from(response.content, 'base64').toString('utf-8');\n    const storedState = JSON.parse(decoded);\n    \n    return [{\n      json: {\n        stateExists: true,\n        storedState: storedState,\n        sha: response.sha\n      }\n    }];\n  }\n} catch (error) {\n  return [{\n    json: {\n      stateExists: false,\n      storedState: null\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        80,
        912
      ],
      "id": "8e5a1718-9e88-44c9-9f49-cdbc0977b4b9",
      "name": "Decode Stored State"
    },
    {
      "parameters": {
        "jsCode": "const currentDocs = $('Filter_Documents1').all();\nconst storedStateData = $input.first().json;\n\n// Build current files map\nconst currentFiles = {};\ncurrentDocs.forEach(doc => {\n  const data = doc.json;\n  currentFiles[data.path] = {\n    sha: data.sha,\n    name: data.name,\n    path: data.path,\n    download_url: data.download_url,\n    type: data.type,\n    size: data.size\n  };\n});\n\n// Get stored files\nconst storedFiles = storedStateData.storedState?.files || {};\n\nconst changedFiles = [];\nconst newFiles = [];\nconst deletedFiles = [];\n\nconsole.log('=== Change Detection ===');\nconsole.log(`Current files: ${Object.keys(currentFiles).length}`);\nconsole.log(`Stored files: ${Object.keys(storedFiles).length}`);\n\n// Find new and changed files\nfor (const [path, data] of Object.entries(currentFiles)) {\n  if (!storedFiles[path]) {\n    newFiles.push(data);\n    console.log(`üÜï NEW: ${path}`);\n  } else {\n    const currentSha = data.sha;\n    const storedSha = storedFiles[path].sha;\n    \n    if (currentSha !== storedSha) {\n      changedFiles.push(data);\n      console.log(`üîÑ CHANGED: ${path}`);\n    }\n  }\n}\n\n// Find deleted files\nfor (const [path, data] of Object.entries(storedFiles)) {\n  if (!currentFiles[path]) {\n    deletedFiles.push({ path, ...data });\n    console.log(`üóëÔ∏è DELETED: ${path}`);\n  }\n}\n\nconst filesToProcess = [...newFiles, ...changedFiles];\n\nconsole.log('\\n=== Summary ===');\nconsole.log(`New: ${newFiles.length}`);\nconsole.log(`Changed: ${changedFiles.length}`);\nconsole.log(`Deleted: ${deletedFiles.length}`);\nconsole.log(`To Process: ${filesToProcess.length}`);\n\nreturn [{\n  json: {\n    changesDetected: filesToProcess.length > 0 || deletedFiles.length > 0,\n    filesToProcess: filesToProcess,\n    deletedFiles: deletedFiles,\n    changedFiles: changedFiles,\n    newFiles: newFiles,\n    newFilesCount: newFiles.length,\n    changedFilesCount: changedFiles.length,\n    deletedFilesCount: deletedFiles.length,\n    totalChanges: filesToProcess.length + deletedFiles.length,\n    currentFilesState: currentFiles,\n    storedStateSha: storedStateData.sha\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        288,
        912
      ],
      "id": "e5c36470-473d-49c9-a1ec-dd2c3c63f2a5",
      "name": "Detect Changes"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "0c2244f7-584a-4d04-a0fb-61de39baf9c2",
              "leftValue": "={{ $json.changesDetected }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        480,
        912
      ],
      "id": "809e4193-7f74-489e-88af-9f3d41579725",
      "name": "If"
    },
    {
      "parameters": {
        "url": "https://api.github.com/repos/ShahzaibAli-1/Automation_Documentation_Project/contents/repo_state.json",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -192,
        896
      ],
      "id": "55c39136-dd0f-4329-b411-cd6f0c80db33",
      "name": "Get Stored State"
    },
    {
      "parameters": {
        "jsCode": "const data = $input.first().json;\n\n// Files to delete: changed files (will re-insert) + deleted files (remove permanently)\nconst filesToDelete = [\n  ...(data.changedFiles || []),\n  ...(data.deletedFiles || [])\n];\n\nconsole.log(`=== Deletion Preparation ===`);\nconsole.log(`Changed files to re-embed: ${data.changedFilesCount || 0}`);\nconsole.log(`Deleted files to remove: ${data.deletedFilesCount || 0}`);\nconsole.log(`Total vectors to delete: ${filesToDelete.length}`);\n\n// If nothing to delete, skip deletion entirely\nif (filesToDelete.length === 0) {\n  console.log('‚úÖ No deletions needed');\n  return [{\n    json: { \n      skipDeletion: true,\n      idsToDelete: [],\n      filesToProcess: data.filesToProcess || [],\n      storedStateSha: data.storedStateSha,\n      newFilesCount: data.newFilesCount,\n      changedFilesCount: data.changedFilesCount,\n      deletedFilesCount: data.deletedFilesCount\n    }\n  }];\n}\n\n// Generate Pinecone IDs for deletion\n// IMPORTANT: This format must match exactly what you use during insertion\nconst idsToDelete = filesToDelete.map(file => {\n  const sanitizedPath = file.path.replace(/[^a-zA-Z0-9]/g, '_');\n  const id = `doc_${sanitizedPath}`;\n  \n  const reason = data.deletedFiles.some(f => f.path === file.path) ? 'üóëÔ∏è DELETED' : 'üîÑ CHANGED';\n  console.log(`${reason}: ${file.path} ‚Üí ID: ${id}`);\n  \n  return id;\n});\n\nreturn [{\n  json: {\n    skipDeletion: false,\n    idsToDelete: idsToDelete,\n    deleteCount: idsToDelete.length,\n    filesToProcess: data.filesToProcess || [],\n    storedStateSha: data.storedStateSha,\n    deletionDetails: filesToDelete.map(f => ({\n      path: f.path,\n      name: f.name,\n      reason: data.deletedFiles.some(df => df.path === f.path) ? 'deleted' : 'changed'\n    }))\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        656,
        800
      ],
      "id": "1bff5dea-2fb8-42f9-b0b7-7a7ef32291ff",
      "name": "Prepare_Deletions"
    },
    {
      "parameters": {
        "jsCode": "const inputData = $input.first().json;\n\n// Get files that need new embeddings (new + changed files)\nconst filesToProcess = inputData.filesToProcess || [];\n\nconsole.log(`=== Preparing Files for Embedding ===`);\nconsole.log(`New files: ${inputData.newFilesCount || 0}`);\nconsole.log(`Changed files: ${inputData.changedFilesCount || 0}`);\nconsole.log(`Deleted files: ${inputData.deletedFilesCount || 0}`);\nconsole.log(`Total to process: ${filesToProcess.length}`);\n\nif (filesToProcess.length === 0) {\n  console.log('‚úÖ No files to process - only deletions occurred');\n  // Return a special flag to skip embedding steps\n  return [{\n    json: {\n      skipEmbedding: true,\n      onlyDeletions: true,\n      deletedCount: inputData.deletedFilesCount || 0,\n      storedStateSha: inputData.storedStateSha,\n      message: 'Only deletions detected - skipping embedding process'\n    }\n  }];\n}\n\n// Log each file\nfilesToProcess.forEach((file, idx) => {\n  console.log(`${idx + 1}. ${file.name} (${file.path})`);\n});\n\n// Return each file as separate item for loop processing\nreturn filesToProcess.map(file => ({ \n  json: {\n    name: file.name,\n    path: file.path,\n    sha: file.sha,\n    download_url: file.download_url,\n    type: file.type,\n    size: file.size,\n    storedStateSha: inputData.storedStateSha,\n    skipEmbedding: false\n  }\n}));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1104,
        720
      ],
      "id": "8fe4ea74-bcde-4c62-b450-a024fbe716df",
      "name": "Prepare_Updates"
    },
    {
      "parameters": {
        "content": "First Run Node",
        "height": 560,
        "width": 2912
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        0,
        0
      ],
      "typeVersion": 1,
      "id": "bc10e2af-94e3-401a-8e7e-769830618dcb",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "dbc4d349-7e15-497a-8eb0-9d4419890fe5",
              "leftValue": "={{ $json.skipDeletion }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        848,
        800
      ],
      "id": "049d04df-492a-44b6-91c5-92bc4614af8c",
      "name": "Skip Deletion"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        1632,
        928
      ],
      "id": "c6c2906a-d3eb-4f9f-8261-7b8db50fa9f7",
      "name": "Loop Over Items2"
    },
    {
      "parameters": {
        "url": "={{ $json.download_url }}",
        "options": {
          "response": {
            "response": {}
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1552,
        640
      ],
      "id": "5aceaa08-62fa-499b-a946-2998d0c11dc9",
      "name": "Download Files"
    },
    {
      "parameters": {
        "mode": "insert",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "options": {
          "clearNamespace": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        1824,
        704
      ],
      "id": "fdebe2ec-47b4-4b92-b001-6e15342f05b4",
      "name": "Pinecone Vector Store2",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1792,
        944
      ],
      "id": "2673f519-5d1e-4d61-b843-e83c12bd523f",
      "name": "Embeddings OpenAI2",
      "credentials": {
        "openAiApi": {
          "id": "bhBOpGB6JIUeu4NX",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [
        1968,
        960
      ],
      "id": "75738a9d-9dff-46bd-9b2e-9076316bd751",
      "name": "Default Data Loader"
    },
    {
      "parameters": {
        "jsCode": "// Get current files state from Filter_Documents1\nconst allDocs = $('Filter_Documents1').all();\n\nconst currentFilesState = {};\nallDocs.forEach(item => {\n  const doc = item.json;\n  currentFilesState[doc.path] = {\n    sha: doc.sha,\n    name: doc.name,\n    path: doc.path,\n    download_url: doc.download_url,\n    type: doc.type,\n    size: doc.size\n  };\n});\n\n// Get stored SHA for update (if exists)\nlet storedSha = null;\ntry {\n  storedSha = $('Decode Stored State2').first().json.sha;\n  console.log(`üìù Updating existing state (SHA: ${storedSha?.substring(0, 7)}...)`);\n} catch (error) {\n  console.log('üìù Creating new state file');\n}\n\n// Build repository state\nconst repositoryState = {\n  lastUpdated: new Date().toISOString(),\n  totalFiles: Object.keys(currentFilesState).length,\n  repository: \"ShahzaibAli-1/Automation_Documentation_Project\",\n  branch: \"main\",\n  files: currentFilesState\n};\n\nconsole.log(`üíæ State contains ${repositoryState.totalFiles} files`);\n\n// Encode to Base64\nconst stateJSON = JSON.stringify(repositoryState, null, 2);\nconst contentBase64 = Buffer.from(stateJSON, 'utf8').toString('base64');\n\n// Verify encoding\nconst verified = Buffer.from(contentBase64, 'base64').toString('utf8');\nif (verified !== stateJSON) {\n  throw new Error('Base64 encoding verification failed!');\n}\n\n// Prepare commit body\nconst body = {\n  message: `Update repo state: ${repositoryState.totalFiles} files tracked`,\n  content: contentBase64,\n  branch: \"main\"\n};\n\n// Only include SHA if updating existing file\nif (storedSha) {\n  body.sha = storedSha;\n}\n\nreturn [{ json: body }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2576,
        672
      ],
      "id": "83e43e57-5f18-415e-8379-4c67cd55bdae",
      "name": "Store_Repository_State1",
      "executeOnce": false
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=https://api.github.com/repos/{{ $('Extract_Selected_Repo').first().json.repoFullName }}/contents/repo_state.json",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "message",
              "value": "={{ $json[\"message\"] }}"
            },
            {
              "name": "content",
              "value": "={{ $json[\"content\"] }}"
            },
            {
              "name": "branch",
              "value": "={{ $json[\"branch\"] }}"
            },
            {
              "name": "sha",
              "value": "={{ $json[\"sha\"] }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2768,
        800
      ],
      "id": "85ede3d4-63cd-49aa-a650-f53c31ca0387",
      "name": "Commit State1"
    },
    {
      "parameters": {
        "jsCode": "const response = $input.first().json;\n\ntry {\n  if (response.content) {\n    const decoded = Buffer.from(response.content, 'base64').toString('utf-8');\n    const storedState = JSON.parse(decoded);\n    \n    console.log('üìñ Retrieved stored state successfully');\n    console.log(`Last updated: ${storedState.lastUpdated}`);\n    console.log(`Total files in state: ${storedState.totalFiles}`);\n    \n    return [{\n      json: {\n        stateExists: true,\n        storedState: storedState,\n        sha: response.sha\n      }\n    }];\n  }\n} catch (error) {\n  console.log('‚ö†Ô∏è No existing state found or decode failed');\n  return [{\n    json: {\n      stateExists: false,\n      storedState: null,\n      sha: null\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2384,
        672
      ],
      "id": "49de6387-80a1-4afd-ba63-f0e2af2c8329",
      "name": "Decode Stored State2"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $('Extract_Selected_Repo').first().json.repoFullName }}/contents/repo_state.json",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2176,
        672
      ],
      "id": "e1d89b52-6547-4e7a-ae1e-4cd10132d7e3",
      "name": "Get Stored State2"
    },
    {
      "parameters": {
        "content": "",
        "height": 544,
        "width": 2928,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        32,
        640
      ],
      "typeVersion": 1,
      "id": "a7ed778d-3bb9-40fb-8eaa-267c4d4e3877",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "Trigger Point and fetching Data From Github",
        "height": 288,
        "width": 1136
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1264,
        448
      ],
      "typeVersion": 1,
      "id": "31ce865b-820f-43ec-8b9d-c85cc3123369",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://github-docs-3musq7k.svc.aped-4627-b74a.pinecone.io/vectors/delete",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Api-Key",
              "value": "pcsk_7Kx2XR_KAELXMEtw7FSQv5RGv5rJDfzwzUEgsuYkZXb7eAktF4589YQ4Lx2c3GdPsegJTa"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"ids\": {{ JSON.stringify($json.idsToDelete) }},\n  \"namespace\": \"\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1216,
        928
      ],
      "id": "7e9d0a08-91ba-4877-8587-cbd39817adbf",
      "name": "Delete From Pinecorn"
    },
    {
      "parameters": {
        "jsCode": "const response = $input.first().json;\nconst preparationData = $('Prepare_Deletions').first().json;\n\nconsole.log('=== Deletion Response ===');\nconsole.log(JSON.stringify(response, null, 2));\n\n// Check for errors\nif (response.error || response.message?.includes('error')) {\n  console.error('‚ùå Deletion failed:', response);\n  throw new Error(`Pinecone deletion failed: ${JSON.stringify(response)}`);\n}\n\nconsole.log(`‚úÖ Successfully deleted ${preparationData.deleteCount} vectors from Pinecone`);\n\n// Check if there are files to process\nconst hasFilesToProcess = preparationData.filesToProcess && \n                           preparationData.filesToProcess.length > 0;\n\n// Pass through all necessary data for next steps\nreturn [{\n  json: {\n    deletionSuccess: true,\n    deletedCount: preparationData.deleteCount,\n    filesToProcess: preparationData.filesToProcess || [],\n    hasFilesToProcess: hasFilesToProcess,\n    storedStateSha: preparationData.storedStateSha,\n    message: hasFilesToProcess \n      ? `Deleted ${preparationData.deleteCount} embeddings, now processing ${preparationData.filesToProcess.length} files`\n      : `Deleted ${preparationData.deleteCount} embeddings, no files to process`\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        848,
        976
      ],
      "id": "0c5a067a-a66d-4140-af7e-373a1ea8bf53",
      "name": "Verify Deletions"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "399af74b-c995-4bba-89a5-10d2aad68c5c",
              "leftValue": "={{ $json.skipEmbedding }}",
              "rightValue": false,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1296,
        720
      ],
      "id": "dd8f7bc2-e15b-4695-bf9e-b059d4ce6975",
      "name": "If1"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "loose",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.message.voice.file_id}}",
                    "rightValue": "",
                    "operator": {
                      "type": "string",
                      "operation": "exists",
                      "singleValue": true
                    },
                    "id": "b50987fb-1785-4fc2-880f-56a1ae630659"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Audio"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "loose",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "6cf8a9ea-302c-4469-a832-52646d9e4987",
                    "leftValue": "={{ $json.message.text || \"\"}}",
                    "rightValue": "",
                    "operator": {
                      "type": "string",
                      "operation": "exists",
                      "singleValue": true
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "text"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "loose",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "5f488db9-5f16-4f4a-9667-5c9e99dea54b",
                    "leftValue": "={{ $json.callback_query !== undefined }}",
                    "rightValue": "true",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Call Back Query"
            }
          ]
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        -1920,
        544
      ],
      "id": "187974a9-31c8-4837-8e23-317809dbab4c",
      "name": "Switch1"
    },
    {
      "parameters": {
        "resource": "file",
        "fileId": "={{ $json.message.voice.file_id }}",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -1696,
        432
      ],
      "id": "9e1f3c78-bbcf-4b2d-a4a5-3bfee6f1c378",
      "name": "Get a file1",
      "webhookId": "be8dd212-fc7a-42f5-be8a-a1ba572c1a25",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "resource": "audio",
        "operation": "transcribe",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        -1424,
        432
      ],
      "id": "f7ee235e-f2d0-4872-a56b-0561fa1e064d",
      "name": "Transcribes Audio1",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "c3ca9784-1074-4daa-9b33-b35259ebc5a6",
              "name": "text",
              "value": "={{ $json.message.text || \"\"}}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1424,
        672
      ],
      "id": "0d14882b-9a20-44c0-bc7c-80f8bbd01a7e",
      "name": "Text Message1"
    },
    {
      "parameters": {
        "content": "Input Nodes",
        "height": 416,
        "width": 896,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2208,
        416
      ],
      "id": "f67952a5-0e35-4bf9-9c5c-32d4fe84023b",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "updates": [
          "message",
          "callback_query"
        ],
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegramTrigger",
      "typeVersion": 1.2,
      "position": [
        -2144,
        560
      ],
      "id": "ca0c3577-adf1-4212-856a-381d77648b64",
      "name": "Telegram Trigger1",
      "webhookId": "a04052f6-4cb2-4062-9f07-5594a992a91e",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Get the incoming message from Telegram or transcription\nconst telegramMessage = $('Telegram Trigger1').first().json.message.text || \n                       $('Transcribes Audio1').first().json.text || '';\n\n// Check if user says \"First Run\" (case insensitive)\nconst isFirstRun = telegramMessage.toLowerCase().includes('first run');\n\nreturn [{\n  json: {\n    isFirstRun: isFirstRun,\n    originalMessage: telegramMessage,\n    chatId: $('Telegram Trigger1').first().json.message.chat.id\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -608,
        544
      ],
      "id": "dd86c990-9a36-4e94-9b6f-bb5b29a4ae55",
      "name": "Check_First_Run_Text"
    },
    {
      "parameters": {
        "url": "https://api.github.com/user/repos",
        "authentication": "genericCredentialType",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "per_page",
              "value": "100"
            },
            {
              "name": "sort",
              "value": "updated"
            },
            {
              "name": "affiliation",
              "value": "owner"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        64,
        416
      ],
      "id": "c4736184-10da-4e41-bbf8-77250e426b52",
      "name": "Fetch_User_Repos"
    },
    {
      "parameters": {
        "jsCode": "// Get the input from Parse_Navigation_Callback\nconst inputData = $input.first().json;\n\nconsole.log('üì¶ Input data:', JSON.stringify(inputData, null, 2));\n\n// Check if this is coming from the new store_embeddings action\nlet callbackData;\nlet chatId;\nlet messageId;\n\nif (inputData.action === 'store_embeddings') {\n  // New flow: data is already parsed\n  console.log('‚úÖ Using store_embeddings action');\n  callbackData = inputData.callbackData;\n  chatId = inputData.chatId;\n  \n  // Try to get messageId from rawInput if available\n  if (inputData.rawInput && inputData.rawInput.callback_query) {\n    messageId = inputData.rawInput.callback_query.message.message_id;\n  }\n} else {\n  // Old flow: try to get from Telegram Trigger callback_query\n  console.log('‚ö†Ô∏è Trying legacy flow');\n  try {\n    const telegramData = $('Telegram Trigger1').first().json.callback_query;\n    callbackData = telegramData.data;\n    chatId = telegramData.message.chat.id;\n    messageId = telegramData.message.message_id;\n  } catch (error) {\n    throw new Error('Could not extract callback data. Input structure: ' + JSON.stringify(inputData));\n  }\n}\n\nconsole.log('üìù Callback data:', callbackData);\nconsole.log('üí¨ Chat ID:', chatId);\n\n// Extract repo info from callback_data (format: \"repo:owner/repo-name\")\nconst repoFullName = callbackData.replace('repo:', '');\nconst [owner, repoName] = repoFullName.split('/');\n\nconsole.log(`‚úÖ User selected repository: ${repoFullName}`);\n\nreturn [{\n  json: {\n    owner: owner,\n    repoName: repoName,\n    repoFullName: repoFullName,\n    chatId: chatId,\n    messageId: messageId,\n    branch: 'main' // Default branch, you can make this dynamic later\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        304,
        192
      ],
      "id": "3c6e960a-0b4b-49a9-a8cb-85e8f8ce0c66",
      "name": "Extract_Selected_Repo"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/git/trees/{{ $json.branch }}?recursive=1",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        768,
        288
      ],
      "id": "24c9cee6-aded-4450-a9e3-0d685130625f",
      "name": "Github_Api_GetTree_Dynamic"
    },
    {
      "parameters": {
        "jsCode": "// Use $input.all() to get all items from GitHub API\nconst allItems = $input.all();\n\nconsole.log('=== DEBUG: Repository Data ===');\nconsole.log('Total items received:', allItems.length);\n\n// Extract repos array from items\nlet repos = [];\n\n// The GitHub API returns multiple items, each containing a repo\nfor (let i = 0; i < allItems.length; i++) {\n  const item = allItems[i];\n  \n  // Each item should have a json property with repo data\n  if (item.json && item.json.full_name) {\n    repos.push(item.json);\n    console.log(`‚úÖ Item ${i}: Found repo ${item.json.name}`);\n  }\n}\n\nconsole.log(`‚úÖ Total repositories extracted: ${repos.length}`);\n\n// Validate we have repos\nif (repos.length === 0) {\n  console.error('‚ùå No repositories found in items');\n  console.error('Item structure:', JSON.stringify(allItems[0], null, 2).substring(0, 500));\n  throw new Error('No repositories found. Check console logs for details.');\n}\n\n// Get chat ID from Check_First_Run node\nlet chatId;\ntry {\n  chatId = $('Check_First_Run').first().json.chatId;\n  console.log('‚úÖ Got chatId from Check_First_Run:', chatId);\n} catch (e) {\n  try {\n    chatId = $('Telegram Trigger1').first().json.message.chat.id;\n    console.log('‚úÖ Got chatId from Telegram Trigger1:', chatId);\n  } catch (err) {\n    throw new Error('Could not find chat ID from previous nodes');\n  }\n}\n\n// Filter out forks (optional - remove if you want to include forks)\nconst userRepos = repos.filter(repo => {\n  return repo && \n         repo.full_name && \n         repo.name && \n         !repo.fork; // Remove this line to include forks\n});\n\nconsole.log(`üìä Filtered: ${userRepos.length} non-fork repos (excluded ${repos.length - userRepos.length} forks)`);\n\n// Handle no repositories\nif (userRepos.length === 0) {\n  return [{\n    json: {\n      chatId: chatId,\n      repositories: [],\n      totalRepos: 0,\n      keyboard: { \n        inline_keyboard: [[{\n          text: '‚ùå No repositories available',\n          callback_data: 'no_repos'\n        }]] \n      },\n      message: '‚ùå No repositories found.\\n\\nAll repositories might be forks.'\n    }\n  }];\n}\n\n// Create inline keyboard buttons (matching your PDF workflow pattern)\nconst buttons = [];\nconst maxRepos = Math.min(userRepos.length, 20);\n\nuserRepos.slice(0, maxRepos).forEach((repo, index) => {\n  const repoIndex = index + 1;\n  const hasFiles = repo.size > 0 ? 'üìÅ ' : 'üìÇ ';\n  const isPrivate = repo.private ? 'üîí ' : '';\n  \n  buttons.push([{\n    text: `${hasFiles}${isPrivate}${repo.name}`,\n    callback_data: `repo:${repo.full_name}`\n  }]);\n});\n\n// Add cancel button\nbuttons.push([\n  { text: \"‚ùå Cancel\", callback_data: \"cancel\" }\n]);\n\n// Format repository list for display\nconst repoList = userRepos.slice(0, maxRepos).map((repo, index) => {\n  return `${index + 1}. *${repo.name}*`;\n}).join('\\n');\n\n// Pagination note\nconst paginationNote = userRepos.length > 20 \n  ? `\\n\\n‚ö†Ô∏è Showing first 20 of ${userRepos.length} repositories` \n  : '';\n\n// Create message text\nconst messageText = `üîç *Found ${userRepos.length} repositories!*${paginationNote}\n\nüìö *Available Repositories:*\n\n${repoList}\n\nüí¨ *Select a repository to process its documentation*`;\n\nconsole.log(`‚úÖ Created ${buttons.length - 1} repository buttons (+ 1 cancel button)`);\n\n// Return formatted data for Telegram (matching your pattern)\nreturn [{\n  json: {\n    chatId: chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    }),\n    repositories: userRepos.slice(0, maxRepos),\n    totalRepos: userRepos.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        288,
        416
      ],
      "id": "932db1e8-00d2-4c49-8e47-975f06ec0625",
      "name": "Extract_Array"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.message.from.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            },
            {
              "name": "reply_markup",
              "value": "={{ JSON.parse($json.reply_markup) }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        560,
        416
      ],
      "id": "51e4ab77-fce8-497f-be1f-4897993034e7",
      "name": "Send a Reply Back"
    },
    {
      "parameters": {
        "content": "Brain Storming Agent",
        "height": 304,
        "width": 1072
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1184,
        1296
      ],
      "typeVersion": 1,
      "id": "c523e988-231a-4552-b640-2ba602019637",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Search through documents using semantic similarity. Returns top 15 most relevant document chunks.",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "topK": 15,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        1536,
        1504
      ],
      "id": "563b0b5d-1f5f-4cb6-857f-de122d2137e1",
      "name": "Pinecone Vector Store4",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1856,
        1488
      ],
      "id": "aaedae3e-ec6e-4fb0-9710-7c739a655258",
      "name": "Embeddings OpenAI4",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "Brain Storming Agent",
        "height": 384,
        "width": 1072,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1184,
        1632
      ],
      "typeVersion": 1,
      "id": "7c974bec-b6e8-469c-91e8-922762751b79",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Search through documents using semantic similarity. Returns top 15 most relevant document chunks.",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "topK": 15,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        1600,
        1856
      ],
      "id": "8ad921a8-809a-467d-b8d9-bc35ed23632a",
      "name": "Pinecone Vector Store6",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1824,
        1920
      ],
      "id": "b056e026-dbc4-467d-b2c1-5fa3b63d94a2",
      "name": "Embeddings OpenAI6",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a Q&A assistant with access to a document search tool.\n\n**Conversation History:**\n{{ $('Load Chat History').first().json.chatHistory || 'None' }}\n\n**User Question:** {{ $('Load Chat History').first().json.userMessage }}\n\n**Available Documents:**\n{{$('Filter_Documents1').all().map(d => `- ${d.json.name}`).join('\\n')}}\n\n**Instructions:**\n1. Use the search tool to find information in the documents\n2. When user mentions a specific file (like \"readme.txt\" or \"README.md\"), search for that file\n3. Extract the exact information requested (requirements, steps, versions, etc.)\n4. Format your answer clearly with bullet points or lists\n5. QA agent it Validates logic, consistency, and completeness.\n**Answer Format:**\nBased on the [filename], here are the [requirements/steps/information]:\n- Item 1\n- Item 2\n- Item 3\n\nAnswer the question now:",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1520,
        1664
      ],
      "id": "a7768cc7-4323-48d6-bc37-dbd8dfb7078c",
      "name": "QA Agent",
      "executeOnce": false
    },
    {
      "parameters": {
        "jsCode": "const chatId = $('Load Chat History').first().json.chatId;\nconst aiResponse = $input.first().json.output;\n\nconst staticData = $getWorkflowStaticData('global');\n\nif (!staticData.chatHistory) {\n  staticData.chatHistory = {};\n}\n\nif (!staticData.chatHistory[chatId]) {\n  staticData.chatHistory[chatId] = [];\n}\n\n// Save the actual AI response\nstaticData.chatHistory[chatId].push({\n  role: 'assistant',\n  content: aiResponse,\n  timestamp: new Date().toISOString()\n});\n\n// Keep only last 50 messages\nif (staticData.chatHistory[chatId].length > 50) {\n  staticData.chatHistory[chatId] = staticData.chatHistory[chatId].slice(-50);\n}\n\nreturn [{\n  json: {\n    response: aiResponse,\n    chatId: chatId\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1856,
        1312
      ],
      "id": "94694187-c3e1-48ab-8ed5-3110bbd00c05",
      "name": "Response Saver"
    },
    {
      "parameters": {
        "jsCode": "const chatId = $('Load Chat History').first().json.chatId;\nconst aiResponse = $input.first().json.output;\n\nconst staticData = $getWorkflowStaticData('global');\n\nif (!staticData.chatHistory) {\n  staticData.chatHistory = {};\n}\n\nif (!staticData.chatHistory[chatId]) {\n  staticData.chatHistory[chatId] = [];\n}\n\n// Save the actual AI response\nstaticData.chatHistory[chatId].push({\n  role: 'assistant',\n  content: aiResponse,\n  timestamp: new Date().toISOString()\n});\n\n// Keep only last 50 messages\nif (staticData.chatHistory[chatId].length > 50) {\n  staticData.chatHistory[chatId] = staticData.chatHistory[chatId].slice(-50);\n}\n\nreturn [{\n  json: {\n    response: aiResponse,\n    chatId: chatId\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1856,
        1664
      ],
      "id": "40af1a1d-0847-4b03-899b-167fbed6652e",
      "name": "Response Saver1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1504,
        1904
      ],
      "id": "d05e5a0d-adb0-45ea-a266-8d891fcc8454",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        160,
        1808
      ],
      "id": "1d522bbb-cd4b-4b2e-bd26-1bcfa26e4d31",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $('Q/A Mode Activation1').item.json.result.chat.id }}",
        "text": "={{ $json.response }}",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        2080,
        1664
      ],
      "id": "d96f20d0-3844-4ec1-a68e-dfa03af6aad0",
      "name": "QA Agent Response",
      "webhookId": "02c92cff-bb31-4632-b350-f6876fe428a9",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "={{ $json.response }}",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        2048,
        1312
      ],
      "id": "204d3329-d532-48a2-978b-e3e06d6e054d",
      "name": "Brain Storming Mode Activation1",
      "webhookId": "02c92cff-bb31-4632-b350-f6876fe428a9",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1424,
        1504
      ],
      "id": "d557a41d-ff2c-4330-b29a-05c666f0b596",
      "name": "OpenAI Chat Model2",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "= üß† *Brainstorming Mode Activated* \nI'll help you generate new ideas based on our documents!        ",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        1264,
        1360
      ],
      "id": "04538b46-db98-4085-a53d-70b20c9bd55f",
      "name": "Brain Storming Mode Activation2",
      "webhookId": "31ab1d91-3bcb-4802-af16-bdbfc7300f35",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "=‚ùì *Q/A Mode Activated*",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        1280,
        1680
      ],
      "id": "ccac83c9-88f2-43b7-9130-b19788f9ae5d",
      "name": "Q/A Mode Activation1",
      "webhookId": "4e0b5441-1c50-43a0-9473-ea2b81339dc2",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "BRAINSTORMING",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "50458522-38bd-47df-859b-3751bff7ef94"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Brain Storming"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "c0060c17-64dc-4771-a0d8-ba2c9bb719a2",
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "QA",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Question and Answer"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "09f0c17e-4d8d-4897-a502-564ea5bf335f",
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "DOCUMENT_GENERATION",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Document Generation"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "a384d717-5c40-4fb3-b4d1-16cb2d2f4be1",
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "CREATE_REPO_AND_DOCUMENT",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "CREATE REPO AND DOCUMENT"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "a8b564f0-3b18-4837-8b2e-2cfc2dbf1497",
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "FEEDBACKLOOP",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Feed Back Loop"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "87b387df-9cb6-4541-93ef-e3484f640ddd",
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "GITHUB_FILE_UPDATE",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "GITHUB FILE UPDATE"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "651a017e-e5d0-47c7-8956-cfa050f6df37",
                    "leftValue": "={{ $json.output }}",
                    "rightValue": "PROMPT_CONFIRMATION",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Prompt Update Confirmation"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        944,
        1728
      ],
      "id": "81caf096-4f3e-45f7-8064-be6b1fae7aa3",
      "name": "Switch"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a classification system. Your ONLY job is to output a single word.\n\n**Previous Conversation History:**\n{{ $('Load Chat History').first().json.chatHistory || 'No previous conversation' }}\n\n**Current User Message:** {{ $('Load Chat History').first().json.userMessage }} \n  \nClassify the user's intent into ONE category:\n\n- BRAINSTORMING: Generate new ideas, explore possibilities, creative thinking.\nIf user aks that I have an Idea to build someting it should proceed to Brainstorming Agent.\n- CREATE_REPO_AND_DOCUMENT: User wants to create a NEW GitHub repository and store documentation there. If user says I like the idea or I'm interested in this idea than switch to it or let's proceed further.\n- QA: Answer questions about documents or seek specific information  \n- DOCUMENT_GENERATION: Create new documents or write content \n\n\n- Prompt_Confirmation: User confirms and enters a prompt to update a GitHub repo. \n  Trigger this category if the message contains ANY of the following (case-insensitive):\n    - \"confirm prompt\"\n    - \"confirm\"\n    - \"confirm changes\"\n    - \"confirmed\"\n    - \"ok confirm\"\n    - \"yes confirm\"\n    - \"confirm and enter prompt\"\n    - OR any message that includes the word \"confirm\" anywhere in the text\n\n\n- GITHUB_FILE_UPDATE: User wants to update/modify a specific file in a GitHub repository \n  (keywords: \"update file in github\", \"modify github file\", \"change file in repository\", \n   \"edit github document\", \"modify\", \"change in github repo\")\n- FEEDBACKLOOP: User wants to make changes in an existing section when user asks to change it or make it better then change it \n\nCRITICAL RULES:\n1. Output ONLY one word: BRAINSTORMING, QA, DOCUMENT_GENERATION, CREATE_REPO_AND_DOCUMENT, \n   FEEDBACKLOOP, Prompt_Confirmation, or GITHUB_FILE_UPDATE\n2. No explanations\n3. No additional text\n4. No punctuation\n5. Just the category name in uppercase\n\nOutput:\n",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        256,
        1504
      ],
      "id": "97f6eddf-9ca6-45fe-863b-11822798da8c",
      "name": "AI Agent1",
      "executeOnce": true
    },
    {
      "parameters": {
        "jsCode": "try {\n  const chatId = $('Telegram Trigger1').first().json.message.chat.id.toString();\n  const userMessage = $('Telegram Trigger1').first().json.message.text || '';\n  // Safely obtain aiResponse (tolerant to undefined shapes)\n  const aiResponse = ($input && $input.first && $input.first().json && $input.first().json.output)\n    ? String($input.first().json.output).trim()\n    : '';\n\n  const staticData = $getWorkflowStaticData('global');\n\n  // Ensure container exists\n  if (!staticData.chatHistory) {\n    staticData.chatHistory = {};\n  }\n\n  // Normalize different possible stored shapes into an array named \"history\"\n  let history = staticData.chatHistory[chatId];\n\n  if (!history) {\n    // nothing stored yet -> initialize as array\n    history = [];\n    staticData.chatHistory[chatId] = history;\n  } else if (!Array.isArray(history)) {\n    // If stored as { messages: [...] } or similar, extract messages if present\n    if (history && typeof history === 'object' && Array.isArray(history.messages)) {\n      history = history.messages;\n      staticData.chatHistory[chatId] = history;\n    } else {\n      // Unknown shape -> overwrite with fresh array (to avoid future errors)\n      history = [];\n      staticData.chatHistory[chatId] = history;\n    }\n  }\n\n  // Append user message (only if non-empty)\n  if (userMessage !== '') {\n    history.push({\n      role: 'user',\n      content: userMessage,\n      timestamp: new Date().toISOString()\n    });\n  }\n\n  // Append assistant/classification result (only if non-empty)\n  if (aiResponse !== '') {\n    history.push({\n      role: 'assistant',\n      content: `[Classification: ${aiResponse}]`,\n      timestamp: new Date().toISOString()\n    });\n  }\n\n  // Trim to last 50 messages to avoid memory growth\n  if (history.length > 50) {\n    staticData.chatHistory[chatId] = history = history.slice(-50);\n  }\n\n  return [{\n    json: {\n      ok: true,\n      output: aiResponse,\n      chatId: chatId,\n      userMessage: userMessage,\n      storedMessages: history.length\n    }\n  }];\n\n} catch (err) {\n  // Return error info for debugging inside n8n\n  return [{\n    json: {\n      ok: false,\n      error: err.message,\n      stack: err.stack\n    }\n  }];\n}\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        608,
        1504
      ],
      "id": "ac8a583e-3223-48ae-8da2-63e7bc96ab2b",
      "name": "Save Chat Message1"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Search through documents using semantic similarity. Returns top 15 most relevant document chunks.",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "topK": 15,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        448,
        1792
      ],
      "id": "cf611bd5-1a76-42ab-992e-f14692744862",
      "name": "Pinecone Vector Store5",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        528,
        1984
      ],
      "id": "8e52224d-91db-486d-8eef-7048f64f1e3b",
      "name": "Embeddings OpenAI5",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "Continuing Toward AI Agent",
        "height": 1056,
        "width": 1200,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -80,
        1280
      ],
      "typeVersion": 1,
      "id": "8a30087b-baad-486d-8915-7ace78e7910b",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "jsCode": "const chatId = $('Telegram Trigger1').first().json.message.chat.id.toString();\nconst userMessage = $('Telegram Trigger1').first().json.message.text ?? $('Transcribes Audio1').first().json.text;\n\n// Supabase config - USE CREDENTIALS IN N8N INSTEAD\nconst SUPABASE_URL = 'YOUR_SUPABASE_URL_HERE';\nconst SUPABASE_KEY = 'YOUR_SUPABASE_KEY_HERE';\n\n\n// Fetch recent chat history (last 20 messages)\nlet chatHistory = [];\nlet formattedHistory = '';\n\ntry {\n  const response = await this.helpers.httpRequest({\n    method: 'GET',\n    url: `${SUPABASE_URL}/rest/v1/chat_messages?chat_id=eq.${chatId}&order=created_at.desc&limit=20`,\n    headers: {\n      'apikey': SUPABASE_KEY,\n      'Authorization': `Bearer ${SUPABASE_KEY}`,\n      'Content-Type': 'application/json'\n    }\n  });\n  \n  chatHistory = Array.isArray(response) ? response.reverse() : []; // Oldest first\n  \n  formattedHistory = chatHistory\n    .map(msg => `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}`)\n    .join('\\n');\n    \n  console.log(`‚úÖ Loaded ${chatHistory.length} messages for chat ${chatId}`);\n} catch (error) {\n  console.log('‚ö†Ô∏è Could not fetch chat history:', error.message);\n  // Continue with empty history rather than failing\n}\n\n// Store the new user message in database\ntry {\n  await this.helpers.httpRequest({\n    method: 'POST',\n    url: `${SUPABASE_URL}/rest/v1/chat_messages`,\n    headers: {\n      'apikey': SUPABASE_KEY,\n      'Authorization': `Bearer ${SUPABASE_KEY}`,\n      'Content-Type': 'application/json',\n      'Prefer': 'return=minimal'\n    },\n    body: {\n      chat_id: chatId,\n      role: 'user',\n      content: userMessage,\n      created_at: new Date().toISOString()\n    }\n  });\n  \n  console.log(`‚úÖ Stored user message for chat ${chatId}`);\n} catch (error) {\n  console.log('‚ùå Failed to store user message:', error.message);\n}\n\nreturn [{\n  json: {\n    chatId,\n    userMessage,\n    chatHistory: formattedHistory,\n    messageCount: chatHistory.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        272,
        1344
      ],
      "id": "8ad02463-87a3-4428-b370-d48d727bd4a5",
      "name": "Load Chat History"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        320,
        1744
      ],
      "id": "9cf122de-556b-481d-be45-b53222d738ee",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "content": "Repo Creation",
        "height": 336,
        "width": 1248,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -176,
        2384
      ],
      "typeVersion": 1,
      "id": "35737ae5-f2d4-4d91-a330-f61d4279580e",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "jsCode": "// Node: Extract_Repo_Details\nconst userMessage = $('Load Chat History').first().json.userMessage;\n\n// Extract repository name\nlet repoName = '';\nlet repoDescription = '';\n\n// Pattern matching for repo name\n\n  repoName = $input.first().json.choices[0].message.content.repo_name;\n\n// Extract description (everything after \"for\" or \"about\")\nconst descMatch = userMessage.match(/(?:for|about|regarding)\\s+(.+?)(?:\\.|$)/i);\nif (descMatch) {\n  repoDescription = descMatch[1].trim();\n} else {\n  repoDescription = `Documentation repository created from workflow`;\n}\n\nconsole.log('üì¶ Extracted repo details:', { repoName, repoDescription });\n\nreturn [{\n  json: {\n    repoName: repoName || `doc_repo_${Date.now()}`,\n    repoDescription: repoDescription,\n    repoOwner: 'codewithshahzaib', // Your GitHub username\n    userMessage: userMessage,\n    chatId: $('Load Chat History').first().json.chatId\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -128,
        2496
      ],
      "id": "4a32e6d7-80b2-47c8-90bd-81fb7ad78ebc",
      "name": "Extract Repository Details"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.github.com/user/repos",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"name\": \"{{ $json.repoName }}\",\n  \"description\": \"{{ $json.repoDescription }}\",\n  \"private\": false,\n  \"auto_init\": true\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        80,
        2496
      ],
      "id": "9aa4cdf6-8672-4a8b-a2f8-537b882417c8",
      "name": "Create GitHub Repository"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        288,
        2496
      ],
      "id": "faa496dc-5e1e-4cc3-bf87-0e548f40c2b4",
      "name": "Wait",
      "webhookId": "9661c8db-1f04-4807-bd25-15ae8e55a353"
    },
    {
      "parameters": {
        "jsCode": "// Node: Store_New_Repo_Info\nconst repoResponse = $input.first().json;\n\n// Safe extraction with error handling\nlet extractedDetails = {};\ntry {\n    const extractNode = $('Extract_Repo_Details');\n    if (extractNode && extractNode.first()) {\n        extractedDetails = extractNode.first().json || {};\n    }\n} catch (error) {\n    console.log('‚ö†Ô∏è Extract_Repo_Details node not available:', error.message);\n    extractedDetails = {};\n}\n\n// Get repository information with fallbacks\nconst repoOwner = repoResponse.owner?.login || extractedDetails.repoOwner || 'unknown-owner';\nconst repoName = repoResponse.name || 'unknown-repo';\nconst repoUrl = repoResponse.html_url || `https://github.com/${repoOwner}/${repoName}`;\nconst defaultBranch = repoResponse.default_branch || 'main';\n\nconsole.log('‚úÖ Repository created:', repoUrl);\n\n// Prepare GitHub config for document generation\nconst github = {\n  owner: repoOwner,\n  repo: repoName,\n  branch: defaultBranch,\n  basePath: 'Documentation_Sections',\n  repoUrl: repoUrl,\n  rawBaseUrl: `https://raw.githubusercontent.com/${repoOwner}/${repoName}/${defaultBranch}`,\n  isNewRepo: true\n};\n\nreturn [{\n  json: {\n    // Repository details\n    github: github,\n    repoCreated: true,\n    repoUrl: repoUrl,\n    \n    // User context with safe access\n    chatId: extractedDetails.chatId || $workflow.chatId, // fallback if available\n    userMessage: extractedDetails.userMessage || 'Documentation repository creation',\n    \n    // For notification\n    notificationMessage: `‚úÖ Repository \"${repoName}\" created successfully!\\nüì¶ URL: ${repoUrl}\\n\\nStarting documentation generation...`\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        496,
        2496
      ],
      "id": "2ccaee30-c0cc-40a6-9ffb-fd894d476829",
      "name": "Store_New_Repo_Info"
    },
    {
      "parameters": {
        "chatId": "={{ $('Telegram Trigger1').first().json.message.chat.id }}",
        "text": "={{ $json.notificationMessage }}",
        "additionalFields": {
          "appendAttribution": false
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        720,
        2496
      ],
      "id": "bbad7473-b00c-4903-aac8-ed345731fc28",
      "name": "Send a text message2",
      "webhookId": "f488186c-fac7-4e7a-99ca-7ea7f837b17b",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "GPT-4.1-MINI"
        },
        "messages": {
          "values": [
            {
              "content": "=Create a very unique Repo Name for Github based on user Entered Prompt and give a single word as ouptut of repo\ncreate a one liner description also \nThe user entered message is given below:\n{{ $('Telegram Trigger1').first().json.message.text }}",
              "role": "assistant"
            }
          ]
        },
        "simplify": false,
        "jsonOutput": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        240,
        2176
      ],
      "id": "26ae76fd-7f1e-49f3-8774-ab1b9c207eb6",
      "name": "Create a Repo Name",
      "credentials": {
        "openAiApi": {
          "id": "bhBOpGB6JIUeu4NX",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a creative brainstorming assistant with access to documents.\n\n**Chat History:**\n{{ $('Load Chat History').first().json.chatHistory }}\n\n**User Request:** {{ $('Load Chat History').first().json.userMessage }}\n|| \n**Available Documents:**\n{{$('Filter_Documents1').all().map(d => `- ${d.json.name}`).join('\\n')}}\n\nUse the document search tool to find relevant information, then generate creative ideas based on:\n1. Information from the documents\n2. The conversation context\n3. Your own creative thinking\n\nProvide innovative ideas, suggestions, or approaches related to the user's request.",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1504,
        1312
      ],
      "id": "652a2cdc-8862-43da-8874-8d51db1b14f2",
      "name": "Brainstorming Agent",
      "executeOnce": false
    },
    {
      "parameters": {
        "jsCode": "// Detect if user wants to edit an existing document\nconst userMessage = $input.first().json.userMessage || '';\nconst output = $input.first().json.output || '';\n\n// Check if this is an edit request\nconst isEditRequest = \n  userMessage.toLowerCase().includes('edit document') ||\n  userMessage.toLowerCase().includes('modify document') ||\n  userMessage.toLowerCase().includes('change document') ||\n  userMessage.toLowerCase().includes('update document') ||\n  output === 'FEEDBACKLOOP';\n\nreturn [{\n  json: {\n    ...($input.first().json),\n    isEditRequest: isEditRequest,\n    editDetected: isEditRequest\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        816,
        1328
      ],
      "id": "32f9181d-8185-46f4-a4b7-0694813ba575",
      "name": "Detect_Edit_Request"
    },
    {
      "parameters": {
        "url": "https://api.github.com/user/repos",
        "authentication": "genericCredentialType",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "per_page",
              "value": "100"
            },
            {
              "name": "sort",
              "value": "updated"
            },
            {
              "name": "affiliation",
              "value": "owner"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4608,
        320
      ],
      "id": "f82d7fd2-dc28-4d55-8be2-624155a63616",
      "name": "Show_User_Repos"
    },
    {
      "parameters": {
        "jsCode": "// Use $input.all() to get all items from GitHub API\nconst allItems = $input.all();\n\nconsole.log('=== DEBUG: Repository Data ===');\nconsole.log('Total items received:', allItems.length);\n\n// Extract repos array from items\nlet repos = [];\n\n// The GitHub API returns multiple items, each containing a repo\nfor (let i = 0; i < allItems.length; i++) {\n  const item = allItems[i];\n  \n  // Each item should have a json property with repo data\n  if (item.json && item.json.full_name) {\n    repos.push(item.json);\n    console.log(`‚úÖ Item ${i}: Found repo ${item.json.name}`);\n  }\n}\n\nconsole.log(`‚úÖ Total repositories extracted: ${repos.length}`);\n\n// Validate we have repos\nif (repos.length === 0) {\n  console.error('‚ùå No repositories found in items');\n  console.error('Item structure:', JSON.stringify(allItems[0], null, 2).substring(0, 500));\n  throw new Error('No repositories found. Check console logs for details.');\n}\n\n// Get chat ID from Check_First_Run node\nlet chatId;\ntry {\n  chatId = $('Check_First_Run').first().json.chatId;\n  console.log('‚úÖ Got chatId from Check_First_Run:', chatId);\n} catch (e) {\n  try {\n    chatId = $('Telegram Trigger1').first().json.message.chat.id;\n    console.log('‚úÖ Got chatId from Telegram Trigger1:', chatId);\n  } catch (err) {\n    throw new Error('Could not find chat ID from previous nodes');\n  }\n}\n\n// Filter out forks (optional - remove if you want to include forks)\nconst userRepos = repos.filter(repo => {\n  return repo && \n         repo.full_name && \n         repo.name && \n         !repo.fork; // Remove this line to include forks\n});\n\nconsole.log(`üìä Filtered: ${userRepos.length} non-fork repos (excluded ${repos.length - userRepos.length} forks)`);\n\n// Handle no repositories\nif (userRepos.length === 0) {\n  return [{\n    json: {\n      chatId: chatId,\n      repositories: [],\n      totalRepos: 0,\n      keyboard: { \n        inline_keyboard: [[{\n          text: '‚ùå No repositories available',\n          callback_data: 'no_repos'\n        }]] \n      },\n      message: '‚ùå No repositories found.\\n\\nAll repositories might be forks.'\n    }\n  }];\n}\n\n// Create inline keyboard buttons (matching your PDF workflow pattern)\nconst buttons = [];\nconst maxRepos = Math.min(userRepos.length, 20);\n\nuserRepos.slice(0, maxRepos).forEach((repo, index) => {\n  const repoIndex = index + 1;\n  const hasFiles = repo.size > 0 ? 'üìÅ ' : 'üìÇ ';\n  const isPrivate = repo.private ? 'üîí ' : '';\n  \n  buttons.push([{\n    text: `${hasFiles}${isPrivate}${repo.name}`,\n    callback_data: `repo:${repo.full_name}`\n  }]);\n});\n\n// Add cancel button\nbuttons.push([\n  { text: \"‚ùå Cancel\", callback_data: \"cancel\" }\n]);\n\n// Format repository list for display\nconst repoList = userRepos.slice(0, maxRepos).map((repo, index) => {\n  return `${index + 1}. *${repo.name}*`;\n}).join('\\n');\n\n// Pagination note\nconst paginationNote = userRepos.length > 20 \n  ? `\\n\\n‚ö†Ô∏è Showing first 20 of ${userRepos.length} repositories` \n  : '';\n\n// Create message text\nconst messageText = `üîç *Found ${userRepos.length} repositories!*${paginationNote}\n\nüìö *Available Repositories:*\n\n${repoList}\n\nüí¨ *Select a repository to process its documentation*`;\n\nconsole.log(`‚úÖ Created ${buttons.length - 1} repository buttons (+ 1 cancel button)`);\n\n// Return formatted data for Telegram (matching your pattern)\nreturn [{\n  json: {\n    chatId: chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    }),\n    repositories: userRepos.slice(0, maxRepos),\n    totalRepos: userRepos.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4800,
        320
      ],
      "id": "3f884e47-21c1-444d-9101-d8af8cb383ae",
      "name": "Format_Repo_List_For_Telegram"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.message.from.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            },
            {
              "name": "reply_markup",
              "value": "={{ JSON.parse($json.reply_markup) }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        5056,
        320
      ],
      "id": "fa2cce95-0939-427d-b04c-041ffd2b48d5",
      "name": "Send_Repo_Selection_Message"
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callback_query.data;\nconst chatId = $input.first().json.callback_query.message.chat.id;\n\n// Check if this is a cancel action\nif (callbackData === 'cancel_edit') {\n  return [{\n    json: {\n      cancelled: true,\n      chatId: chatId,\n      message: \"‚ùå Edit cancelled\"\n    }\n  }];\n}\n\n// Extract repo info (format: \"edit_repo:owner/repo-name\")\nconst repoFullName = callbackData.replace('edit_repo:', '');\nconst [owner, repoName] = repoFullName.split('/');\n\nconsole.log(`üì¶ User selected repository: ${repoFullName}`);\n\nreturn [{\n  json: {\n    owner: owner,\n    repoName: repoName,\n    repoFullName: repoFullName,\n    chatId: chatId,\n    branch: 'main',\n    cancelled: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4032,
        320
      ],
      "id": "6030efa2-3115-4e82-bea1-bbb5b77d951c",
      "name": "Extract_Selected_Repo_For_Edit"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.owner }}/{{ $json.repoName }}/contents",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4272,
        320
      ],
      "id": "267ccb3b-7577-47d1-9919-428caa4ff7ef",
      "name": "List_Folders_In_Repo"
    },
    {
      "parameters": {
        "content": "Update Using Github File",
        "height": 688,
        "width": 1184,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2416,
        1232
      ],
      "typeVersion": 1,
      "id": "effed0f3-ff9a-4d47-bfbc-9d831606811a",
      "name": "Sticky Note12"
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "=üîß *GitHub File Update Mode Activated*\nI'll help you update a file in your GitHub repository.\nSend Complete deatils of updates.\nPlease enter \"confirm prompt\" while sending the message.",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "Markdown"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        2800,
        1424
      ],
      "id": "df09cae9-c8b2-4bda-880a-b93387865616",
      "name": "GitHub_Update_Mode_Activation",
      "webhookId": "a18ebd1c-887e-4ac2-bb68-a7824e1a3b90",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "url": "https://api.github.com/user/repos",
        "authentication": "genericCredentialType",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "per_page",
              "value": "100"
            },
            {
              "name": "sort",
              "value": "updated"
            },
            {
              "name": "affiliation",
              "value": "owner"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2784,
        1760
      ],
      "id": "26bd00ac-792a-4e62-9448-00cfc0dd0304",
      "name": "Fetch_User_Repos_For_Update"
    },
    {
      "parameters": {
        "jsCode": "const allItems = $input.all();\nconst chatId = $('Load Chat History').first().json.chatId;\n\n\nconst staticData = $getWorkflowStaticData('global');\n\n\n// Extract repos\nlet repos = [];\nfor (let i = 0; i < allItems.length; i++) {\n  const item = allItems[i];\n  if (item.json && item.json.full_name) {\n    repos.push(item.json);\n  }\n}\n\n// Filter out forks\nconst userRepos = repos.filter(repo => !repo.fork);\n\n\nif (userRepos.length === 0) {\n  return [{\n    json: {\n      chatId: chatId,\n      repositories: [],\n      keyboard: { \n        inline_keyboard: [[{\n          text: '‚ùå No repositories available',\n          callback_data: 'no_repos'\n        }]] \n      },\n      message: '‚ùå No repositories found for file updates.'\n    }\n  }];\n}\n\nconst userPrompt = $('Store_Update_Prompt').first().json.userPrompt;\nconsole.log('üì¶ Formatting repositories for file update...');\n\nconst messageText = userPrompt \n  ? `‚úÖ *Prompt Saved Successfully!*\n\nüìù *Your Update Instructions:*\n_\"${userPrompt}\"_\n\nüìÅ *Select Repository to Update*\n\nFound ${userRepos.length} repositories. Select one to browse its files:\n\n‚öôÔ∏è *Next Step:* After selecting a repo, you'll see its folders and files.`\n  : `üìÅ *Select Repository to Update*\n\nFound ${userRepos.length} repositories. Select one to browse its files:\n\n‚öôÔ∏è *Next Step:* After selecting a repo, you'll see its folders and files.`;\n\n// Create buttons (max 20)\nconst buttons = [];\nconst maxRepos = Math.min(userRepos.length, 20);\n\nuserRepos.slice(0, maxRepos).forEach((repo, index) => {\n  const hasFiles = repo.size > 0 ? 'üìÑ ' : 'üìÇ ';\n  const isPrivate = repo.private ? 'üîí ' : '';\n  \n  buttons.push([{\n    text: `${hasFiles}${isPrivate}${repo.name}`,\n    callback_data: `fileupdate:repo:${repo.full_name}`\n  }]);\n});\n\n// Add cancel button\nbuttons.push([\n  { text: \"‚ùå Cancel\", callback_data: \"cancel_fileupdate\" }\n]);\n\n// const messageText = `üìÅ *Select Repository to Update*\n\n// Found ${userRepos.length} repositories. Select one to browse its files:\n\n// ‚öôÔ∏è *Next Step:* After selecting a repo, you'll see its folders and files.`;\n\n\n\nreturn [{\n  json: {\n    chatId: chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    }),\n    repositories: userRepos.slice(0, maxRepos),\n    totalRepos: userRepos.length,\n    updateMode: 'github_file',\n    userPrompt: userPrompt  // ADD THIS\n\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3040,
        1760
      ],
      "id": "5ce35717-073b-43c3-a5a6-106144d6821d",
      "name": "Format_Repo_List_For_Update"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.message.from.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            },
            {
              "name": "reply_markup",
              "value": "={{ JSON.parse($json.reply_markup) }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3280,
        1760
      ],
      "id": "148cee7d-ddaa-40b7-9e1c-283cb434ea7e",
      "name": "Send_Repo_Selection_Message_1"
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callback_query.data;\nconst chatId = $input.first().json.callback_query.message.chat.id;\n\nconsole.log('üéØ Processing repo selection:', callbackData);\n\n// Extract repo info (format: \"fileupdate:repo:owner/repo-name\")\nif (!callbackData.startsWith('fileupdate:repo:')) {\n  throw new Error('Invalid callback format');\n}\n\nconst repoFullName = callbackData.replace('fileupdate:repo:', '');\nconst [owner, repoName] = repoFullName.split('/');\n\nconsole.log(`‚úÖ Selected: ${repoFullName}`);\n\nreturn [{\n  json: {\n    owner: owner,\n    repoName: repoName,\n    repoFullName: repoFullName,\n    chatId: chatId,\n    branch: 'main',\n    updateMode: 'github_file'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4576,
        1104
      ],
      "id": "b6a1b784-9978-44e8-8c6f-6f8593f1bec4",
      "name": "Extract_Selected_Repo_For_Update"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4752,
        1088
      ],
      "id": "7a9f343b-cc3e-49c3-ba29-2e01ab295237",
      "name": "HTTP Request"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/git/trees/{{ $json.branch }}?recursive=1",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4400,
        784
      ],
      "id": "e074207c-569f-4b90-9b7f-6f096d3521f1",
      "name": "Github_Api_GetTree_Dynamic1"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4640,
        880
      ],
      "id": "6b51c590-1d25-4c1b-923e-d58490260675",
      "name": "Get Repo Structure"
    },
    {
      "parameters": {
        "jsCode": "// Get the tree data\nconst treeData = $input.first().json;\nconst tree = treeData.tree || [];\n\n// Get chat and repo info from Parse Repo Selection\nconst repoData = $('Parse Repo Selection').first().json;\n\nconst chatId = repoData.chatId;\nconst repoName = repoData.repoName;\nconst owner = repoData.owner;\nconst fileName = repoData.fileName;\nconst fileId = repoData.fileId;\nconst extractedText = repoData.extractedText || '';\n\n// Filter only directories (type: \"tree\")\nconst directories = tree\n  .filter(item => item.type === 'tree')\n  .map(item => item.path);\n\ndirectories.unshift('/');\n\n// Create buttons with SHORT callback_data (just index)\nconst buttons = directories.slice(0, 10).map((dir, index) => [{\n  text: dir === '/' ? 'üìÅ Root Directory' : `üìÅ ${dir}`,\n  callback_data: `dir_${index}`\n}]);\n\nif (directories.length > 10) {\n  buttons.push([{\n    text: `üìã Show All (${directories.length} directories)`,\n    callback_data: 'show_all_dirs'\n  }]);\n}\n\nbuttons.push([\n  { text: \"‚¨ÖÔ∏è Back to Repos\", callback_data: \"back_to_repos\" },\n  { text: \"‚ùå Cancel\", callback_data: \"cancel\" }\n]);\n\nconst dirList = directories.slice(0, 15).map((dir, index) => \n  `${index + 1}. \\`${dir === '/' ? '/' : dir}\\``\n).join('\\n');\n\n// Include file_id AND filename in the message text\nconst messageText = `üìÑ *${fileName}*\n\nüìÇ *Repository: ${owner}/${repoName}*\n\nüóÇÔ∏è *Select Upload Location:*\n\n${dirList}${directories.length > 15 ? `\\n\\n... and ${directories.length - 15} more directories` : ''}\n\nüí¨ Click a button for required directory \n\n\\`FILE_ID:${fileId}\\``;\n\nreturn [{\n  json: {\n    chatId: chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    }),\n    directories: directories,\n    repoName: repoName,\n    owner: owner,\n    fileName: fileName,\n    fileId: fileId,\n    extractedText: extractedText\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4864,
        880
      ],
      "id": "a0eebdc5-fcca-4ffa-a168-0d1552564e9d",
      "name": "Format Directory Structure"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger').item.json.callback_query.message.chat.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            },
            {
              "name": "reply_markup",
              "value": "={{ JSON.parse($json.reply_markup) }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        5136,
        880
      ],
      "id": "f23f1dde-af74-4492-87be-fb3621b78249",
      "name": "Send a Reply Back1"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4128,
        112
      ],
      "id": "a1ee1cd4-98d2-4245-a6fb-7c46db3fc78a",
      "name": "Fetch_Repo_Contents"
    },
    {
      "parameters": {
        "jsCode": "const contents = $input.all();\nconst repoInfo = $('Extract_Selected_Repo_For_Update1').first().json;\n\nconsole.log('üìÇ Formatting files and folders...');\n\n// Separate folders and files\nconst folders = [];\nconst files = [];\n\nfor (const item of contents) {\n  const data = item.json;\n  \n  if (data.type === 'dir') {\n    folders.push(data);\n  } else if (data.type === 'file') {\n    // Only show text-based files\n    const fileName = data.name.toLowerCase();\n    if (fileName.endsWith('.md') || \n        fileName.endsWith('.txt') || \n        fileName.endsWith('.json') ||\n        fileName.endsWith('.js') ||\n        fileName.endsWith('.py')) {\n      files.push(data);\n    }\n  }\n}\n\nconsole.log(`üìä Found ${folders.length} folders, ${files.length} files`);\n\n// Create buttons with index-based callback\nconst buttons = [];\nlet itemIndex = 0;\n\n// Add folders first\nfolders.forEach(folder => {\n  buttons.push([{\n    text: `üìÅ ${folder.name}`,\n    callback_data: `fud:${itemIndex++}`\n  }]);\n});\n\n// Add files\nfiles.forEach(file => {\n  const icon = file.name.endsWith('.md') ? 'üìù' : \n               file.name.endsWith('.json') ? 'üìã' : 'üìÑ';\n  buttons.push([{\n    text: `${icon} ${file.name}`,\n    callback_data: `fuf:${itemIndex++}`\n  }]);\n});\n\n// Add back/cancel buttons\nbuttons.push([\n  { text: \"üîô Back to Repos\", callback_data: \"fileupdate:back\" },\n  { text: \"‚ùå Cancel\", callback_data: \"cancel_fileupdate\" }\n]);\n\n// Create item mapping as JSON string to embed in message\nconst allItems = [...folders, ...files];\nconst itemsData = allItems.map(item => ({\n  name: item.name,\n  path: item.path,\n  type: item.type\n}));\n\n// Encode repo and items data as base64 to hide in message\nconst hiddenData = Buffer.from(JSON.stringify({\n  repo: repoInfo.repoFullName,\n  items: itemsData\n})).toString('base64');\n\nconst messageText = `üìÇ *Contents of ${repoInfo.repoName}*\n\nSelect a folder to browse or a file to update:\n\nüìÅ Folders: ${folders.length}\nüìÑ Editable Files: ${files.length}\n\n‚ö†Ô∏è Only text-based files (.md, .txt, .json, etc.) are shown.\n\n\\`${hiddenData}\\``;\n\nreturn [{\n  json: {\n    chatId: repoInfo.chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    })\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4336,
        112
      ],
      "id": "72f336c1-123c-4333-871d-f0d57ae8588e",
      "name": "Format_File_Folder_List"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.callback_query.message.chat.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            },
            {
              "name": "reply_markup",
              "value": "={{ $json.reply_markup }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4544,
        112
      ],
      "id": "753aecb4-1588-4c1c-916c-8904a3029025",
      "name": "Send_File_Selection_Message"
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callback_query.data;\nconst messageText = $input.first().json.callback_query.message.text;\nconst chatId = $input.first().json.callback_query.message.chat.id;\n\nconsole.log('üìÑ Processing file/folder selection:', callbackData);\n\n// Extract hidden data from message (it's in backticks at the end)\nconst hiddenDataMatch = messageText.match(/`([A-Za-z0-9+/=]+)`/);\nif (!hiddenDataMatch) {\n  throw new Error('Could not find hidden data in message');\n}\n\nconst hiddenData = JSON.parse(Buffer.from(hiddenDataMatch[1], 'base64').toString('utf-8'));\nconst repoFullName = hiddenData.repo;\nconst items = hiddenData.items;\n\nconsole.log(`üì¶ Repo: ${repoFullName}`);\nconsole.log(`üìã Items count: ${items.length}`);\n\n// Parse the callback data\nif (callbackData.startsWith('fud:') || callbackData.startsWith('fuf:')) {\n  const type = callbackData.startsWith('fud:') ? 'dir' : 'file';\n  const index = parseInt(callbackData.split(':')[1]);\n  \n  const item = items[index];\n  \n  if (!item) {\n    throw new Error(`Item at index ${index} not found`);\n  }\n  \n  console.log(`‚úÖ Selected: ${item.name} (${item.path})`);\n  \n  if (type === 'dir') {\n    // User clicked a folder - fetch its contents\n    return [{\n      json: {\n        action: 'browse_folder',\n        repoFullName: repoFullName,\n        folderPath: item.path,\n        chatId: chatId,\n        needsFolderContents: true\n      }\n    }];\n  } else {\n    // User clicked a file - prepare to fetch and update it\n    return [{\n      json: {\n        action: 'update_file',\n        repoFullName: repoFullName,\n        filePath: item.path,\n        chatId: chatId,\n        needsFileContents: true\n      }\n    }];\n  }\n}\n\n// Handle back/cancel buttons\nif (callbackData === 'fileupdate:back' || callbackData === 'cancel_fileupdate') {\n  return [{\n    json: {\n      action: callbackData,\n      chatId: chatId\n    }\n  }];\n}\n\nthrow new Error('Invalid callback data format');"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3904,
        608
      ],
      "id": "ef9bc7c6-0ed7-4106-8488-eb7b911dc67d",
      "name": "Handle_File_Selection"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents/{{ $json.filePath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4160,
        608
      ],
      "id": "59fd583a-4ef1-41d0-aa9e-ef647f9567f8",
      "name": "Fetch_File_Contents"
    },
    {
      "parameters": {
        "jsCode": "const fileResponse = $input.first().json;\nconst selectionData = $('Handle_File_Selection').first().json;\nconst userMessage = $('Telegram Trigger1').first().json.message.text;\n\nconsole.log('üîì Decoding file contents...');\n\n// Decode base64 content\nconst decodedContent = Buffer.from(fileResponse.content, 'base64').toString('utf-8');\n\nconsole.log(`üìÑ File size: ${decodedContent.length} characters`);\nconsole.log(`üîë SHA: ${fileResponse.sha}`);\n\n// Extract user's update instruction\nconst updateInstruction = userMessage.replace(/update.*?in github/i, '').trim();\n\nreturn [{\n  json: {\n    repoFullName: selectionData.repoFullName,\n    filePath: selectionData.filePath,\n    fileName: fileResponse.name,\n    currentContent: decodedContent,\n    fileSha: fileResponse.sha, // CRITICAL for updating\n    chatId: selectionData.chatId,\n    updateInstruction: updateInstruction,\n    originalUserMessage: userMessage,\n    fileUrl: fileResponse.html_url,\n    downloadUrl: fileResponse.download_url\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4368,
        608
      ],
      "id": "1a8573b9-f3df-4a07-a276-e50e7d05b196",
      "name": "Decode_File_And_Prepare_Update"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=`You are a Senior Software Engineer tasked with updating a file in a GitHub repository.\n\n**File Information:**\n- Repository: {{ $json.repoFullName }}\n- File Path: {{ $json.filePath }}\n- File Name: {{ $json.fileName }}\n\n**Current File Content:**\n{{ $json.currentContent }}\n\n\n**User's Update Request:**\n{{ $json.updateInstruction }}\n\n**Original Message:**\n{{ $json.originalUserMessage }}\n\n**YOUR TASK:**\n1. Analyze the current file content carefully\n2. Understand what changes the user wants\n3. Apply the requested changes precisely\n4. Maintain code quality, formatting, and style\n5. Return the COMPLETE updated file content\n\n**OUTPUT FORMAT:**\nReturn a JSON object with this structure:\n\n{\n  \"updatedContent\": \"... complete updated file content here ...\",\n  \"changesSummary\": \"Brief bullet-point list of what was changed\",\n  \"linesChanged\": 5\n}\n\n\n**CRITICAL RULES:**\n- Return the ENTIRE file content, not just the changed parts\n- Preserve all formatting, indentation, and code style\n- Do NOT add any markdown code fences to the content itself\n- Do NOT truncate or summarize the file\n- Be precise with the changes requested",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        4576,
        608
      ],
      "id": "46547de2-70ce-48c8-ab2f-74790a734f8e",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4576,
        816
      ],
      "id": "13726aa8-c0b4-47cb-b739-bb7e7481db21",
      "name": "OpenAI Chat Model6",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $('Decode_File_And_Prepare_Update').first().json.repoFullName }}/contents/{{ $('Decode_File_And_Prepare_Update').first().json.filePath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "message",
              "value": "=Update {{ $('Decode_File_And_Prepare_Update').first().json.fileName }} via n8n workflow"
            },
            {
              "name": "content",
              "value": "={{ Buffer.from($json.output.updatedContent).toString('base64') }}"
            },
            {
              "name": "sha",
              "value": "={{ $('Decode_File_And_Prepare_Update').first().json.fileSha }}"
            },
            {
              "name": "branch",
              "value": "main"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4864,
        592
      ],
      "id": "3ad0d07f-77d5-4a0f-b8e1-f25f2e3ead47",
      "name": "Commit_Updated_File_To_GitHub"
    },
    {
      "parameters": {
        "chatId": "={{ $('Decode_File_And_Prepare_Update').first().json.chatId }}",
        "text": "=‚úÖ *File Updated Successfully!*  üìÑ File: {{ $('Decode_File_And_Prepare_Update').first().json.fileName }} üìÅ Repository: {{ $('Decode_File_And_Prepare_Update').first().json.repoFullName }} üîó View on GitHub: {{ $('Commit_Updated_File_To_GitHub').first().json.content.html_url }}  **Changes Made:** {{ $('GitHub_File_Update_Agent').first().json.output.changesSummary }}  üéâ Your file has been updated and committed to GitHub!",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        5104,
        592
      ],
      "id": "47a5ce67-2c16-4aa9-b5dd-933d8d226422",
      "name": "Send_Update_Confirmation",
      "webhookId": "6ce7076e-43b7-4f4c-9259-ff072f6e59bc",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callback_query.data;\nconst chatId = $input.first().json.callback_query.message.chat.id;\n\nconsole.log('üéØ Processing repo selection:', callbackData);\n\n// Extract repo info (format: \"fileupdate:repo:owner/repo-name\")\nif (!callbackData.startsWith('fileupdate:repo:')) {\n  throw new Error('Invalid callback format');\n}\n\nconst repoFullName = callbackData.replace('fileupdate:repo:', '');\nconst [owner, repoName] = repoFullName.split('/');\n\nconsole.log(`‚úÖ Selected: ${repoFullName}`);\n\nreturn [{\n  json: {\n    owner: owner,\n    repoName: repoName,\n    repoFullName: repoFullName,\n    chatId: chatId,\n    branch: 'main',\n    updateMode: 'github_file'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3920,
        112
      ],
      "id": "037a07af-1286-46d7-86d8-7df8302d5af2",
      "name": "Extract_Selected_Repo_For_Update1"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents/{{ $json.folderPath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1568,
        2192
      ],
      "id": "7adf5e70-8a2d-4f7e-83d7-5b50080cb80a",
      "name": "Fetch_Folder_Contents"
    },
    {
      "parameters": {
        "jsCode": "const contents = $input.all();\n\n// Get the folder path and repo info from the Decode_Legacy_Navigation node\nconst navData = $('Decode_Legacy_Navigation').first().json;\n\nconst currentPath = navData.folderPath || '';\nconst repoFullName = navData.repoFullName;\nconst chatId = navData.chatId;\n\nconsole.log('üìÇ Formatting subfolder:', currentPath);\nconsole.log('üì¶ Repository:', repoFullName);\n\n// Separate folders and files\nconst folders = [];\nconst files = [];\n\nfor (const item of contents) {\n  const data = item.json;\n  \n  if (data.type === 'dir') {\n    folders.push(data);\n  } else if (data.type === 'file') {\n    const fileName = data.name.toLowerCase();\n    if (fileName.endsWith('.md') || fileName.endsWith('.txt') || \n        fileName.endsWith('.json') || fileName.endsWith('.js') || \n        fileName.endsWith('.py') || fileName.endsWith('.html') ||\n        fileName.endsWith('.css') || fileName.endsWith('.yml') ||\n        fileName.endsWith('.yaml')) {\n      files.push(data);\n    }\n  }\n}\n\nconsole.log(`üìä Found ${folders.length} folders, ${files.length} files`);\n\n// Create item mapping for storage\nconst allItems = [...folders, ...files];\nconst itemsData = allItems.map(item => ({\n  name: item.name,\n  path: item.path,\n  type: item.type\n}));\n\n// Store navigation data (will be retrieved via Parse_Navigation_Callback)\nconst navigationData = {\n  repo: repoFullName,\n  currentPath: currentPath,\n  items: itemsData,\n  userPrompt: navData.userPrompt  // ADD THIS\n\n};\n\n// Encode as base64 to hide in message (place at end)\nconst hiddenData = Buffer.from(JSON.stringify(navigationData)).toString('base64');\n\n// Create buttons with SHORT callback_data using indices\nconst buttons = [];\n\n// Add \"Up\" button if not at root\nif (currentPath !== '' && currentPath !== '/') {\n  buttons.push([{\n    text: \"‚¨ÜÔ∏è Go Up\",\n    callback_data: `nav:up`\n  }]);\n}\n\n// Add folders with index-based callbacks\nfolders.forEach((folder, index) => {\n  buttons.push([{\n    text: `üìÅ ${folder.name}`,\n    callback_data: `nav:d:${index}` // \"d\" for directory, then index\n  }]);\n});\n\n// Add files with index-based callbacks\nfiles.forEach((file, index) => {\n  const icon = file.name.endsWith('.md') ? 'üìù' : \n               file.name.endsWith('.json') ? 'üìã' : 'üìÑ';\n  buttons.push([{\n    text: `${icon} ${file.name}`,\n    callback_data: `nav:f:${folders.length + index}` // \"f\" for file, offset by folder count\n  }]);\n});\n\n// Add navigation buttons\nbuttons.push([\n  { text: \"üè† Back to Root\", callback_data: \"nav:root\" },\n  { text: \"‚ùå Cancel\", callback_data: \"cancel_fileupdate\" }\n]);\n\n// Breadcrumb\nconst breadcrumb = currentPath ? currentPath.split('/').join(' / ') : 'Root';\n\n// Use HTML formatting with hidden data at the end\nconst messageText = `üìÇ <b>Repository: ${repoFullName}</b>\nüìç Location: ${breadcrumb}\n\nüìÅ Folders: ${folders.length}\nüìÑ Files: ${files.length}\n\n‚ö†Ô∏è Only text-based files shown\n\n<code>${hiddenData}</code>`;\n\nreturn [{\n  json: {\n    chatId: chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    }),\n    repoFullName: repoFullName,\n    currentPath: currentPath\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1312,
        2192
      ],
      "id": "aab6acf1-d877-47d0-b459-2fcd60fa6952",
      "name": "Format_Subfolder_Contents"
    },
    {
      "parameters": {
        "jsCode": "// UPDATED Parse_Navigation_Callback Node\n// This now handles BOTH repo selection for embeddings AND file update navigation\n\nconst callbackData = $input.first().json.callback_query.data;\nconst messageText = $input.first().json.callback_query.message.text;\nconst chatId = $input.first().json.callback_query.message.chat.id;\n\nconst staticData = $getWorkflowStaticData('global');\nconst userPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n\nconsole.log('üîç Parsing callback:', callbackData);\n\n// ===== NEW: Handle initial repo selection (for embeddings) =====\nif (callbackData.startsWith('repo:')) {\n  console.log('üì¶ Initial repo selection for embeddings detected');\n  return [{\n    json: {\n      action: 'store_embeddings',\n      callbackData: callbackData,\n      chatId: chatId,\n      rawInput: $input.first().json\n    }\n  }];\n}\n\n// ===== CASE 1: File update repo selection =====\nif (callbackData.startsWith('fileupdate:repo:')) {\n  console.log('üì¶ File update repo selection detected');\n  return [{\n    json: {\n      action: 'select_repo',\n      callbackData: callbackData,\n      chatId: chatId,\n      rawInput: $input.first().json,\n      userPrompt: userPrompt\n    }\n  }];\n}\n\n// ===== CASE 2: Cancel button =====\nif (callbackData === 'cancel_fileupdate' || callbackData === 'cancel') {\n  console.log('‚ùå Cancel detected');\n  return [{\n    json: {\n      action: 'cancel_fileupdate',\n      chatId: chatId,\n      userPrompt: userPrompt\n    }\n  }];\n}\n\n// ===== CASE 3: Navigation commands (require hidden data) =====\nconst lines = messageText.split('\\n');\nconst hiddenDataBase64 = lines[lines.length - 1].trim();\n\nconsole.log('üì¶ Looking for hidden data...');\n\nif (!hiddenDataBase64 || hiddenDataBase64.length < 50 || !/^[A-Za-z0-9+/=]+$/.test(hiddenDataBase64)) {\n  throw new Error('Navigation data not found in message. This callback requires folder/file context.');\n}\n\nlet navigationData;\ntry {\n  navigationData = JSON.parse(Buffer.from(hiddenDataBase64, 'base64').toString('utf-8'));\n  console.log('‚úÖ Navigation data decoded successfully');\n} catch (error) {\n  throw new Error('Failed to decode navigation data: ' + error.message);\n}\n\nconst repoFullName = navigationData.repo;\nconst currentPath = navigationData.currentPath;\nconst items = navigationData.items;\n\nconsole.log(`üì¶ Repo: ${repoFullName}, Current: ${currentPath}`);\nconsole.log(`üìã Items count: ${items.length}`);\n\n// Handle \"Up\" navigation\nif (callbackData === 'nav:up') {\n  const pathParts = currentPath.split('/').filter(p => p);\n  const parentPath = pathParts.slice(0, -1).join('/');\n  \n  console.log(`‚¨ÜÔ∏è Going up to: ${parentPath || 'root'}`);\n  \n  return [{\n    json: {\n      action: 'navigate_folder',\n      folderPath: parentPath || '',\n      repoFullName: repoFullName,\n      chatId: chatId,\n      userPrompt: userPrompt\n    }\n  }];\n}\n\n// Handle \"Back to Root\"\nif (callbackData === 'nav:root') {\n  console.log('üè† Going to root');\n  \n  return [{\n    json: {\n      action: 'navigate_folder',\n      folderPath: '',\n      repoFullName: repoFullName,\n      chatId: chatId,\n      userPrompt: userPrompt\n    }\n  }];\n}\n\n// Handle index-based navigation (nav:d:0 or nav:f:3)\nif (callbackData.startsWith('nav:d:') || callbackData.startsWith('nav:f:')) {\n  const [, type, indexStr] = callbackData.split(':');\n  const index = parseInt(indexStr);\n  \n  const item = items[index];\n  if (!item) {\n    throw new Error(`Item at index ${index} not found`);\n  }\n  \n  console.log(`‚úÖ Selected: ${item.name} (${item.path})`);\n  \n  if (type === 'd') {\n    return [{\n      json: {\n        action: 'navigate_folder',\n        folderPath: item.path,\n        repoFullName: repoFullName,\n        chatId: chatId,\n        userPrompt: userPrompt\n      }\n    }];\n  } else {\n    return [{\n      json: {\n        action: 'select_file',\n        filePath: item.path,\n        repoFullName: repoFullName,\n        chatId: chatId,\n        userPrompt: userPrompt\n      }\n    }];\n  }\n}\n\n// Legacy format (for backward compatibility)\nif (callbackData.startsWith('fud:') || callbackData.startsWith('fuf:')) {\n  console.log('üîÑ Legacy navigation format detected');\n  return [{\n    json: {\n      action: 'legacy_navigation',\n      callbackData: callbackData,\n      chatId: chatId,\n      rawInput: $input.first().json,\n      userPrompt: userPrompt\n    }\n  }];\n}\n\n// Fallback\nconsole.log('‚ö†Ô∏è Unknown callback format');\nreturn [{\n  json: {\n    action: callbackData,\n    chatId: chatId\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2544,
        2384
      ],
      "id": "d043788e-9179-40cc-8248-5f33a1b7c614",
      "name": "Parse_Navigation_Callback"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "2136b7db-9bae-4267-a189-27ddd096b336",
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "legacy_navigation",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Legacy Navigation"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "navigate_folder",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "9ab9cdf2-d289-4f36-a18e-38c7449ef75a"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Folder Selection"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "76b4fb41-05dc-4e2c-8dd9-1e553894adc4",
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "select_repo",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Select Repo"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "c9cccb17-0055-4de6-9c63-0c854ad24c7b",
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "select_file",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "File Selection"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "48a898cd-445f-4018-8de2-f791f7b6d756",
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "store_embeddings",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Store Data"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        -2336,
        2448
      ],
      "id": "e0762344-b384-4171-adb0-6c81a4b62d4c",
      "name": "Route_Navigation_Action"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.callback_query.message.chat.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "HTML"
            },
            {
              "name": "reply_markup",
              "value": "={{ $json.reply_markup }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -992,
        2192
      ],
      "id": "dde455ff-f96c-44cc-9121-69d547e9e2fc",
      "name": "Send_Folder_Contents_Message"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1376,
        2640
      ],
      "id": "da73fdd7-3e47-4d56-840f-33a39550d528",
      "name": "Fetch_Repo_Contents1"
    },
    {
      "parameters": {
        "jsCode": "const contents = $input.all();\nconst repoInfo = $('Extract_Selected_Repo_For_Update2').first().json;\n\nconsole.log('üìÇ Formatting files and folders...');\nconst userPrompt = repoInfo.userPrompt;  // ADD THIS\n\nconsole.log('üìÇ Formatting files and folders...');\nconsole.log('üìù Has prompt:', userPrompt ? 'Yes' : 'No');\n// Separate folders and files\nconst folders = [];\nconst files = [];\n\nfor (const item of contents) {\n  const data = item.json;\n  \n  if (data.type === 'dir') {\n    folders.push(data);\n  } else if (data.type === 'file') {\n    // Only show text-based files\n    const fileName = data.name.toLowerCase();\n    if (fileName.endsWith('.md') || \n        fileName.endsWith('.txt') || \n        fileName.endsWith('.json') ||\n        fileName.endsWith('.js') ||\n        fileName.endsWith('.py')) {\n      files.push(data);\n    }\n  }\n}\n\nconsole.log(`üìä Found ${folders.length} folders, ${files.length} files`);\n\n// Create buttons with index-based callback\nconst buttons = [];\nlet itemIndex = 0;\n\n// Add folders first\nfolders.forEach(folder => {\n  buttons.push([{\n    text: `üìÅ ${folder.name}`,\n    callback_data: `fud:${itemIndex++}`\n  }]);\n});\n\n// Add files\nfiles.forEach(file => {\n  const icon = file.name.endsWith('.md') ? 'üìù' : \n               file.name.endsWith('.json') ? 'üìã' : 'üìÑ';\n  buttons.push([{\n    text: `${icon} ${file.name}`,\n    callback_data: `fuf:${itemIndex++}`\n  }]);\n});\n\n// Add back/cancel buttons\nbuttons.push([\n  { text: \"üîô Back to Repos\", callback_data: \"fileupdate:back\" },\n  { text: \"‚ùå Cancel\", callback_data: \"cancel_fileupdate\" }\n]);\n\n// Create item mapping as JSON string to embed in message\nconst allItems = [...folders, ...files];\nconst itemsData = allItems.map(item => ({\n  name: item.name,\n  path: item.path,\n  type: item.type\n}));\n\n// Encode repo and items data as base64 to hide in message\nconst hiddenData = Buffer.from(JSON.stringify({\n  repo: repoInfo.repoFullName,\n  items: itemsData,\n  userPrompt: userPrompt  \n})).toString('base64');\n\nconst messageText = `üìÇ *Contents of ${repoInfo.repoName}*\n\nSelect a folder to browse or a file to update:\n\nüìÅ Folders: ${folders.length}\nüìÑ Editable Files: ${files.length}\n\n‚ö†Ô∏è Only text-based files (.md, .txt, .json, etc.) are shown.\n\n\\`${hiddenData}\\``;\n\nreturn [{\n  json: {\n    chatId: repoInfo.chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    })\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1152,
        2640
      ],
      "id": "c40bc58c-9e57-48fb-afbd-bf08fccdc9a2",
      "name": "Format_File_Folder_List1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.callback_query.message.chat.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "Markdown"
            },
            {
              "name": "reply_markup",
              "value": "={{ $json.reply_markup }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -928,
        2640
      ],
      "id": "1cf9d722-2063-42af-bc9f-c029d7349870",
      "name": "Send_File_Selection_Message1"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents/{{ $json.filePath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1696,
        2960
      ],
      "id": "47c643c3-f9b1-4e1e-914a-cc6739f66489",
      "name": "Fetch_File_Contents1"
    },
    {
      "parameters": {
        "jsCode": "const fileResponse = $input.first().json;\nconst selectionData = $('Handle_File_Selection1').first().json;\n\nconsole.log('üìÑ Decoding file contents...');\n\n// Decode base64 content\nconst decodedContent = Buffer.from(fileResponse.content, 'base64').toString('utf-8');\n\nconsole.log(`üìÑ File size: ${decodedContent.length} characters`);\nconsole.log(`üîí SHA: ${fileResponse.sha}`);\n\n// Get user's custom prompt or use default\nconst userPrompt = selectionData.userPrompt;\nconst defaultInstruction = \"Review and improve the document structure, fix any typos, and ensure consistent formatting. Also Make the document very very comprehensive Explain the Details also of the portion also\";\n\nconst updateInstruction = userPrompt || defaultInstruction;\n\nconsole.log('üìù Using instruction:', userPrompt ? 'CUSTOM PROMPT' : 'DEFAULT');\nconsole.log('üí° Instruction:', updateInstruction);\n\nreturn [{\n  json: {\n    repoFullName: selectionData.repoFullName,\n    filePath: selectionData.filePath,\n    fileName: fileResponse.name,\n    currentContent: decodedContent,\n    fileSha: fileResponse.sha,\n    chatId: selectionData.chatId,\n    updateInstruction: updateInstruction,  // THIS NOW USES USER'S PROMPT!\n    originalUserMessage: userPrompt || \"File update via GitHub navigation\",\n    fileUrl: fileResponse.html_url,\n    downloadUrl: fileResponse.download_url,\n    usedCustomPrompt: !!userPrompt  // Track if custom prompt was used\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1472,
        2960
      ],
      "id": "3581929b-e779-4dc1-9edb-4802f9cff8bb",
      "name": "Decode_File_And_Prepare_Update1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=`You are a Senior Software Engineer tasked with updating a file in a GitHub repository.\n\n**File Information:**\n- Repository: {{ $json.repoFullName }}\n- File Path: {{ $json.filePath }}\n- File Name: {{ $json.fileName }}\n\n**Current File Content:**\n{{ $json.currentContent }}\n\n\n**User's Update Request:**\n{{ $json.updateInstruction }}\n\n**Original Message:**\n{{ $json.originalUserMessage }}\n\n**YOUR TASK:**\n1. Analyze the current file content carefully\n2. Understand what changes the user wants\n3. Apply the requested changes precisely\n4. Maintain code quality, formatting, and style\n5. Return the COMPLETE updated file content\n\n**OUTPUT FORMAT:**\nReturn a JSON object with this structure:\n\n{\n  \"updatedContent\": \"... complete updated file content here ...\",\n  \"changesSummary\": \"Brief bullet-point list of what was changed\",\n  \"linesChanged\": 5\n}\n\n\n**CRITICAL RULES:**\n- Return the ENTIRE file content, not just the changed parts\n- Preserve all formatting, indentation, and code style\n- Do NOT add any markdown code fences to the content itself\n- Do NOT truncate or summarize the file\n- Be precise with the changes requested",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -1328,
        2960
      ],
      "id": "74626ee8-0a37-4ee2-a599-fafbcc13c313",
      "name": "AI Agent2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -1376,
        3168
      ],
      "id": "57b9f24f-d281-4dd9-92b1-4dcf59a43b89",
      "name": "OpenAI Chat Model7",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=https://api.github.com/repos/{{ $('Prepare_GitHub_Commit').first().json.repoFullName }}/contents/{{ $('Prepare_GitHub_Commit').first().json.filePath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "message",
              "value": "=Update {{ $('Decode_File_And_Prepare_Update1').first().json.fileName }} via n8n workflow"
            },
            {
              "name": "content",
              "value": "={{ $('Prepare_GitHub_Commit').first().json.base64Content }}"
            },
            {
              "name": "sha",
              "value": "={{ $('Decode_File_And_Prepare_Update1').first().json.fileSha }}"
            },
            {
              "name": "branch",
              "value": "main"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -992,
        3184
      ],
      "id": "f9a8f5b4-6d5f-422a-a7b8-c1b98324dd9d",
      "name": "Commit_Updated_File_To_GitHub1"
    },
    {
      "parameters": {
        "chatId": "={{ $('Decode_File_And_Prepare_Update1').first().json.chatId }}",
        "text": "=// Configuration for Send_Update_Confirmation1 Telegram node\n\n// Chat ID\nchatId: {{ $('Decode_File_And_Prepare_Update1').first().json.chatId }}\n\n// Message text (use this in the \"text\" field)\n‚úÖ *File Updated Successfully!*\n\nüìÑ *File:* {{ $('Decode_File_And_Prepare_Update1').first().json.fileName }}\nüìÅ *Repository:* {{ $('Decode_File_And_Prepare_Update1').first().json.repoFullName }}\nüìç *Path:* {{ $('Decode_File_And_Prepare_Update1').first().json.filePath }}\n\nüîó *View on GitHub:*\n{{ $json.content.html_url }}\n‚ú® *Changes Summary:*\n{{ $('AI Agent2').first().json.output.changesSummary || 'File has been updated successfully' }}\n\nüéâ Your file has been committed to the main branch!\n\n_Commit SHA:_ `{{ $json.content.sha }}`",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -752,
        3184
      ],
      "id": "040dfd10-b872-4027-ba68-518029267197",
      "name": "Send_Update_Confirmation1",
      "webhookId": "6ce7076e-43b7-4f4c-9259-ff072f6e59bc",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callbackData;\nconst chatId = $input.first().json.chatId;\nconst rawInput = $input.first().json.rawInput;\n\nconsole.log('üéØ Processing repo selection:', callbackData);\n\nif (!callbackData.startsWith('fileupdate:repo:')) {\n  throw new Error('Invalid callback format');\n}\n\nconst repoFullName = callbackData.replace('fileupdate:repo:', '');\nconst [owner, repoName] = repoFullName.split('/');\n\nconsole.log(`‚úÖ Selected: ${repoFullName}`);\n\n// Extract user prompt from the Telegram message text\nlet userPrompt = null;\n\ntry {\n  const messageText = rawInput.callback_query.message.text;\n  console.log('üìÑ Full message text:', messageText);\n  console.log('üìè Message length:', messageText.length);\n  \n  // Updated regex to match the exact format in your message\n  // Pattern: Your Update Instructions:\\n\"<PROMPT>\\n\"confirm prompt\"\"\n  const instructionsMatch = messageText.match(/Your Update Instructions:\\n\"([\\s\\S]*?)\\n\"confirm prompt\"/);\n  \n  if (instructionsMatch && instructionsMatch[1]) {\n    userPrompt = instructionsMatch[1].trim();\n    console.log('‚úÖ Extracted prompt (length):', userPrompt.length);\n    console.log('‚úÖ Extracted prompt:', userPrompt);\n  } else {\n    console.log('‚ö†Ô∏è No prompt found with primary regex');\n    \n    // Fallback: Try alternative patterns\n    // Pattern 1: Between quotes after \"Your Update Instructions:\"\n    const altMatch1 = messageText.match(/Your Update Instructions:\\s*\\n\\s*\"([^\"]+)\"/);\n    if (altMatch1 && altMatch1[1]) {\n      userPrompt = altMatch1[1].trim();\n      console.log('‚úÖ Extracted with fallback pattern 1');\n    } else {\n      // Pattern 2: Try to extract everything between the first quote and \"confirm prompt\"\n      const altMatch2 = messageText.match(/\"([\\s\\S]*?)\"\\s*\\n\\s*\"confirm prompt\"/);\n      if (altMatch2 && altMatch2[1]) {\n        userPrompt = altMatch2[1].trim();\n        console.log('‚úÖ Extracted with fallback pattern 2');\n      }\n    }\n  }\n  \n  // Final fallback: Check workflow static data\n  if (!userPrompt) {\n    console.log('üì¶ Checking workflow static data...');\n    const staticData = $getWorkflowStaticData('global');\n    userPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n    console.log('üíæ Static data prompt:', userPrompt ? 'Found' : 'Not found');\n  }\n  \n} catch (error) {\n  console.error('‚ùå Error extracting prompt:', error.message);\n  console.error('Stack:', error.stack);\n  \n  // Final fallback: try to get from static data\n  const staticData = $getWorkflowStaticData('global');\n  userPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n}\n\nconsole.log('üîç Final prompt status:', userPrompt ? 'Available' : 'Not available');\nif (userPrompt) {\n  console.log('üìù Final prompt preview:', userPrompt.substring(0, 100) + '...');\n}\n\nreturn [{\n  json: {\n    owner: owner,\n    repoName: repoName,\n    repoFullName: repoFullName,\n    chatId: chatId,\n    branch: 'main',\n    updateMode: 'github_file',\n    userPrompt: userPrompt\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1616,
        2640
      ],
      "id": "fe92b8fb-44ed-4653-9ce3-495fcef03444",
      "name": "Extract_Selected_Repo_For_Update2"
    },
    {
      "parameters": {
        "content": "Handles Github File Selection",
        "height": 1216,
        "width": 2016,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -2592,
        2096
      ],
      "typeVersion": 1,
      "id": "3058c76e-22b7-4a4b-a49c-454982246762",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callbackData;\nconst messageText = $input.first().json.rawInput.callback_query.message.text;\nconst chatId = $input.first().json.chatId;\n\nconst staticData = $getWorkflowStaticData('global');\nconst storedPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n\nconsole.log('üîç Decoding legacy navigation:', callbackData);\nconsole.log('üìù Has stored prompt:', storedPrompt ? 'Yes' : 'No');\n// The hidden data is at the end of the message after the last newline\n// It's NOT wrapped in backticks in the raw text, just formatted as code by Telegram\nconst lines = messageText.split('\\n');\nconst hiddenDataBase64 = lines[lines.length - 1].trim();\n\nconsole.log('üîê Extracted base64:', hiddenDataBase64);\n\nif (!hiddenDataBase64 || hiddenDataBase64.length < 10) {\n  throw new Error('Could not find hidden data in message');\n}\n\nlet hiddenData;\ntry {\n  hiddenData = JSON.parse(Buffer.from(hiddenDataBase64, 'base64').toString('utf-8'));\n} catch (error) {\n  throw new Error('Failed to decode hidden data: ' + error.message);\n}\n\nconst repoFullName = hiddenData.repo;\nconst items = hiddenData.items;\nconst userPrompt = hiddenData.userPrompt || storedPrompt;  \nconsole.log(`üì¶ Repo: ${repoFullName}`);\nconsole.log(`üìã Items count: ${items.length}`);\nconsole.log('üìù Prompt available:', userPrompt ? 'Yes' : 'No');\n\n\n// Parse the callback data (format: fud:0 or fuf:1)\nconst [type, indexStr] = callbackData.split(':');\nconst index = parseInt(indexStr);\n\nconst item = items[index];\n\nif (!item) {\n  throw new Error(`Item at index ${index} not found`);\n}\n\nconsole.log(`‚úÖ Selected: ${item.name} (${item.path})`);\n\nif (type === 'fud') {\n  // User clicked a folder\n  return [{\n    json: {\n      repoFullName: repoFullName,\n      folderPath: item.path,\n      chatId: chatId,\n      action: 'browse_folder',\n      userPrompt: userPrompt,  // ADD THIS\n    }\n  }];\n} else if (type === 'fuf') {\n  // User clicked a file\n  return [{\n    json: {\n      repoFullName: repoFullName,\n      filePath: item.path,\n      chatId: chatId,\n      action: 'update_file',\n      userPrompt: userPrompt\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2016,
        2208
      ],
      "id": "99d3a9f4-2d7b-4525-9599-a05d4bdfdc50",
      "name": "Decode_Legacy_Navigation"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "browse_folder",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "f449f769-d3e8-496e-aa37-37a48be313f9"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Browse Folder"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "40ed127a-24bb-48ba-b612-8bb0bcfd1805",
                    "leftValue": "={{ $json.action }}",
                    "rightValue": "update_file",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Update File"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        -1792,
        2208
      ],
      "id": "4fca30d3-75d1-432b-a532-17272ca99846",
      "name": "Switch2"
    },
    {
      "parameters": {
        "jsCode": "const folderPath = $input.first().json.folderPath;\nconst repoFullName = $input.first().json.repoFullName;\nconst chatId = $input.first().json.chatId;\n\nconsole.log('üìÑ Preparing to fetch folder:', folderPath);\nconsole.log('üì¶ Repository:', repoFullName);\n\n// Try to get userPrompt from incoming data first\nlet userPrompt = $input.first().json.userPrompt;\n\n// If not found, try to extract from the Telegram callback message\nif (!userPrompt) {\n  console.log('‚ö†Ô∏è UserPrompt not in input, trying to extract from message...');\n  \n  try {\n    // Get the raw callback query data\n    const callbackQuery = $('Telegram Trigger1').first().json.callback_query;\n    const messageText = callbackQuery.message.text;\n    \n    console.log('üìù Message text preview:', messageText.substring(0, 100));\n    \n    // Extract the base64 encoded data (it's the last line after \"shown\\n\\n\")\n    const lines = messageText.split('\\n');\n    const base64Data = lines[lines.length - 1].trim();\n    \n    console.log('üîç Extracted base64 length:', base64Data.length);\n    \n    if (base64Data && base64Data.length > 50) {\n      // Decode the base64 data\n      const decodedData = JSON.parse(Buffer.from(base64Data, 'base64').toString('utf-8'));\n      userPrompt = decodedData.userPrompt;\n      console.log('‚úÖ Extracted userPrompt from message:', userPrompt ? 'Yes' : 'No');\n    }\n  } catch (error) {\n    console.error('‚ùå Failed to extract userPrompt from message:', error.message);\n  }\n}\n\n// Final fallback: check workflow static data\nif (!userPrompt) {\n  console.log('üì¶ Checking workflow static data...');\n  const staticData = $getWorkflowStaticData('global');\n  userPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n  console.log('üíæ Static data prompt:', userPrompt ? 'Found' : 'Not found');\n}\n\nconsole.log('üîç Final userPrompt:', userPrompt ? 'Yes' : 'No');\n\nreturn [{\n  json: {\n    repoFullName: repoFullName,\n    folderPath: folderPath,\n    chatId: chatId,\n    userPrompt: userPrompt\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1888,
        2448
      ],
      "id": "ad977d3a-8e3d-4267-a221-ba365e7906a5",
      "name": "Prepare_Folder_Fetch"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoFullName }}/contents/{{ $json.folderPath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1600,
        2432
      ],
      "id": "dd54b45c-8019-460d-82ed-c4b265003e43",
      "name": "Fetch_Folder_Contents1"
    },
    {
      "parameters": {
        "jsCode": "const contents = $input.all();\n\n// Try to get navigation data from multiple possible sources\nlet navData;\nlet repoFullName;\nlet currentPath;\nlet chatId;\nlet userPrompt = null;\n\n// Try Prepare_Folder_Fetch first (new flow)\ntry {\n  navData = $('Prepare_Folder_Fetch').first().json;\n  repoFullName = navData.repoFullName;\n  currentPath = navData.folderPath || '';\n  chatId = navData.chatId;\n  userPrompt = navData.userPrompt || null;\n  console.log('üì¶ Using data from Prepare_Folder_Fetch');\n  console.log('üîç UserPrompt:', userPrompt ? 'Found' : 'Not found');\n} catch (e) {\n  // Fallback to Decode_Legacy_Navigation (old flow)\n  try {\n    navData = $('Decode_Legacy_Navigation').first().json;\n    repoFullName = navData.repoFullName;\n    currentPath = navData.folderPath || '';\n    chatId = navData.chatId;\n    userPrompt = navData.userPrompt || null;\n    console.log('üì¶ Using data from Decode_Legacy_Navigation');\n    console.log('üîç UserPrompt:', userPrompt ? 'Found' : 'Not found');\n  } catch (e2) {\n    // Last resort: try to extract from Telegram callback\n    const triggerData = $('Telegram Trigger1').first().json;\n    chatId = triggerData.callback_query.message.chat.id;\n    \n    // Extract repo from message text\n    const messageText = triggerData.callback_query.message.text;\n    const repoMatch = messageText.match(/Repository: ([^\\s\\n]+)/);\n    repoFullName = repoMatch ? repoMatch[1] : 'unknown/repo';\n    \n    // Try to extract path from first item\n    currentPath = contents.length > 0 ? contents[0].json.path.split('/').slice(0, -1).join('/') : '';\n    \n    // Try to extract userPrompt from base64 data in message\n    try {\n      const lines = messageText.split('\\n');\n      const base64Data = lines[lines.length - 1].trim();\n      if (base64Data && base64Data.length > 50) {\n        const decodedData = JSON.parse(Buffer.from(base64Data, 'base64').toString('utf-8'));\n        userPrompt = decodedData.userPrompt || null;\n      }\n    } catch (decodeError) {\n      console.log('‚ö†Ô∏è Could not extract userPrompt from message');\n    }\n    \n    console.log('‚ö†Ô∏è Using fallback data extraction');\n  }\n}\n\n// Final fallback: check workflow static data\nif (!userPrompt) {\n  console.log('üì¶ Checking workflow static data for prompt...');\n  const staticData = $getWorkflowStaticData('global');\n  userPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n  console.log('üíæ Static data prompt:', userPrompt ? 'Found' : 'Not found');\n}\n\nconsole.log('üìÇ Formatting subfolder:', currentPath);\nconsole.log('üì¶ Repository:', repoFullName);\nconsole.log('‚úÖ Final userPrompt status:', userPrompt ? 'Available' : 'Not available');\n\n// Separate folders and files\nconst folders = [];\nconst files = [];\n\nfor (const item of contents) {\n  const data = item.json;\n  \n  if (data.type === 'dir') {\n    folders.push(data);\n  } else if (data.type === 'file') {\n    const fileName = data.name.toLowerCase();\n    if (fileName.endsWith('.md') || fileName.endsWith('.txt') || \n        fileName.endsWith('.json') || fileName.endsWith('.js') || \n        fileName.endsWith('.py') || fileName.endsWith('.html') ||\n        fileName.endsWith('.css') || fileName.endsWith('.yml') ||\n        fileName.endsWith('.yaml')) {\n      files.push(data);\n    }\n  }\n}\n\nconsole.log(`üìä Found ${folders.length} folders, ${files.length} files`);\n\n// Create item mapping for storage\nconst allItems = [...folders, ...files];\nconst itemsData = allItems.map(item => ({\n  name: item.name,\n  path: item.path,\n  type: item.type\n}));\n\n// Store navigation data WITH userPrompt\nconst navigationData = {\n  repo: repoFullName,\n  currentPath: currentPath,\n  items: itemsData,\n  userPrompt: userPrompt  // ‚úÖ ADD THIS - Include the prompt in encrypted data\n};\n\n// Encode as base64 to hide in message\nconst hiddenData = Buffer.from(JSON.stringify(navigationData)).toString('base64');\n\n// Create buttons with SHORT callback_data using indices\nconst buttons = [];\n\n// Add \"Up\" button if not at root\nif (currentPath !== '' && currentPath !== '/') {\n  buttons.push([{\n    text: \"‚¨ÜÔ∏è Go Up\",\n    callback_data: `nav:up`\n  }]);\n}\n\n// Add folders with index-based callbacks\nfolders.forEach((folder, index) => {\n  buttons.push([{\n    text: `üìÅ ${folder.name}`,\n    callback_data: `nav:d:${index}` // \"d\" for directory\n  }]);\n});\n\n// Add files with index-based callbacks\nfiles.forEach((file, index) => {\n  const icon = file.name.endsWith('.md') ? 'üìù' : \n               file.name.endsWith('.json') ? 'üìã' : 'üìÑ';\n  buttons.push([{\n    text: `${icon} ${file.name}`,\n    callback_data: `nav:f:${folders.length + index}` // \"f\" for file\n  }]);\n});\n\n// Add navigation buttons\nbuttons.push([\n  { text: \"üè† Back to Root\", callback_data: \"nav:root\" },\n  { text: \"‚ùå Cancel\", callback_data: \"cancel_fileupdate\" }\n]);\n\n// Breadcrumb\nconst breadcrumb = currentPath ? currentPath.split('/').join(' / ') : 'Root';\n\n// Message text with hidden data\nconst messageText = `üìÇ <b>Repository: ${repoFullName}</b>\nüìç Location: ${breadcrumb}\n\nüìÅ Folders: ${folders.length}\nüìÑ Files: ${files.length}\n\n‚ö†Ô∏è Only text-based files shown\n\n${hiddenData}`;\n\nreturn [{\n  json: {\n    chatId: chatId,\n    text: messageText,\n    reply_markup: JSON.stringify({\n      inline_keyboard: buttons\n    }),\n    repoFullName: repoFullName,\n    currentPath: currentPath,\n    userPrompt: userPrompt  // ‚úÖ Also include in output for debugging\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1328,
        2416
      ],
      "id": "8228f93e-1940-463d-a2b8-260f3a972b4a",
      "name": "Format_Subfolder_Contents1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.telegram.org/bot8052226322:AAGAP2uOFmRuPNCKnrJpUSrAEEgtnXYwYnw/sendMessage",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "chat_id",
              "value": "={{ $('Telegram Trigger1').first().json.callback_query.message.chat.id }}"
            },
            {
              "name": "text",
              "value": "={{ $json.text }}"
            },
            {
              "name": "parse_mode",
              "value": "HTML"
            },
            {
              "name": "reply_markup",
              "value": "={{ $json.reply_markup }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1072,
        2416
      ],
      "id": "e036fd4c-0da4-40e3-a988-cb2f3d4d73a8",
      "name": "Send_Folder_Contents_Message1"
    },
    {
      "parameters": {
        "jsCode": "const fileData = $('Decode_File_And_Prepare_Update1').first().json;\nconst aiResponse = $('AI Agent2').first().json;\n\nconsole.log('üîç Checking AI Agent response...');\nconsole.log('AI Response:', JSON.stringify(aiResponse, null, 2));\n\n// Parse AI output (it might be in different formats)\nlet updatedContent;\nlet changesSummary;\n\n// Try to get the output from different possible locations\nif (aiResponse.output && typeof aiResponse.output === 'object') {\n  // Output is already parsed\n  updatedContent = aiResponse.output.updatedContent;\n  changesSummary = aiResponse.output.changesSummary;\n} else if (aiResponse.output && typeof aiResponse.output === 'string') {\n  // Output is a string that needs parsing\n  try {\n    // Remove markdown code fences if present\n    let cleanOutput = aiResponse.output.trim();\n    cleanOutput = cleanOutput.replace(/```json\\n?/g, '').replace(/```\\n?/g, '');\n    \n    const parsed = JSON.parse(cleanOutput);\n    updatedContent = parsed.updatedContent;\n    changesSummary = parsed.changesSummary;\n  } catch (e) {\n    console.error('Failed to parse AI output:', e);\n    throw new Error('AI Agent output is not valid JSON. Check AI Agent2 response.');\n  }\n} else {\n  throw new Error('AI Agent output format is unexpected. Check AI Agent2 configuration.');\n}\n\n// Validate we have content\nif (!updatedContent || updatedContent.trim().length === 0) {\n  throw new Error('AI Agent did not return any updated content!');\n}\n\nconsole.log('‚úÖ Updated content length:', updatedContent.length);\nconsole.log('üìù Changes summary:', changesSummary);\n\n// Encode to base64 for GitHub\nconst base64Content = Buffer.from(updatedContent).toString('base64');\n\nreturn [{\n  json: {\n    repoFullName: fileData.repoFullName,\n    filePath: fileData.filePath,\n    fileName: fileData.fileName,\n    fileSha: fileData.fileSha,\n    base64Content: base64Content,\n    updatedContent: updatedContent,\n    changesSummary: changesSummary || 'File updated',\n    chatId: fileData.chatId,\n    commitMessage: `Update ${fileData.fileName} via n8n workflow`\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -864,
        2960
      ],
      "id": "2ce47bff-586a-4726-9692-fd4060c3c3f9",
      "name": "Prepare_GitHub_Commit"
    },
    {
      "parameters": {
        "jsCode": "const userMessage = $('Save Chat Message1').first().json.userMessage;\nconst chatId = $('Save Chat Message1').first().json.chatId;\n\nconsole.log('üíæ Storing update prompt for chat:', chatId);\nconsole.log('üìù Prompt:', userMessage);\n\n// Store in workflow static data\nconst staticData = $getWorkflowStaticData('global');\n\nif (!staticData.fileUpdatePrompts) {\n  staticData.fileUpdatePrompts = {};\n}\n\nstaticData.fileUpdatePrompts[chatId] = userMessage;\n\nconsole.log('‚úÖ Prompt stored successfully');\n\n// Return data to trigger repo fetch\nreturn [{\n  json: {\n    chatId: chatId,\n    promptStored: true,\n    userPrompt: userMessage,\n    triggerRepoFetch: true\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2512,
        1760
      ],
      "id": "60e93df6-84cb-443b-b597-96dfd2e5a0ff",
      "name": "Store_Update_Prompt"
    },
    {
      "parameters": {
        "chatId": "={{ $('Telegram Trigger1').first().json.message.from.id }}",
        "text": "=‚úÖ **Prompt Stored!**\n\nYour update instructions have been saved. Now select a file to update:\n\nüìù Your Instructions:\n{{ $json.prompt }}\nUse the buttons below to navigate and select the file you want to update.\n",
        "additionalFields": {
          "appendAttribution": false
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        4064,
        1056
      ],
      "id": "691a1bdc-b775-46dd-be02-0a348cb45c14",
      "name": "Confirm_Prompt_Stored",
      "webhookId": "853a7039-fd9d-44d2-a093-e93bd846dd4a",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const callbackData = $input.first().json.callbackData;\nconst messageText = $input.first().json.rawInput.callback_query.message.text;\nconst chatId = $input.first().json.chatId;\n\nconst staticData = $getWorkflowStaticData('global');\nconst storedPrompt = staticData.fileUpdatePrompts?.[chatId] || null;\n\nconsole.log('üîç Decoding legacy navigation:', callbackData);\nconsole.log('üìù Has stored prompt:', storedPrompt ? 'Yes' : 'No');\n// The hidden data is at the end of the message after the last newline\n// It's NOT wrapped in backticks in the raw text, just formatted as code by Telegram\nconst lines = messageText.split('\\n');\nconst hiddenDataBase64 = lines[lines.length - 1].trim();\n\nconsole.log('üîê Extracted base64:', hiddenDataBase64);\n\nif (!hiddenDataBase64 || hiddenDataBase64.length < 10) {\n  throw new Error('Could not find hidden data in message');\n}\n\nlet hiddenData;\ntry {\n  hiddenData = JSON.parse(Buffer.from(hiddenDataBase64, 'base64').toString('utf-8'));\n} catch (error) {\n  throw new Error('Failed to decode hidden data: ' + error.message);\n}\n\nconst repoFullName = hiddenData.repo;\nconst items = hiddenData.items;\nconst userPrompt = hiddenData.userPrompt || storedPrompt;  \nconsole.log(`üì¶ Repo: ${repoFullName}`);\nconsole.log(`üìã Items count: ${items.length}`);\nconsole.log('üìù Prompt available:', userPrompt ? 'Yes' : 'No');\n\n\n// Parse the callback data (format: fud:0 or fuf:1)\nconst [type, indexStr] = callbackData.split(':');\nconst index = parseInt(indexStr);\n\nconst item = items[index];\n\nif (!item) {\n  throw new Error(`Item at index ${index} not found`);\n}\n\nconsole.log(`‚úÖ Selected: ${item.name} (${item.path})`);\n\nif (type === 'fud') {\n  // User clicked a folder\n  return [{\n    json: {\n      repoFullName: repoFullName,\n      folderPath: item.path,\n      chatId: chatId,\n      action: 'browse_folder',\n      userPrompt: userPrompt,  // ADD THIS\n    }\n  }];\n} else if (type === 'fuf') {\n  // User clicked a file\n  return [{\n    json: {\n      repoFullName: repoFullName,\n      filePath: item.path,\n      chatId: chatId,\n      action: 'update_file',\n      userPrompt: userPrompt\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2144,
        3456
      ],
      "id": "07df3960-776f-4430-a46c-60a561c1f3d5",
      "name": "Decode_Legacy_Navigation1"
    },
    {
      "parameters": {
        "jsCode": "// This node receives already-processed data from Parse_Navigation_Callback\n// The data structure is: { action, filePath, repoFullName, chatId }\n\nconst inputData = $input.first().json;\n\nconsole.log('üìÑ Processing file selection...');\nconsole.log('Action:', inputData.action);\nconsole.log('Input userPrompt:', inputData.userPrompt);\n\n// Check if this is a file selection\nif (inputData.action === 'select_file') {\n  console.log('‚úÖ File selected:', inputData.filePath);\n  console.log('üì¶ Repository:', inputData.repoFullName);\n  \n  let userPrompt = inputData.userPrompt;\n  \n  // If userPrompt is null, try to extract from Telegram message\n  if (!userPrompt) {\n    console.log('‚ö†Ô∏è UserPrompt is null, extracting from Telegram message...');\n    \n    try {\n      // Get the callback query from Telegram Trigger\n      const callbackQuery = $('Telegram Trigger1').first().json.callback_query;\n      const messageText = callbackQuery.message.text;\n      \n      console.log('üìù Message text length:', messageText.length);\n      \n      // Extract the base64 encoded data (last line after \"shown\\n\\n\")\n      const lines = messageText.split('\\n');\n      const base64Data = lines[lines.length - 1].trim();\n      \n      console.log('üîç Base64 data length:', base64Data.length);\n      console.log('üîç Base64 preview:', base64Data.substring(0, 50) + '...');\n      \n      if (base64Data && base64Data.length > 50) {\n        // Decode the base64 data\n        const decodedData = JSON.parse(Buffer.from(base64Data, 'base64').toString('utf-8'));\n        userPrompt = decodedData.userPrompt || null;\n        \n        console.log('‚úÖ Decoded data keys:', Object.keys(decodedData));\n        console.log('‚úÖ Extracted userPrompt:', userPrompt ? 'Yes' : 'No');\n        \n        if (userPrompt) {\n          console.log('üìù Prompt preview:', userPrompt.substring(0, 100) + '...');\n        }\n      }\n    } catch (error) {\n      console.error('‚ùå Failed to extract userPrompt:', error.message);\n      console.error('Stack:', error.stack);\n    }\n  }\n  \n  // Final fallback: check workflow static data\n  if (!userPrompt) {\n    console.log('üì¶ Checking workflow static data...');\n    const staticData = $getWorkflowStaticData('global');\n    userPrompt = staticData.fileUpdatePrompts?.[inputData.chatId] || null;\n    console.log('üíæ Static data prompt:', userPrompt ? 'Found' : 'Not found');\n  }\n  \n  console.log('üéØ Final userPrompt status:', userPrompt ? 'Available' : 'Still null');\n  \n  // Return file selection data with user prompt\n  return [{\n    json: {\n      action: 'update_file',\n      repoFullName: inputData.repoFullName,\n      filePath: inputData.filePath,\n      chatId: inputData.chatId,\n      needsFileContents: true,\n      userPrompt: userPrompt\n    }\n  }];\n}\n\n// If it's not a file selection, just pass through\nconsole.log('‚ö†Ô∏è Not a file selection, passing through');\nreturn [{\n  json: inputData\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2144,
        3040
      ],
      "id": "114b49e8-8270-496a-b510-4aaf193f7ba7",
      "name": "Handle_File_Selection1"
    },
    {
      "parameters": {
        "chatId": "={{ $('Telegram Trigger1').first().json.callback_query.message.chat.id }}",
        "text": "=‚úÖ *Data Stored Successfully!*\n\nüì¶ Repository: {{ $('Extract_Selected_Repo').first().json.repoFullName }}\nüóÇÔ∏è Documents processed and embeddings stored in Pinecone\n\nYou can now ask questions about your documentation!",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        2272,
        112
      ],
      "id": "b1ab3377-2d1c-46ad-8a43-ad97e36f1154",
      "name": "Brain Storming Mode Activation",
      "webhookId": "02c92cff-bb31-4632-b350-f6876fe428a9",
      "executeOnce": true,
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "content": "Github Node",
        "height": 528,
        "width": 2128
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2624,
        2832
      ],
      "typeVersion": 1,
      "id": "5d7d12cf-ccc2-4117-955c-ff330184e689",
      "name": "Sticky Note8"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Search through documents using semantic similarity. Returns top 15 most relevant document chunks.",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "topK": 15,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        2000,
        2432
      ],
      "id": "2bd7c51f-54c1-4704-aa18-22dc6c93f4f3",
      "name": "Pinecone Vector Store7",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1840,
        2592
      ],
      "id": "4748d098-5681-43a1-ab61-f0d046d9d46b",
      "name": "Embeddings OpenAI7",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        1840,
        2416
      ],
      "id": "9cb50b3b-8a12-4fc1-807d-e12e84eebe45",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse_TOC_JSON (FIXED - Properly handles new repo GitHub config)\nconst rawOutput = $input.first().json.output;\nlet tocData;\n\n// ============================================\n// STEP 1: Parse the TOC JSON from AI output\n// ============================================\ntry {\n  if (typeof rawOutput === 'string') {\n    let cleanJson = rawOutput\n      .replace(/```json\\n?/g, '')\n      .replace(/```\\n?/g, '')\n      .trim();\n    \n    const jsonStart = cleanJson.indexOf('{');\n    const jsonEnd = cleanJson.lastIndexOf('}');\n    \n    if (jsonStart !== -1 && jsonEnd !== -1) {\n      cleanJson = cleanJson.substring(jsonStart, jsonEnd + 1);\n    }\n    \n    tocData = JSON.parse(cleanJson);\n  } else {\n    tocData = rawOutput;\n  }\n\n  // Validate TOC structure\n  if (!tocData.sections || !Array.isArray(tocData.sections)) {\n    throw new Error('Invalid TOC structure: missing sections array');\n  }\n\n  if (tocData.sections.length < 1) {\n    throw new Error('TOC must have at least 1 section');\n  }\n\n  console.log('‚úÖ Successfully parsed TOC with', tocData.sections.length, 'sections');\n\n} catch (error) {\n  console.error('‚ùå TOC Parsing Error:', error.message);\n  console.error('Raw output:', rawOutput);\n  throw new Error(`Failed to parse TOC: ${error.message}`);\n}\n\n// ============================================\n// STEP 2: Get GitHub Configuration (FIXED)\n// ============================================\nlet github = null;\n\nconsole.log('\\nüîç Starting GitHub config search...');\n\n// üî• PRIORITY 1: Check if TOC_Generator_Agent received new repo config from Prepare_For_TOC_Generation\ntry {\n  const inputData = $input.first().json;\n  \n  if (inputData.github && inputData.usingNewRepo) {\n    github = inputData.github;\n    console.log('‚úÖ Using NEWLY CREATED repository from TOC Generator input:', github.repo);\n    console.log('üì¶ Owner:', github.owner);\n    console.log('üåø Branch:', github.branch);\n    console.log('üìÇ Base path:', github.basePath);\n    console.log('üîó URL:', github.repoUrl);\n  }\n} catch (e) {\n  console.log('‚ÑπÔ∏è No new repo in TOC Generator input:', e.message);\n}\n\n// Priority 2: Check Prepare_For_TOC_Generation node directly\nif (!github) {\n  try {\n    const prepareNode = $('Prepare_For_TOC_Generation');\n    \n    if (prepareNode && prepareNode.first() && prepareNode.first().json) {\n      const prepareData = prepareNode.first().json;\n      \n      if (prepareData.usingNewRepo && prepareData.github) {\n        github = prepareData.github;\n        console.log('‚úÖ Using repository from Prepare_For_TOC_Generation:', github.repo);\n        console.log('üì¶ Owner:', github.owner);\n        console.log('üåø Branch:', github.branch);\n        console.log('üìÇ Base path:', github.basePath);\n      }\n    }\n  } catch (e) {\n    console.log('‚ÑπÔ∏è Prepare_For_TOC_Generation not available:', e.message);\n  }\n}\n\n// Priority 3: Check Store_New_Repo_Info node\nif (!github) {\n  try {\n    const repoNode = $('Store_New_Repo_Info');\n    \n    if (repoNode && repoNode.first() && repoNode.first().json) {\n      const repoData = repoNode.first().json;\n      \n      if (repoData.github && repoData.repoCreated) {\n        github = repoData.github;\n        console.log('‚úÖ Using repository from Store_New_Repo_Info:', github.repo);\n        console.log('üì¶ Owner:', github.owner);\n        console.log('üåø Branch:', github.branch);\n        console.log('üìÇ Base path:', github.basePath);\n      }\n    }\n  } catch (e) {\n    console.log('‚ÑπÔ∏è Store_New_Repo_Info not available:', e.message);\n  }\n}\n\n// Priority 4: Fallback to default hardcoded repository\nif (!github) {\n  console.log('‚ÑπÔ∏è No new repo detected, using DEFAULT repository');\n  \n  const GITHUB_OWNER = 'codewithshahzaib';\n  const GITHUB_REPO = 'Documentation_Upload_Project';\n  const documentTitle = tocData.documentTitle || 'technical_document';\n  const timestamp = Date.now();\n  \n  // Create a safe folder name from document title\n  const docTitle = documentTitle\n    .replace(/[^a-zA-Z0-9]/g, '_')\n    .toLowerCase()\n    .substring(0, 50);\n  \n  const repoFolderName = `${docTitle}_${timestamp}`;\n  \n  github = {\n    owner: GITHUB_OWNER,\n    repo: GITHUB_REPO,\n    branch: 'main',\n    basePath: repoFolderName,\n    repoUrl: `https://github.com/${GITHUB_OWNER}/${GITHUB_REPO}`,\n    rawBaseUrl: `https://raw.githubusercontent.com/${GITHUB_OWNER}/${GITHUB_REPO}/main/${repoFolderName}`,\n    isNewRepo: false\n  };\n  \n  console.log('üì¶ Using DEFAULT repository:', GITHUB_REPO);\n  console.log('üìÇ Creating folder:', repoFolderName);\n}\n\n// Validate GitHub config\nif (!github || !github.owner || !github.repo) {\n  throw new Error('‚ùå Invalid GitHub configuration! Missing owner or repo.');\n}\n\nconsole.log('\\nüéØ FINAL GitHub Config:');\nconsole.log('   Owner:', github.owner);\nconsole.log('   Repo:', github.repo);\nconsole.log('   Base Path:', github.basePath);\nconsole.log('   Is New Repo:', github.isNewRepo || false);\nconsole.log('   Repo URL:', github.repoUrl);\n\n// ============================================\n// STEP 3: Prepare Document Metadata\n// ============================================\nconst chatId = $('Load Chat History').first().json.chatId;\nconst userMessage = $('Load Chat History').first().json.userMessage;\n\nconst metadata = {\n  documentTitle: tocData.documentTitle || 'Technical Documentation',\n  documentType: tocData.documentType || 'Technical Document',\n  targetAudience: tocData.targetAudience || 'Technical Teams',\n  totalSections: tocData.sections.length,\n  chatId: chatId,\n  userRequest: userMessage,\n  github: github  // ‚≠ê CRITICAL: Include GitHub config in metadata\n};\n\nconsole.log('üìÑ Document Metadata:', {\n  title: metadata.documentTitle,\n  type: metadata.documentType,\n  sections: metadata.totalSections,\n  repoUsing: github.repo,\n  isNewRepo: github.isNewRepo || false\n});\n\n// ============================================\n// STEP 4: Map Sections with Complete Metadata\n// ============================================\nconst outputSections = tocData.sections.map((section, index) => {\n  const sectionNumber = section.sectionNumber || (index + 1).toString();\n  const title = section.title || `Section ${index + 1}`;\n  \n  console.log(`üìù Section ${index + 1}:`, { sectionNumber, title });\n  \n  return {\n    json: {\n      // Section-specific data\n      sectionNumber: sectionNumber,\n      title: title,\n      description: section.description || '',\n      keyTopics: section.keyTopics || [],\n      estimatedLength: section.estimatedLength || '3-5 paragraphs',\n      sectionIndex: index,\n      \n      // Document-level metadata\n      documentTitle: metadata.documentTitle,\n      documentType: metadata.documentType,\n      targetAudience: metadata.targetAudience,\n      chatId: metadata.chatId,\n      userRequest: metadata.userRequest,\n      totalSections: metadata.totalSections,\n      \n      // ‚≠ê CRITICAL: GitHub configuration\n      github: github,\n      \n      // Complete metadata object for reference\n      documentMetadata: metadata\n    }\n  };\n});\n\n// ============================================\n// STEP 5: Final Validation & Return\n// ============================================\nconsole.log('‚úÖ Successfully prepared', outputSections.length, 'sections for processing');\nconsole.log('üéØ Each section contains:');\nconsole.log('   - Section metadata (number, title, description)');\nconsole.log('   - Document metadata (title, type, audience)');\nconsole.log('   - GitHub config (owner, repo, basePath)');\nconsole.log('   - User context (chatId, userRequest)');\n\n// Verify first section has all required data\nconst firstSection = outputSections[0].json;\nconst requiredFields = ['sectionNumber', 'title', 'github', 'documentTitle', 'chatId'];\nconst missingFields = requiredFields.filter(field => !firstSection[field]);\n\nif (missingFields.length > 0) {\n  console.warn('‚ö†Ô∏è Warning: Missing fields in section data:', missingFields);\n}\n\n// Final verification of GitHub config\nif (firstSection.github.repo !== github.repo) {\n  console.error('‚ùå GitHub config mismatch!');\n  console.error('Expected:', github.repo);\n  console.error('Got:', firstSection.github.repo);\n  throw new Error('GitHub configuration was not properly passed to sections!');\n}\n\nconsole.log('\\n‚úÖ VERIFICATION PASSED - All sections have correct GitHub config');\nconsole.log('üìå Target Repository:', github.repo);\nconsole.log('üìå Is New Repo:', github.isNewRepo ? 'YES' : 'NO (using default)');\n\nreturn outputSections;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2320,
        2176
      ],
      "id": "2f11a8b2-e61e-4b09-b6c3-98b5f7dfa6e6",
      "name": "Parse_TOC_JSON"
    },
    {
      "parameters": {
        "options": {
          "reset": false
        }
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        2944,
        2176
      ],
      "id": "f569b620-fd75-40e8-b773-489446aeb196",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=System Role Definition\n\nYou are an Enterprise Architect and Technical Mentor with over 30 years of experience designing and documenting large-scale enterprise systems. You are responsible for writing one specific section of a larger multi-section technical document.\n\nYour goal is to produce a professionally written, technically detailed, and enterprise-quality section according to the specifications below.\n\nDocument Context\n\nDocument Title: {{ $json.documentTitle }}\nDocument Type: {{ $json.documentType }}\nTarget Audience: {{ $json.targetAudience }}\nTotal Sections: {{ $json.totalSections }}\n\nCurrent Section Details\n\nSection Number: {{ $json.sectionNumber }}\nSection Title: {{ $json.title }}\nSection Description: {{ $json.description }}\nKey Topics: {{ $json.keyTopics }}\nTarget Length: {{ $json.estimatedLength }}\n\nOriginal User Request:\n{{ $json.userRequest }}\n\nWriting Instructions\n\n1. Scope\n\n- Write only this section ‚Äî do not include table of contents, introduction, or other sections.\n- Treat it as self-contained but use an enterprise technical tone.\n- Ensure value for both technical and leadership audiences.\n\n2. Section Structure\n\nFollow this exact Markdown layout:\n\n## {{ $json.sectionNumber }}. {{ $json.title }}\n\n[Opening paragraph ‚Äì 4‚Äì5 sentences]\n\n### {{ $json.sectionNumber }}.1 [First Subsection Title]\n\n[5‚Äì6 sentences]\n\n### {{ $json.sectionNumber }}.2 [Second Subsection Title]\n\n[5‚Äì6 sentences]\n\n### {{ $json.sectionNumber }}.3 [Third Subsection Title]\n\n[5‚Äì6 sentences]\n\nKey Considerations:\n\nSecurity: [2‚Äì3 sentences]\n\nScalability: [2‚Äì3 sentences]\n\nCompliance: [2‚Äì3 sentences]\n\nIntegration: [2‚Äì3 sentences]\n\nBest Practices:\n\n[Practice 1]\n\n[Practice 2]\n\n[Practice 3]\n\nNote: [Optional insight]\n\n3. Technical Quality Requirements\n\n- Minimum 5‚Äì7 detailed paragraphs, 4‚Äì6 sentences each.\n- Enterprise tone.\n- Include architecture frameworks (TOGAF, Zero Trust, ITIL, DevSecOps, etc.).\n- No code snippets.\n- Clean, consistent Markdown.\n\n4. Flow Diagrams (SVG-Based) ‚Äî ENFORCED\nNOTICE:\n**All ampersands (&) in attributes, text, and data must be escaped as &amp;**. Unescaped & characters are forbidden.\n- Include a diagram if it improves comprehension.\n- When no diagram is needed:\n{\n  \"diagramData\": {\n    \"hasDiagram\": false\n  }\n}\n- When a diagram is required:\n{\n  \"diagramData\": {\n    \"hasDiagram\": true,\n    \"svg\": \"<svg ...>...</svg>\"\n  }\n}\n\nSVG Requirements (Strict):\n\n- Must be valid inline SVG/XML.\n- Must parse without errors.\n- **All ampersands (&) in attributes, text, and data must be escaped as &amp;**. Unescaped & characters are forbidden.\n- No external CSS or assets; all styling must be inline.\n- Use standard flowchart shapes:\n    - Rounded rectangle = Start/End\n    - Rectangle = Process\n    - Diamond = Decision\n- Include arrow markers (<defs>, <marker>, marker-end).\n- Maximum 8‚Äì10 nodes.\n- Clear top-to-bottom or left-to-right layout.\n- All shapes and connectors must have unique IDs.\n- Include <desc> for accessibility and role=\"img\".\n- When generating the SVG, explicitly **replace every `&` with `&amp;`**.\n- If a diagram is included, it must contain at least:\n    - One arrow marker\n    - One start or end rounded rectangle\n    - One process rectangle\n    - One decision diamond (if branching)\n\nIMPORTANT: Before finalizing the JSON output, ensure that the SVG content is fully XML-valid:\n- Replace every `&` with `&amp;`.\n- Validate that all tags are properly closed.\n- Validate that all IDs are unique.\n- Ensure proper nesting of elements.\n\n5. Research & Validation Strategy\n\n- Review industry standards, UAE DPA, GDPR, ISO 27001, and frameworks relevant to {{ $json.title }}.\n- Ensure all recommendations match enterprise architecture best practices.\n\n6. Output Format\n\nReturn valid JSON:\n\n{\n  \"sectionNumber\": \"{{ $json.sectionNumber }}\",\n  \"title\": \"{{ $json.title }}\",\n  \"content\": \"<Markdown content>\",\n  \"diagramData\": {\n    \"hasDiagram\": true/false,\n    \"svg\": \"<svg>...</svg>\"\n  }\n}\n\nCRITICAL:\n\n- Always include diagramData.\n- If hasDiagram is true ‚Üí SVG is mandatory and must be valid XML.\n- Ensure all & characters in the SVG are escaped as &amp;.\n",
        "hasOutputParser": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        3904,
        2176
      ],
      "id": "8af4f5eb-f3e3-498c-8306-bb06e4fe153c",
      "name": "Section_Detail_Generator_Agent",
      "executeOnce": false
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3904,
        2384
      ],
      "id": "455e9e22-2ce3-43c2-88ef-e3c940529ea8",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        4096,
        2656
      ],
      "id": "a83b2e51-fb44-40af-9c5c-5d92f2607cf4",
      "name": "Embeddings OpenAI8",
      "credentials": {
        "openAiApi": {
          "id": "bJmBsCI3C8E5V3o0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a Master Technical Architect and Documentation Planner with 30+ years of enterprise experience.\n\n(Very Important )\n{Generate at max 3-4 sections as it is currently in testing stage for now only generate 4-5 sections table of content}\n\n**Chat History:**\n{{ $('Load Chat History').first().json.chatHistory }}\n\n**User Request:**\n{{ $('Load Chat History').first().json.userMessage }} || {{ $('Transcribes Audio1').first().json.text }}\n\n**Your Mission:**\nAnalyze the user's request and generate a comprehensive, topic-specific Table of Contents (TOC) for a professional technical document. The sections must be DYNAMICALLY TAILORED to the specific topic requested‚Äîdo NOT use generic templates.\n\n---\n\n## CRITICAL RULES\n\n**MASTER RULE #1: Dynamic Section Generation**\n- Read and understand what the user is ACTUALLY asking for\n- Generate sections that are SPECIFIC to the topic\n- DO NOT use a fixed template or hardcoded section list\n- Each document type requires different sections\n\n**Examples:**\n\n*User asks: \"Create OCR pipeline architecture document\"*\n‚Üí Sections might include: Executive Summary, OCR Technology Overview, Pipeline Architecture, Processing Stages, Model Selection, Performance Optimization, Deployment Strategies, Monitoring & Observability, etc.\n\n*User asks: \"Write API integration guide for payment gateway\"*\n‚Üí Sections might include: Introduction, Prerequisites, Authentication Flow, API Endpoints Reference, Request/Response Examples, Error Handling, Testing Guide, Security Best Practices, etc.\n\n*User asks: \"Document our data governance framework\"*\n‚Üí Sections might include: Governance Overview, Regulatory Compliance, Data Classification, Access Control Policies, Audit Requirements, Incident Response, etc.\n\n**MASTER RULE #2: Security by Design**\nEvery document must have at least ONE section dedicated to security/compliance considerations appropriate to the topic.\n\n**MASTER RULE #3: Enterprise Scalability**\nConsider sections that address:\n- Both SMB (CPU-optimized) and Enterprise/LE (GPU-optimized) scenarios where relevant\n- Scalability and performance considerations\n- Integration touchpoints\n\n**MASTER RULE #4: Compliance First**\nFor UAE enterprise clients, ensure compliance-related sections are included when relevant:\n- Data residency requirements\n- PII handling\n- Audit trails\n- Regulatory frameworks\n\n---\n\n## Document Type Analysis\n\n**Step 1: Identify Document Type from User Request**\n\nDetermine what the user is asking for:\n- üèóÔ∏è Architecture Document (HLD/LLD)\n- üìã Requirements Document (PRD/BRD)\n- üìò Implementation Guide / How-To\n- üìä Technical Specification\n- üîê Security/Compliance Framework\n- üìà Business/Strategy Document\n- üîß Operational Runbook\n- üìö API Documentation\n- üß™ Testing Strategy\n- Other (be flexible!)\n\n**Step 2: Determine Appropriate Section Structure**\n\nBased on the document type identified, generate sections that make sense:\n\n### Architecture Documents Typically Need:\n- Executive Summary / Abstract\n- Business Context & Objectives\n- Architecture Overview (high-level diagrams)\n- Component Breakdown\n- Data Flow & Integration Points\n- Security Architecture\n- Scalability & Performance\n- Deployment Models\n- Monitoring & Operations\n- Future Considerations\n\n### Implementation Guides Typically Need:\n- Introduction & Purpose\n- Prerequisites & Requirements\n- Environment Setup\n- Step-by-Step Implementation\n- Configuration Details\n- Testing & Validation\n- Troubleshooting Common Issues\n- Best Practices & Tips\n- Next Steps\n\n### Technical Specifications Typically Need:\n- Specification Overview\n- Functional Requirements\n- Technical Requirements\n- System Interfaces (APIs, protocols)\n- Data Models & Schemas\n- Performance Criteria\n- Security Requirements\n- Acceptance Criteria\n- Appendices (glossary, references)\n\n### API Documentation Typically Needs:\n- API Overview\n- Authentication & Authorization\n- Endpoint Reference (grouped by resource)\n- Request/Response Examples\n- Error Codes & Handling\n- Rate Limiting & Quotas\n- SDKs & Libraries\n- Changelog & Versioning\n\n**Step 3: Customize Sections for the Specific Topic**\n\nDon't just use generic templates. Ask yourself:\n- What specific aspects of THIS topic need to be covered?\n- What would a technical team need to know about THIS specific subject?\n- What are the unique challenges or considerations for THIS use case?\n\n---\n\n## Output Format Requirements\n\nGenerate ONLY a JSON object with this EXACT structure (no markdown, no explanations, no additional text):\n```json\n{\n  \"documentTitle\": \"Clear, specific title that reflects the actual topic\",\n  \"documentType\": \"HLD|LLD|PRD|Implementation Guide|Technical Spec|etc.\",\n  \"targetAudience\": \"Who will read this (e.g., DevOps Engineers, Technical Leads, C-Suite, etc.)\",\n  \"topicAnalysis\": \"One sentence describing what this document is about\",\n  \"sections\": [\n    {\n      \"sectionNumber\": \"1\",\n      \"title\": \"Topic-Specific Section Title\",\n      \"description\": \"Detailed 2-3 sentence description of what this section will cover, tailored to the actual topic\",\n      \"keyTopics\": [\"specific topic 1\", \"specific topic 2\", \"specific topic 3\"],\n      \"estimatedLength\": \"2-3 paragraphs (or more detailed estimate)\",\n      \"rationale\": \"Why this section is important for THIS specific document\"\n    },\n    {\n      \"sectionNumber\": \"2\",\n      \"title\": \"Next Logical Section\",\n      \"description\": \"...\",\n      \"keyTopics\": [...],\n      \"estimatedLength\": \"...\",\n      \"rationale\": \"...\"\n    }\n  ],\n  \"enterpriseConsiderations\": {\n    \"securitySections\": [\"List section numbers that cover security\"],\n    \"complianceSections\": [\"List section numbers that cover compliance\"],\n    \"scalabilitySections\": [\"List section numbers that cover scalability\"]\n  }\n}\n```\n\n---\n\n## Search Strategy\n\nBefore generating the TOC, use the document search tool to:\n\n1. **Find Related Documents:**\n   - Search for existing documentation on similar topics\n   - Identify what sections were used in comparable documents\n   - Learn from the structure of well-organized documents\n\n2. **Understand Domain-Specific Requirements:**\n   - Search for technical specifications related to the topic\n   - Find compliance requirements that should be addressed\n   - Identify industry best practices for this type of document\n\n3. **Validate Section Relevance:**\n   - Ensure proposed sections align with available information\n   - Check if source documents support the planned structure\n   - Identify gaps that need to be addressed\n\n**Example Searches:**\n- If user asks about \"OCR pipeline\" ‚Üí Search: \"OCR architecture\", \"document processing pipeline\", \"vision models\"\n- If user asks about \"API integration\" ‚Üí Search: \"API design best practices\", \"authentication methods\", \"integration patterns\"\n- If user asks about \"compliance framework\" ‚Üí Search: \"UAE data governance\", \"compliance requirements\", \"audit frameworks\"\n\n---\n\n## Quality Validation Checklist\n\nBefore outputting the TOC JSON, validate:\n\n‚úÖ **Relevance:**\n- [ ] All sections are directly relevant to the user's specific request\n- [ ] No generic filler sections that don't add value\n- [ ] Section titles are specific, not vague\n\n‚úÖ **Completeness:**\n- [ ] Minimum 5-8 major sections (adjust based on topic complexity)\n- [ ] At least ONE section covers security/compliance where applicable\n- [ ] Logical progression from overview ‚Üí details ‚Üí implementation/operations\n\n‚úÖ **Enterprise Standards:**\n- [ ] Scalability considerations included where relevant\n- [ ] Integration touchpoints addressed\n- [ ] UAE compliance needs considered for sensitive topics\n\n‚úÖ **Clarity:**\n- [ ] Each section has a clear 2-3 sentence description\n- [ ] Key topics list is specific and actionable\n- [ ] Rationale explains WHY this section matters for THIS document\n\n‚úÖ **JSON Structure:**\n- [ ] Valid JSON syntax (no trailing commas, proper quotes)\n- [ ] All required fields present\n- [ ] Section numbers are sequential (1, 2, 3...)\n\n---\n\n## Example Outputs (For Reference Only - Yours Should Be Topic-Specific!)\n\n### Example 1: User Request = \"Document our real-time fraud detection system\"\n```json\n{\n  \"documentTitle\": \"Real-Time Fraud Detection System - Technical Architecture\",\n  \"documentType\": \"High-Level Design (HLD)\",\n  \"targetAudience\": \"Engineering Teams, Security Architects, ML Engineers\",\n  \"topicAnalysis\": \"Comprehensive architecture documentation for a real-time ML-based fraud detection system\",\n  \"sections\": [\n    {\n      \"sectionNumber\": \"1\",\n      \"title\": \"System Overview and Business Context\",\n      \"description\": \"Overview of the fraud detection system's purpose, business drivers for real-time detection, and key stakeholders. Covers the types of fraud being detected and the financial impact of detection delays.\",\n      \"keyTopics\": [\"fraud types\", \"business impact\", \"real-time requirements\", \"stakeholder needs\"],\n      \"estimatedLength\": \"3-4 paragraphs\",\n      \"rationale\": \"Establishes business context and justifies architectural decisions\"\n    },\n    {\n      \"sectionNumber\": \"2\",\n      \"title\": \"Real-Time Processing Architecture\",\n      \"description\": \"Detailed architecture for ingesting, processing, and scoring transactions in real-time. Covers streaming data pipelines, event processing, and sub-second latency requirements. Includes diagrams showing data flow from transaction initiation to fraud verdict.\",\n      \"keyTopics\": [\"stream processing\", \"Kafka/event streams\", \"latency requirements\", \"data ingestion\"],\n      \"estimatedLength\": \"5-6 paragraphs with architecture diagrams\",\n      \"rationale\": \"Core technical architecture enabling real-time fraud detection\"\n    },\n    {\n      \"sectionNumber\": \"3\",\n      \"title\": \"Machine Learning Models and Feature Engineering\",\n      \"description\": \"ML models used for fraud detection (supervised, unsupervised, ensemble methods), feature engineering pipeline, model training infrastructure, and online inference serving. Covers model versioning and A/B testing strategies.\",\n      \"keyTopics\": [\"ML models\", \"feature engineering\", \"model serving\", \"inference latency\"],\n      \"estimatedLength\": \"6-7 paragraphs\",\n      \"rationale\": \"ML is the core intelligence of the fraud detection system\"\n    },\n    {\n      \"sectionNumber\": \"4\",\n      \"title\": \"Rules Engine and Hybrid Detection Approach\",\n      \"description\": \"Integration of rule-based fraud detection with ML-based detection. Covers rules engine architecture, rule versioning, business user interface for rule management, and orchestration between rules and ML models.\",\n      \"keyTopics\": [\"rules engine\", \"hybrid approach\", \"rule management\", \"orchestration\"],\n      \"estimatedLength\": \"4-5 paragraphs\",\n      \"rationale\": \"Many fraud systems use hybrid ML + rules approach for flexibility\"\n    },\n    {\n      \"sectionNumber\": \"5\",\n      \"title\": \"Security and Compliance Framework\",\n      \"description\": \"Security architecture for handling sensitive transaction data, PII protection, encryption at rest and in transit, UAE compliance requirements for financial data, and audit logging for fraud investigation.\",\n      \"keyTopics\": [\"data security\", \"PII handling\", \"UAE compliance\", \"audit trails\"],\n      \"estimatedLength\": \"5-6 paragraphs\",\n      \"rationale\": \"Critical for UAE enterprise deployments handling financial data\"\n    },\n    {\n      \"sectionNumber\": \"6\",\n      \"title\": \"Scalability and Performance Optimization\",\n      \"description\": \"Strategies for scaling the system to handle peak transaction volumes, performance benchmarks for SMB vs enterprise deployments, caching strategies, and database optimization for high-throughput operations.\",\n      \"keyTopics\": [\"horizontal scaling\", \"performance tuning\", \"caching\", \"load testing\"],\n      \"estimatedLength\": \"4-5 paragraphs\",\n      \"rationale\": \"System must handle Black Friday-level transaction spikes\"\n    },\n    {\n      \"sectionNumber\": \"7\",\n      \"title\": \"Monitoring, Alerting, and Model Observability\",\n      \"description\": \"Real-time monitoring of system health, model performance metrics, alert thresholds for fraud spike detection, dashboards for fraud analysts, and model drift detection mechanisms.\",\n      \"keyTopics\": [\"monitoring\", \"alerting\", \"model observability\", \"dashboards\"],\n      \"estimatedLength\": \"4-5 paragraphs\",\n      \"rationale\": \"Operational excellence requires comprehensive monitoring\"\n    },\n    {\n      \"sectionNumber\": \"8\",\n      \"title\": \"Deployment Architecture and DR Strategy\",\n      \"description\": \"Multi-region deployment for high availability, disaster recovery strategy, failover mechanisms, and deployment pipelines for model and rule updates without downtime.\",\n      \"keyTopics\": [\"multi-region\", \"disaster recovery\", \"high availability\", \"CI/CD\"],\n      \"estimatedLength\": \"4-5 paragraphs\",\n      \"rationale\": \"Fraud detection systems require 99.99% uptime\"\n    }\n  ],\n  \"enterpriseConsiderations\": {\n    \"securitySections\": [\"5\"],\n    \"complianceSections\": [\"5\"],\n    \"scalabilitySections\": [\"2\", \"6\"]\n  }\n}\n```\n\n### Example 2: User Request = \"Create developer onboarding guide\"\n```json\n{\n  \"documentTitle\": \"Developer Onboarding Guide - Getting Started\",\n  \"documentType\": \"Implementation Guide\",\n  \"targetAudience\": \"New Software Engineers, Junior Developers, Contractors\",\n  \"topicAnalysis\": \"Step-by-step guide for new developers joining the engineering team\",\n  \"sections\": [\n    {\n      \"sectionNumber\": \"1\",\n      \"title\": \"Welcome and Team Introduction\",\n      \"description\": \"Welcome message, team structure overview, key contacts, communication channels (Slack, email), and an introduction to the company's engineering culture and values.\",\n      \"keyTopics\": [\"team structure\", \"communication\", \"culture\", \"contacts\"],\n      \"estimatedLength\": \"2-3 paragraphs\",\n      \"rationale\": \"Sets expectations and helps new developers feel welcomed\"\n    },\n    {\n      \"sectionNumber\": \"2\",\n      \"title\": \"Development Environment Setup\",\n      \"description\": \"Step-by-step instructions for setting up local development environment, installing required tools (IDE, Docker, Git), configuring SSH keys, and accessing development infrastructure.\",\n      \"keyTopics\": [\"IDE setup\", \"Docker installation\", \"Git configuration\", \"SSH keys\"],\n      \"estimatedLength\": \"6-8 paragraphs with commands\",\n      \"rationale\": \"Critical first step for developer productivity\"\n    },\n    {\n      \"sectionNumber\": \"3\",\n      \"title\": \"Codebase Overview and Architecture\",\n      \"description\": \"High-level overview of the codebase structure, key repositories, microservices architecture, technology stack, and design patterns used throughout the system.\",\n      \"keyTopics\": [\"repository structure\", \"microservices\", \"tech stack\", \"design patterns\"],\n      \"estimatedLength\": \"5-6 paragraphs with diagrams\",\n      \"rationale\": \"Helps developers understand the system before diving into code\"\n    },\n    {\n      \"sectionNumber\": \"4\",\n      \"title\": \"Development Workflow and Git Practices\",\n      \"description\": \"Git branching strategy, pull request process, code review guidelines, commit message conventions, and CI/CD pipeline overview for automated testing and deployment.\",\n      \"keyTopics\": [\"Git workflow\", \"PR process\", \"code reviews\", \"CI/CD\"],\n      \"estimatedLength\": \"5-6 paragraphs\",\n      \"rationale\": \"Ensures consistent development practices across the team\"\n    },\n    {\n      \"sectionNumber\": \"5\",\n      \"title\": \"Testing and Quality Assurance\",\n      \"description\": \"Testing philosophy, unit testing requirements, integration testing setup, end-to-end testing framework, and code coverage expectations.\",\n      \"keyTopics\": [\"unit tests\", \"integration tests\", \"E2E testing\", \"code coverage\"],\n      \"estimatedLength\": \"4-5 paragraphs\",\n      \"rationale\": \"Quality is non-negotiable in enterprise systems\"\n    },\n    {\n      \"sectionNumber\": \"6\",\n      \"title\": \"First Tasks and Learning Resources\",\n      \"description\": \"Suggested starter tasks for new developers, onboarding projects, recommended learning resources (documentation, tutorials, internal wikis), and mentorship program details.\",\n      \"keyTopics\": [\"starter tasks\", \"onboarding projects\", \"learning resources\", \"mentorship\"],\n      \"estimatedLength\": \"3-4 paragraphs\",\n      \"rationale\": \"Provides clear next steps for new developers\"\n    }\n  ],\n  \"enterpriseConsiderations\": {\n    \"securitySections\": [\"2\"],\n    \"complianceSections\": [],\n    \"scalabilitySections\": [\"3\"]\n  }\n}\n```\n\n---\n\n## CRITICAL FINAL REMINDERS\n\n1. **DO NOT** copy the examples above‚Äîthey are for inspiration only\n2. **DO** analyze what the user ACTUALLY asked for\n3. **DO** generate sections specific to the topic\n4. **DO** use the search tool to find relevant context\n5. **DO** output ONLY valid JSON (no markdown, no extra text)\n\n**Now analyze the user's request and generate a topic-specific, comprehensive TOC in JSON format:**",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1936,
        2176
      ],
      "id": "cdf8eb1f-5403-48f5-8b1f-ea63a6321dc4",
      "name": "TOC_Generator_Agent",
      "executeOnce": false
    },
    {
      "parameters": {
        "content": "Document Generation Agent",
        "height": 672,
        "width": 4528,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1296,
        2144
      ],
      "typeVersion": 1,
      "id": "97077dd8-c905-4f2e-841b-41fe888f7d55",
      "name": "Sticky Note7"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "name": "Replace Me",
      "typeVersion": 1,
      "position": [
        3360,
        2256
      ],
      "id": "9afee27d-0d65-4304-a21e-6ea2f2108f08"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Search through documents using semantic similarity. Returns top 15 most relevant document chunks.",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "topK": 15,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        4096,
        2496
      ],
      "id": "b62ea270-dd03-42d9-b99e-bc678dbfa2c5",
      "name": "Pinecone Vector Store8",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"sectionNumber\": \"string\",\n  \"title\": \"string\",\n  \"content\": \"string\",\n  \"diagramData\": {\n      \"hasDiagram\": \"boolean\",\n      \"svg\": \"string\"\n  }\n}\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        4416,
        2608
      ],
      "id": "e70365fa-d389-4f85-863f-9d963d23de19",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "jsCode": "// Node 2: Parse_Sections_to_Structured_JSON (WITH URL SUPPORT)\n// Place this AFTER Collect_Section_Results\n\nconst collectedData = $input.first().json;\nconst sections = collectedData.sections || [];\n\nconsole.log(`üîß Parsing ${sections.length} sections into structured JSON`);\n\n// Main parsing function\nfunction parseSection(rawContent, sectionNumber) {\n  if (!rawContent || typeof rawContent !== 'string' || rawContent.trim().length === 0) {\n    console.log(`‚ö†Ô∏è Section ${sectionNumber}: No valid content to parse`);\n    return null;\n  }\n\n  console.log(`\\nüîç Parsing section ${sectionNumber}, length: ${rawContent.length}`);\n\n  const result = {\n    title: '',\n    content: '',\n    url: '',\n    subsections: {}\n  };\n\n  // Extract main section header (## 1. Title)\n  const mainHeaderRegex = /^##\\s+(\\d+(?:\\.\\d+)?)\\.\\s+(.+?)$/m;\n  const mainHeaderMatch = rawContent.match(mainHeaderRegex);\n  \n  if (mainHeaderMatch) {\n    result.title = mainHeaderMatch[2].trim();\n    console.log(`  ‚úì Title: \"${result.title}\"`);\n  } else {\n    console.log(`  ‚ö†Ô∏è No main header found`);\n    return null;\n  }\n\n  // Find all subsections (### 1.1 Title)\n  const subsectionRegex = /###\\s+([\\d.]+)\\s+(.+?)$/gm;\n  const subsections = [];\n  let match;\n  \n  while ((match = subsectionRegex.exec(rawContent)) !== null) {\n    subsections.push({\n      number: match[1].trim(),\n      title: match[2].trim(),\n      startIndex: match.index\n    });\n  }\n\n  console.log(`  ‚úì Found ${subsections.length} subsections`);\n\n  // No subsections - all content is main content\n  if (subsections.length === 0) {\n    const headerEnd = mainHeaderMatch.index + mainHeaderMatch[0].length;\n    result.content = rawContent.slice(headerEnd).trim();\n    console.log(`  ‚Üí Main content only: ${result.content.length} chars`);\n    return result;\n  }\n\n  // Extract main content (between header and first subsection)\n  const firstSubStart = subsections[0].startIndex;\n  const headerEnd = mainHeaderMatch.index + mainHeaderMatch[0].length;\n  result.content = rawContent.slice(headerEnd, firstSubStart).trim();\n  console.log(`  ‚Üí Main content: ${result.content.length} chars`);\n\n  // Parse each subsection\n  for (let i = 0; i < subsections.length; i++) {\n    const current = subsections[i];\n    const nextStart = i + 1 < subsections.length \n      ? subsections[i + 1].startIndex \n      : rawContent.length;\n    \n    // Find end of subsection header line\n    const headerLine = rawContent.substring(current.startIndex);\n    const newlineIdx = headerLine.indexOf('\\n');\n    const contentStart = current.startIndex + (newlineIdx !== -1 ? newlineIdx + 1 : 0);\n    \n    const subsectionContent = rawContent.slice(contentStart, nextStart).trim();\n    \n    // Parse subsection content\n    const parsed = parseSubsectionContent(subsectionContent);\n    \n    result.subsections[current.number] = {\n      title: current.title,\n      ...parsed\n    };\n    \n    console.log(`  ‚Üí Subsection ${current.number}: ${subsectionContent.length} chars`);\n  }\n\n  return result;\n}\n\n// Parse subsection content into structured parts\nfunction parseSubsectionContent(content) {\n  const structure = {\n    content: '',\n    keyConsiderations: null,\n    bestPractices: null,\n    notes: null\n  };\n\n  // Find special sections\n  const kcMatch = content.match(/\\*\\*Key Considerations:\\*\\*([\\s\\S]*?)(?=\\*\\*Best Practices:|\\*\\*Note:|$)/);\n  const bpMatch = content.match(/\\*\\*Best Practices:\\*\\*([\\s\\S]*?)(?=>\\s*\\*\\*Note:|$)/);\n  const noteMatch = content.match(/>\\s*\\*\\*Note:\\*\\*([\\s\\S]*?)$/);\n\n  // Main content ends where first special section begins\n  let mainEnd = content.length;\n  if (kcMatch) mainEnd = Math.min(mainEnd, kcMatch.index);\n  else if (bpMatch) mainEnd = Math.min(mainEnd, bpMatch.index);\n  else if (noteMatch) mainEnd = Math.min(mainEnd, noteMatch.index);\n\n  structure.content = content.slice(0, mainEnd).trim();\n\n  // Parse Key Considerations\n  if (kcMatch) {\n    const kcContent = kcMatch[1].trim();\n    structure.keyConsiderations = parseListItems(kcContent);\n  }\n\n  // Parse Best Practices\n  if (bpMatch) {\n    const bpContent = bpMatch[1].trim();\n    structure.bestPractices = parseListItems(bpContent);\n  }\n\n  // Parse Notes\n  if (noteMatch) {\n    structure.notes = noteMatch[1].trim();\n  }\n\n  // Clean up empty fields\n  if (!structure.keyConsiderations) delete structure.keyConsiderations;\n  if (!structure.bestPractices) delete structure.bestPractices;\n  if (!structure.notes) delete structure.notes;\n\n  return structure;\n}\n\n// Parse lists into structured format\nfunction parseListItems(content) {\n  const items = {};\n  \n  // Try structured format (- **Label:** Content)\n  const structuredRegex = /-\\s*\\*\\*([^:]+):\\*\\*\\s*(.+?)(?=\\n-|\\n\\*\\*|$)/gs;\n  let match;\n  \n  while ((match = structuredRegex.exec(content)) !== null) {\n    const key = match[1].trim().toLowerCase().replace(/\\s+/g, '_');\n    items[key] = match[2].trim();\n  }\n\n  if (Object.keys(items).length > 0) {\n    return items;\n  }\n\n  // Fallback: simple list\n  const lines = content.split('\\n')\n    .map(line => line.trim())\n    .filter(line => line.startsWith('-'))\n    .map(line => line.replace(/^-\\s*/, '').trim())\n    .filter(line => line.length > 0);\n  \n  return lines.length > 0 ? lines : null;\n}\n\n// Build structured document\nconst structuredDocument = {\n  metadata: {\n    documentTitle: collectedData.documentTitle,\n    documentType: collectedData.documentType,\n    targetAudience: collectedData.targetAudience,\n    chatId: collectedData.chatId,\n    userRequest: collectedData.userRequest,\n    totalSections: collectedData.totalSections,\n    completeTOC: collectedData.completeTOC,\n    github: collectedData.github,\n    createdAt: new Date().toISOString(),\n    version: '1.0'\n  },\n  sections: {}\n};\n\n// Process each section\nlet successCount = 0;\nlet failCount = 0;\n\nfor (const section of sections) {\n  const sectionNum = section.sectionNumber;\n  \n  if (!section.content || section.content.trim().length === 0) {\n    console.log(`‚ö†Ô∏è Section ${sectionNum}: Empty content, skipping`);\n    failCount++;\n    continue;\n  }\n\n  const parsed = parseSection(section.content, sectionNum);\n\n  if (!parsed || !parsed.title) {\n    console.log(`‚ùå Section ${sectionNum}: Parse failed`);\n    failCount++;\n    continue;\n  }\n\n  // Build section data with URL\n  const sectionData = {\n    title: parsed.title,\n    content: parsed.content,\n    url: section.url || '' // ‚úÖ ADDED: Extract URL from section data\n  };\n\n  // Add subsections if present\n  if (Object.keys(parsed.subsections).length > 0) {\n    sectionData.subsections = parsed.subsections;\n  }\n\n  // Add diagram if present\n  if (section.diagramData && section.diagramData.hasDiagram) {\n    sectionData.diagram = {\n      type: section.diagramData.diagramType || 'flowchart',\n      title: section.diagramData.title || '',\n      nodes: section.diagramData.nodes || [],\n      edges: section.diagramData.edges || []\n    };\n  }\n\n  structuredDocument.sections[sectionNum] = sectionData;\n  successCount++;\n  console.log(`‚úÖ Section ${sectionNum}: Parsed successfully (URL: ${sectionData.url ? '‚úì' : '‚úó'})`);\n}\n\n// Statistics\nconst stats = {\n  totalSections: Object.keys(structuredDocument.sections).length,\n  successCount: successCount,\n  failCount: failCount,\n  sectionsWithSubsections: Object.values(structuredDocument.sections)\n    .filter(s => s.subsections).length,\n  sectionsWithDiagrams: Object.values(structuredDocument.sections)\n    .filter(s => s.diagram).length,\n  sectionsWithUrls: Object.values(structuredDocument.sections)\n    .filter(s => s.url && s.url.length > 0).length,\n  totalSubsections: Object.values(structuredDocument.sections)\n    .reduce((sum, s) => sum + (s.subsections ? Object.keys(s.subsections).length : 0), 0)\n};\n\nconsole.log(`\\nüìä Parsing Complete:`);\nconsole.log(`  ‚úÖ Success: ${stats.successCount}`);\nconsole.log(`  ‚ùå Failed: ${stats.failCount}`);\nconsole.log(`  üìö With subsections: ${stats.sectionsWithSubsections}`);\nconsole.log(`  üîó With URLs: ${stats.sectionsWithUrls}`);\nconsole.log(`  üìä Total subsections: ${stats.totalSubsections}`);\n\n// Prepare GitHub upload\nconst jsonContent = JSON.stringify(structuredDocument, null, 2);\nconst base64Content = Buffer.from(jsonContent).toString('base64');\n\nconst timestamp = new Date().toISOString().split('T')[0];\nconst safeTitle = structuredDocument.metadata.documentTitle.replace(/[^a-zA-Z0-9]/g, '_').toLowerCase();\nconst filename = `${safeTitle}_${timestamp}.json`;\n\nconst githubPayload = {\n  message: `üìÑ ${structuredDocument.metadata.documentTitle} (${stats.totalSections} sections)`,\n  content: base64Content,\n  branch: 'main'\n};\n\n// Return result\nreturn [{\n  json: {\n    structuredDocument: structuredDocument,\n    stats: stats,\n    github: {\n      owner: collectedData.github?.owner || 'codewithshahzaib',\n      repo: collectedData.github?.repo || 'Documentation_Upload_Project',\n      path: `${collectedData.github?.basePath || 'documents'}/${filename}`,\n      payload: githubPayload,\n      rawUrl: `https://raw.githubusercontent.com/${collectedData.github?.owner || 'codewithshahzaib'}/${collectedData.github?.repo || 'Documentation_Upload_Project'}/main/${collectedData.github?.basePath || 'documents'}/${filename}`\n    },\n    documentTitle: structuredDocument.metadata.documentTitle,\n    chatId: structuredDocument.metadata.chatId,\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4688,
        2160
      ],
      "id": "fe686ed2-d6ac-4877-94ee-21a901c3fc5c",
      "name": "Parse_Sections_to_Structured_JSON"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://docs.googleapis.com/v1/documents ",
        "authentication": "genericCredentialType",
        "genericAuthType": "oAuth2Api",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"title\": \"Technical Documentation\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4464,
        2384
      ],
      "id": "fdfabfb8-66f6-42e9-9af4-0c2aa2f40b26",
      "name": "Create Google Doc",
      "credentials": {
        "oAuth2Api": {
          "id": "6VtG2NAOONCkC0aw",
          "name": "Google Drive Docs API Credentials"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Google Docs Document Generator for n8n\n// This node creates a fully formatted Google Doc from structured JSON\n\nconst structuredDoc =$('Parse_Sections_to_Structured_JSON').first().json.structuredDocument;\nconst metadata = structuredDoc.metadata;\n\nconsole.log(`üìÑ Generating Google Docs requests for: ${metadata.documentTitle}`);\n\n// Google Docs API batch requests array\nconst requests = [];\nlet currentIndex = 1; // Start after the title\n\n// Helper: Create text style\nfunction createTextStyle(bold = false, fontSize = 11, namedStyleType = 'NORMAL_TEXT') {\n  return {\n    bold: bold,\n    fontSize: { magnitude: fontSize, unit: 'PT' },\n    weightedFontFamily: { fontFamily: 'Arial' }\n  };\n}\n\n// Helper: Create paragraph style\nfunction createParagraphStyle(namedStyleType = 'NORMAL_TEXT', alignment = 'START', spaceAbove = 0, spaceBelow = 0) {\n  return {\n    namedStyleType: namedStyleType,\n    alignment: alignment,\n    spaceAbove: { magnitude: spaceAbove, unit: 'PT' },\n    spaceBelow: { magnitude: spaceBelow, unit: 'PT' }\n  };\n}\n\n// 1. Insert Document Title\nrequests.push({\n  insertText: {\n    location: { index: 1 },\n    text: `${metadata.documentTitle}\\n\\n`\n  }\n});\n\nrequests.push({\n  updateParagraphStyle: {\n    range: { startIndex: 1, endIndex: metadata.documentTitle.length + 1 },\n    paragraphStyle: createParagraphStyle('TITLE', 'CENTER', 0, 12),\n    fields: 'namedStyleType,alignment,spaceBelow'\n  }\n});\n\ncurrentIndex += metadata.documentTitle.length + 2;\n\n// 2. Insert Document Metadata\nconst metadataText = `Document Type: ${metadata.documentType}\\nTarget Audience: ${metadata.targetAudience}\\nGenerated: ${new Date(metadata.createdAt).toLocaleDateString()}\\n\\n`;\n\nrequests.push({\n  insertText: {\n    location: { index: currentIndex },\n    text: metadataText\n  }\n});\n\nrequests.push({\n  updateTextStyle: {\n    range: { startIndex: currentIndex, endIndex: currentIndex + metadataText.length },\n    textStyle: createTextStyle(false, 10),\n    fields: 'fontSize,weightedFontFamily'\n  }\n});\n\nrequests.push({\n  updateParagraphStyle: {\n    range: { startIndex: currentIndex, endIndex: currentIndex + metadataText.length },\n    paragraphStyle: createParagraphStyle('NORMAL_TEXT', 'CENTER', 0, 12),\n    fields: 'alignment,spaceBelow'\n  }\n});\n\ncurrentIndex += metadataText.length;\n\n// 3. Insert Page Break before content\nrequests.push({\n  insertPageBreak: {\n    location: { index: currentIndex }\n  }\n});\n\ncurrentIndex += 1;\n\n// 4. Process each section\nconst sectionNumbers = Object.keys(structuredDoc.sections).sort((a, b) => {\n  const numA = parseFloat(a);\n  const numB = parseFloat(b);\n  return numA - numB;\n});\n\nfor (const sectionNum of sectionNumbers) {\n  const section = structuredDoc.sections[sectionNum];\n  \n  console.log(`Processing Section ${sectionNum}: ${section.title}`);\n  \n  // Section Header (## X. Title)\n  const sectionHeader = `${sectionNum}. ${section.title}\\n\\n`;\n  const sectionHeaderStart = currentIndex;\n  \n  requests.push({\n    insertText: {\n      location: { index: currentIndex },\n      text: sectionHeader\n    }\n  });\n  \n  requests.push({\n    updateParagraphStyle: {\n      range: { startIndex: sectionHeaderStart, endIndex: sectionHeaderStart + sectionHeader.length },\n      paragraphStyle: createParagraphStyle('HEADING_1', 'START', 12, 6),\n      fields: 'namedStyleType,spaceAbove,spaceBelow'\n    }\n  });\n  \n  currentIndex += sectionHeader.length;\n  \n  // Section Main Content\n  if (section.content && section.content.trim()) {\n    const contentText = `${section.content.trim()}\\n\\n`;\n    \n    requests.push({\n      insertText: {\n        location: { index: currentIndex },\n        text: contentText\n      }\n    });\n    \n    requests.push({\n      updateParagraphStyle: {\n        range: { startIndex: currentIndex, endIndex: currentIndex + contentText.length },\n        paragraphStyle: createParagraphStyle('NORMAL_TEXT', 'START', 0, 6),\n        fields: 'namedStyleType,spaceBelow'\n      }\n    });\n    \n    currentIndex += contentText.length;\n  }\n  \n  // Process Subsections\n  if (section.subsections) {\n    const subsectionNumbers = Object.keys(section.subsections).sort((a, b) => {\n      const partsA = a.split('.').map(Number);\n      const partsB = b.split('.').map(Number);\n      for (let i = 0; i < Math.max(partsA.length, partsB.length); i++) {\n        const diff = (partsA[i] || 0) - (partsB[i] || 0);\n        if (diff !== 0) return diff;\n      }\n      return 0;\n    });\n    \n    for (const subsectionNum of subsectionNumbers) {\n      const subsection = section.subsections[subsectionNum];\n      \n      console.log(`  Processing Subsection ${subsectionNum}: ${subsection.title}`);\n      \n      // Subsection Header (### X.Y Title)\n      const subsectionHeader = `${subsectionNum} ${subsection.title}\\n\\n`;\n      const subsectionHeaderStart = currentIndex;\n      \n      requests.push({\n        insertText: {\n          location: { index: currentIndex },\n          text: subsectionHeader\n        }\n      });\n      \n      requests.push({\n        updateParagraphStyle: {\n          range: { startIndex: subsectionHeaderStart, endIndex: subsectionHeaderStart + subsectionHeader.length },\n          paragraphStyle: createParagraphStyle('HEADING_2', 'START', 8, 4),\n          fields: 'namedStyleType,spaceAbove,spaceBelow'\n        }\n      });\n      \n      currentIndex += subsectionHeader.length;\n      \n      // Subsection Content\n      if (subsection.content && subsection.content.trim()) {\n        const subContentText = `${subsection.content.trim()}\\n\\n`;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: subContentText\n          }\n        });\n        \n        requests.push({\n          updateParagraphStyle: {\n            range: { startIndex: currentIndex, endIndex: currentIndex + subContentText.length },\n            paragraphStyle: createParagraphStyle('NORMAL_TEXT', 'START', 0, 6),\n            fields: 'namedStyleType,spaceBelow'\n          }\n        });\n        \n        currentIndex += subContentText.length;\n      }\n      \n      // Key Considerations\n      if (subsection.keyConsiderations) {\n        const kcHeader = 'Key Considerations:\\n';\n        const kcHeaderStart = currentIndex;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: kcHeader\n          }\n        });\n        \n        requests.push({\n          updateTextStyle: {\n            range: { startIndex: kcHeaderStart, endIndex: kcHeaderStart + kcHeader.length },\n            textStyle: createTextStyle(true, 11),\n            fields: 'bold,fontSize'\n          }\n        });\n        \n        currentIndex += kcHeader.length;\n        \n        // Process Key Considerations items\n        const kcItems = Array.isArray(subsection.keyConsiderations) \n          ? subsection.keyConsiderations \n          : Object.entries(subsection.keyConsiderations);\n        \n        for (const item of kcItems) {\n          let itemText;\n          if (Array.isArray(item)) {\n            itemText = `‚Ä¢ ${item[0]}: ${item[1]}\\n`;\n          } else {\n            itemText = `‚Ä¢ ${item}\\n`;\n          }\n          \n          requests.push({\n            insertText: {\n              location: { index: currentIndex },\n              text: itemText\n            }\n          });\n          \n          currentIndex += itemText.length;\n        }\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: '\\n'\n          }\n        });\n        \n        currentIndex += 1;\n      }\n      \n      // Best Practices\n      if (subsection.bestPractices) {\n        const bpHeader = 'Best Practices:\\n';\n        const bpHeaderStart = currentIndex;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: bpHeader\n          }\n        });\n        \n        requests.push({\n          updateTextStyle: {\n            range: { startIndex: bpHeaderStart, endIndex: bpHeaderStart + bpHeader.length },\n            textStyle: createTextStyle(true, 11),\n            fields: 'bold,fontSize'\n          }\n        });\n        \n        currentIndex += bpHeader.length;\n        \n        // Process Best Practices items\n        const bpItems = Array.isArray(subsection.bestPractices) \n          ? subsection.bestPractices \n          : Object.values(subsection.bestPractices);\n        \n        for (const item of bpItems) {\n          const itemText = `‚Ä¢ ${item}\\n`;\n          \n          requests.push({\n            insertText: {\n              location: { index: currentIndex },\n              text: itemText\n            }\n          });\n          \n          currentIndex += itemText.length;\n        }\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: '\\n'\n          }\n        });\n        \n        currentIndex += 1;\n      }\n      \n      // Notes\n      if (subsection.notes) {\n        const noteText = `üìù Note: ${subsection.notes}\\n\\n`;\n        const noteStart = currentIndex;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: noteText\n          }\n        });\n        \n        requests.push({\n          updateTextStyle: {\n            range: { startIndex: noteStart, endIndex: noteStart + noteText.length },\n            textStyle: {\n              italic: true,\n              fontSize: { magnitude: 10, unit: 'PT' },\n              foregroundColor: { color: { rgbColor: { red: 0.4, green: 0.4, blue: 0.4 } } }\n            },\n            fields: 'italic,fontSize,foregroundColor'\n          }\n        });\n        \n        currentIndex += noteText.length;\n      }\n    }\n  }\n  \n  // Add diagram placeholder if present\n  if (section.diagram) {\n    const diagramNote = `[Diagram: ${section.diagram.title || 'Process Flow'}]\\nDiagram available at: ${metadata.github.rawBaseUrl || 'GitHub repository'}\\n\\n`;\n    const diagramStart = currentIndex;\n    \n    requests.push({\n      insertText: {\n        location: { index: currentIndex },\n        text: diagramNote\n      }\n    });\n    \n    requests.push({\n      updateTextStyle: {\n        range: { startIndex: diagramStart, endIndex: diagramStart + diagramNote.length },\n        textStyle: {\n          italic: true,\n          fontSize: { magnitude: 10, unit: 'PT' },\n          backgroundColor: { color: { rgbColor: { red: 0.95, green: 0.95, blue: 0.95 } } }\n        },\n        fields: 'italic,fontSize,backgroundColor'\n      }\n    });\n    \n    currentIndex += diagramNote.length;\n  }\n  \n  // Add spacing between sections\n  requests.push({\n    insertText: {\n      location: { index: currentIndex },\n      text: '\\n'\n    }\n  });\n  \n  currentIndex += 1;\n}\n\nconsole.log(`‚úÖ Generated ${requests.length} Google Docs API requests`);\n\n// Return the requests array for Google Docs API\nreturn [{\n  json: {\n    requests: requests,\n    documentTitle: metadata.documentTitle,\n    totalRequests: requests.length,\n    chatId: metadata.chatId,\n    metadata: {\n      sections: Object.keys(structuredDoc.sections).length,\n      timestamp: new Date().toISOString()\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4672,
        2384
      ],
      "id": "c76c97aa-7c83-4203-ba0f-e292b4ce65f0",
      "name": "Prepare Google Docs Requests"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://docs.googleapis.com/v1/documents/{{ $('Create Google Doc').item.json.documentId }}:batchUpdate",
        "authentication": "genericCredentialType",
        "genericAuthType": "oAuth2Api",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"requests\": {{ JSON.stringify($json.requests) }}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4880,
        2384
      ],
      "id": "cccf4e98-0169-4640-9c70-ab3d587c7e46",
      "name": "Format Google Doc",
      "credentials": {
        "oAuth2Api": {
          "id": "6VtG2NAOONCkC0aw",
          "name": "Google Drive Docs API Credentials"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const documentId = $('Create Google Doc').first().json.documentId;\nconst documentTitle = $json.documentTitle;\n\nconst docLink = `https://docs.google.com/document/d/${documentId}/edit`;\nconst viewLink = `https://docs.google.com/document/d/${documentId}/view`;\n\nconsole.log(`‚úÖ Document created: ${documentTitle}`);\nconsole.log(`üîó Edit Link: ${docLink}`);\n\nreturn [{\n  json: {\n    documentId: documentId,\n    documentTitle: documentTitle,\n    editLink: docLink,\n    viewLink: viewLink,\n    createdAt: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5088,
        2384
      ],
      "id": "5d06e125-166f-4f37-afec-6561a8422b3f",
      "name": "Generate Document Link"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "={{ $json.url }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.payload) }}",
        "options": {
          "response": {
            "response": {
              "fullResponse": true,
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        5312,
        2160
      ],
      "id": "9f7407b4-9eec-4d3a-a29a-6148ab7b7143",
      "name": "GitHub Upload"
    },
    {
      "parameters": {
        "jsCode": "// Node 1: Collect_Section_Results (WITH URL EXTRACTION)\nconst allSections = $input.all();\n\nif (!allSections || allSections.length === 0) {\n  return [{\n    json: {\n      error: true,\n      message: 'No sections received for collection',\n      sections: []\n    }\n  }];\n}\n\n// Sort by sectionIndex\nallSections.sort((a, b) => (a.json.sectionIndex || 0) - (b.json.sectionIndex || 0));\n\n// Helper: safely parse JSON\nfunction tryParseJSON(data) {\n  if (!data) return null;\n  if (typeof data === 'object') return data;\n  if (typeof data !== 'string') return null;\n  try {\n    const clean = data.replace(/```json\\n?|```/g, '').trim();\n    return JSON.parse(clean);\n  } catch {\n    return null;\n  }\n}\n\n// Try getting github from TOC node\nlet github = null;\ntry {\n  const tocNode = $('Parse_TOC_JSON');\n  if (tocNode?.first()?.json?.github) github = tocNode.first().json.github;\n} catch (e) {}\n\n// Extract content from a section\nfunction extractActualContent(item) {\n  let content = item.json.data?.output?.content;\n\n  if (typeof content === 'string' && content.length > 0 && !content.includes('download_url')) {\n    return content;\n  }\n\n  const rawOutput = item.json.output || item.json.result || item.json.text || '';\n  const parsed = tryParseJSON(rawOutput);\n  if (parsed && parsed.content && typeof parsed.content === 'string') return parsed.content;\n\n  if (typeof rawOutput === 'string' && (rawOutput.includes('##') || rawOutput.includes('###'))) {\n    return rawOutput;\n  }\n\n  return typeof content === 'string' ? content : '';\n}\n\n// Extract URL from section\nfunction extractUrl(item) {\n  return item.json.url || item.json.data?.url || item.json.output?.url || '';\n}\n\n// Collect sections\nconst sectionContents = allSections.map((item, index) => {\n  const actualContent = extractActualContent(item);\n  const sectionUrl = extractUrl(item);\n\n  console.log(`üìÑ Collecting section ${index + 1}:`, {\n    sectionNumber: item.json.sectionNumber,\n    title: item.json.data?.output?.title || item.json.title,\n    contentLength: actualContent.length,\n    hasContent: actualContent.length > 0,\n    hasUrl: !!sectionUrl,\n    url: sectionUrl\n  });\n\n  return {\n    sectionNumber: item.json.sectionNumber || (index + 1).toString(),\n    title: item.json.data?.output?.title || item.json.title || `Section ${index + 1}`,\n    content: actualContent,\n    url: sectionUrl,\n    sectionIndex: item.json.sectionIndex || index,\n    diagramData: item.json.diagramData || { hasDiagram: false },\n    githubUrls: item.json.githubUrls || null\n  };\n});\n\n// Get document metadata from first section\nconst firstItem = allSections[0].json;\nconst metadata = firstItem.documentMetadata || {\n  documentTitle: firstItem.documentTitle || 'Technical Documentation',\n  documentType: firstItem.documentType || 'Technical Document',\n  targetAudience: firstItem.targetAudience || 'Technical Teams',\n  chatId: firstItem.chatId || 'unknown',\n  userRequest: firstItem.userRequest || 'Document generation',\n  totalSections: sectionContents.length,\n  completeTOC: firstItem.completeTOC || null,\n  github: firstItem.github || {}\n};\n\n// Count sections with URLs\nconst sectionsWithUrls = sectionContents.filter(s => s.url && s.url.length > 0).length;\n\nconsole.log(`‚úÖ Collected ${sectionContents.length} sections`);\nconsole.log(`üìã Document: ${metadata.documentTitle}`);\nconsole.log(`üîó Sections with URLs: ${sectionsWithUrls}/${sectionContents.length}`);\n\nreturn [{\n  json: {\n    documentTitle: metadata.documentTitle,\n    documentType: metadata.documentType,\n    targetAudience: metadata.targetAudience,\n    chatId: metadata.chatId,\n    userRequest: metadata.userRequest,\n    totalSections: metadata.totalSections,\n    completeTOC: metadata.completeTOC,\n    sections: sectionContents,\n    github: github,\n    generatedAt: new Date().toISOString()\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4480,
        2160
      ],
      "id": "f2ab117a-0755-4593-9b00-0e52c5bca0ed",
      "name": "Collect_Section_Results"
    },
    {
      "parameters": {
        "jsCode": "// Prepare_GitHub_Payload_With_SHA\n// This node prepares the GitHub upload payload correctly\n\nconst inputData = $input.first().json;\n\nconsole.log('üîß Preparing GitHub Upload Payload');\n\n// Get GitHub configuration\nconst github = inputData.github || {};\nconst owner = github.owner || 'codewithshahzaib';\nconst repo = github.repo || 'Documentation_Upload_Project';\nconst path = github.path || inputData.path;\n\n// Get document data\nconst structuredDoc = inputData.structuredDocument || inputData;\nconst jsonContent = JSON.stringify(structuredDoc, null, 2);\nconst base64Content = Buffer.from(jsonContent).toString('base64');\n\n// Get document title\nconst documentTitle = inputData.documentTitle || \n  structuredDoc?.metadata?.documentTitle || \n  'Technical Documentation';\n\n// Create commit message\nconst sectionCount = Object.keys(structuredDoc.sections || {}).length;\nconst commitMessage = `üìÑ Add ${documentTitle} (${sectionCount} sections)`;\n\nconsole.log('üì¶ Repository:', owner + '/' + repo);\nconsole.log('üìÇ Path:', path);\nconsole.log('üìù Commit:', commitMessage);\nconsole.log('üíæ Content size:', jsonContent.length, 'bytes');\n\n// Build the payload object\nconst payload = {\n  message: commitMessage,\n  content: base64Content,\n  branch: 'main'\n};\n\n// CRITICAL: Only add SHA if it exists and is valid\nconst sha = inputData.sha;\nconst hasSHA = sha && \n  sha !== null && \n  sha !== 'null' && \n  sha !== undefined && \n  sha !== 'undefined' &&\n  typeof sha === 'string' &&\n  sha.trim() !== '';\n\nif (hasSHA) {\n  payload.sha = sha;\n  console.log('üîÑ UPDATE mode - SHA:', sha.substring(0, 10) + '...');\n} else {\n  console.log('‚ú® CREATE mode - No SHA (new file)');\n}\n\n// Construct API URL\nconst apiUrl = `https://api.github.com/repos/${owner}/${repo}/contents/${path}`;\n\nconsole.log('üåê API URL:', apiUrl);\nconsole.log('üìã Payload keys:', Object.keys(payload).join(', '));\n\n// Return data for GitHub Upload node\nreturn [{\n  json: {\n    // For HTTP Request node\n    url: apiUrl,\n    method: 'PUT',\n    payload: payload,\n    \n    // Metadata\n    owner: owner,\n    repo: repo,\n    path: path,\n    documentTitle: documentTitle,\n    chatId: inputData.chatId,\n    mode: hasSHA ? 'update' : 'create',\n    \n    // Pass through\n    structuredDocument: structuredDoc,\n    github: {\n      ...github,\n      rawUrl: `https://raw.githubusercontent.com/${owner}/${repo}/main/${path}`,\n      webUrl: `https://github.com/${owner}/${repo}/blob/main/${path}`\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5104,
        2160
      ],
      "id": "4fbcd611-eb55-49ae-85f2-d02196c57688",
      "name": "Prepare_GitHub_Payload_With_SHA"
    },
    {
      "parameters": {
        "jsCode": "// Getting_Sha_Fixed (Using n8n's built-in methods)\nconst parsedData = $('Parse_Sections_to_Structured_JSON').first().json;\nconst github = parsedData.github;\n\nconsole.log('üîç Checking if file exists in GitHub...');\nconsole.log('üì¶ Repository:', github.repo);\nconsole.log('üìÇ Path:', github.path);\n\nconst githubApiUrl = `https://api.github.com/repos/${github.owner}/${github.repo}/contents/${github.path}`;\n\ntry {\n  // Use n8n's $http helper instead of fetch\n  const response = await this.helpers.request({\n    method: 'GET',\n    url: githubApiUrl,\n    headers: {\n      'Accept': 'application/vnd.github.v3+json',\n      'Authorization': 'Bearer YOUR_GITHUB_TOKEN_HERE'\n    },\n    json: true,\n    resolveWithFullResponse: true\n  });\n\n  // File exists - get its SHA\n  const fileInfo = response.body;\n  console.log('‚úÖ File exists, SHA:', fileInfo.sha);\n  \n  return [{\n    json: {\n      ...parsedData,\n      sha: fileInfo.sha,\n      fileExists: true,\n      updateMode: true\n    }\n  }];\n  \n} catch (error) {\n  // Check if it's a 404 (file doesn't exist)\n  if (error.statusCode === 404 || error.message.includes('404')) {\n    console.log('üìù File does not exist yet - will create new file');\n    \n    return [{\n      json: {\n        ...parsedData,\n        // Don't include sha field at all\n        fileExists: false,\n        updateMode: false\n      }\n    }];\n  }\n  \n  // For other errors, log and throw\n  console.error('‚ùå GitHub API error:', error.message);\n  console.error('Status:', error.statusCode);\n  throw error;\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4896,
        2160
      ],
      "id": "36e51781-66c8-46ed-853c-0b5e84837d27",
      "name": "Getting Sha2"
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "=üìÑ Here's your generated document!   üîó Google Sheets: \n{{ $('Create_Drive_Folder').item.json.viewLink }}\nüìÖ Generated at : {{ $json.generatedAt || new Date().toLocaleString() }}",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        5568,
        2640
      ],
      "id": "ecb0a2c7-296e-49b6-bd98-abb7a1693d07",
      "name": "Send a text message4",
      "webhookId": "e39a16c4-f784-4468-8743-a76ef6b54767",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Extract_And_Process_SVGs (FIXED - Checks BOTH content AND diagramData)\ntry {\n  const section = $input.first().json;\n  const sectionNumber = section.sectionNumber || '1';\n  const output = section.output || {};\n  let content = output.content || section.content || '';\n\n  console.log(`üîç Section ${sectionNumber}: Checking for SVG code`);\n\n  // Edge Case 1: No content at all\n  if (!content || content.trim().length === 0) {\n    console.log(`‚ö†Ô∏è Section ${sectionNumber}: Empty content`);\n  }\n\n  // Edge Case 2: Content is not a string\n  if (typeof content !== 'string') {\n    console.log(`‚ö†Ô∏è Section ${sectionNumber}: Content is not string, converting...`);\n    content = String(content);\n  }\n\n  const svgSources = [];\n  \n  // ========================================\n  // SOURCE 1: SVG embedded in content text\n  // ========================================\n  const svgRegex = /<svg[\\s\\S]*?<\\/svg>/gi;\n  const contentSvgMatches = content.match(svgRegex) || [];\n  \n  if (contentSvgMatches.length > 0) {\n    console.log(`üìä Found ${contentSvgMatches.length} SVG blocks in content text`);\n    svgSources.push(...contentSvgMatches.map(svg => ({\n      svg: svg,\n      source: 'content'\n    })));\n  }\n\n  // ========================================\n  // SOURCE 2: SVG in diagramData (CRITICAL!)\n  // ========================================\n  const diagramData = output.diagramData || section.diagramData || {};\n  \n  if (diagramData.hasDiagram === true && diagramData.svg) {\n    console.log(`üìä Found SVG in diagramData.svg`);\n    \n    // Validate it's actually SVG code\n    const diagramSvg = diagramData.svg;\n    if (typeof diagramSvg === 'string' && \n        diagramSvg.includes('<svg') && \n        diagramSvg.includes('</svg>')) {\n      \n      svgSources.push({\n        svg: diagramSvg,\n        source: 'diagramData',\n        title: diagramData.title || 'Process Diagram',\n        type: diagramData.type || 'diagram'\n      });\n      \n      console.log(`‚úÖ Valid SVG found in diagramData: ${diagramData.title || 'Untitled'}`);\n    } else {\n      console.warn(`‚ö†Ô∏è Invalid SVG in diagramData`);\n    }\n  }\n\n  // ========================================\n  // NO SVGs FOUND\n  // ========================================\n  if (svgSources.length === 0) {\n    console.log(`‚úÖ Section ${sectionNumber}: No SVGs found (checked content + diagramData)`);\n    return [{\n      json: {\n        ...section,\n        hasSVGs: false,\n        svgCount: 0,\n        processedContent: content,\n        skipImageProcessing: true,\n        processingStatus: 'no_svgs',\n        content: content,\n        output: {\n          ...output,\n          content: content\n        }\n      }\n    }];\n  }\n\n  // ========================================\n  // PROCESS ALL SVGs\n  // ========================================\n  const svgData = [];\n  let processedContent = content;\n  let validSVGCount = 0;\n\n  svgSources.forEach((svgSource, index) => {\n    const svg = svgSource.svg;\n    \n    // Validate SVG structure\n    if (!svg.includes('<svg') || !svg.includes('</svg>')) {\n      console.warn(`‚ö†Ô∏è Section ${sectionNumber}: Invalid SVG at index ${index}, skipping`);\n      return;\n    }\n\n    // Check SVG is not too small\n    if (svg.length < 50) {\n      console.warn(`‚ö†Ô∏è Section ${sectionNumber}: SVG too small at index ${index}, skipping`);\n      return;\n    }\n\n    validSVGCount++;\n    const figureNumber = validSVGCount;\n    const figureName = `Section_${sectionNumber}_Figure_${figureNumber}`;\n    const figureReference = `Figure ${sectionNumber}.${figureNumber}`;\n    \n    // Determine if we need to add figure reference to content\n    let shouldAddReferenceToContent = false;\n    \n    if (svgSource.source === 'diagramData') {\n      // SVG from diagramData - add reference at the end of content\n      shouldAddReferenceToContent = true;\n      const diagramTitle = svgSource.title || 'Process Diagram';\n      \n      // Add figure reference at end of section\n      processedContent += `\\n\\n---\\n\\n**${figureReference}: ${diagramTitle}**\\n\\n*[Diagram: ${figureName}.png]*\\n\\nThis diagram illustrates the ${diagramTitle.toLowerCase()} discussed in this section. The visual representation shows the key components and their interactions.\\n\\n`;\n      \n      console.log(`‚úÖ Added diagram reference for: ${diagramTitle}`);\n      \n    } else if (svgSource.source === 'content') {\n      // SVG embedded in content - replace inline\n      const replacement = `\\n\\n**${figureReference}: ${figureName}**\\n\\n*[Image: ${figureName}.png]*\\n\\n`;\n      processedContent = processedContent.replace(svg, replacement);\n      \n      console.log(`‚úÖ Replaced inline SVG with reference`);\n    }\n    \n    svgData.push({\n      svgCode: svg,\n      figureName: figureName,\n      figureNumber: figureNumber,\n      figureReference: figureReference,\n      sectionNumber: sectionNumber,\n      originalIndex: index,\n      source: svgSource.source,\n      title: svgSource.title || figureName,\n      isValid: true\n    });\n    \n    console.log(`‚úÖ Section ${sectionNumber}: Processed ${figureName} (from ${svgSource.source})`);\n  });\n\n  // Edge Case: Had SVG sources but all were invalid\n  if (validSVGCount === 0) {\n    console.log(`‚ö†Ô∏è Section ${sectionNumber}: All SVGs invalid, treating as no-SVG section`);\n    return [{\n      json: {\n        ...section,\n        hasSVGs: false,\n        svgCount: 0,\n        processedContent: content,\n        skipImageProcessing: true,\n        processingStatus: 'invalid_svgs',\n        content: content,\n        output: {\n          ...output,\n          content: content\n        }\n      }\n    }];\n  }\n\n  // ========================================\n  // SUCCESS\n  // ========================================\n  console.log(`‚úÖ Section ${sectionNumber}: Processed ${validSVGCount} valid SVGs`);\n  console.log(`   Sources breakdown:`);\n  svgData.forEach(svg => {\n    console.log(`   - ${svg.figureName} (from ${svg.source})`);\n  });\n  \n  return [{\n    json: {\n      ...section,\n      hasSVGs: true,\n      svgCount: validSVGCount,\n      svgData: svgData,\n      processedContent: processedContent,\n      skipImageProcessing: false,\n      processingStatus: 'svgs_processed',\n      \n      // Update content with figure references\n      content: processedContent,\n      output: {\n        ...output,\n        content: processedContent,\n        // Remove diagramData.svg since we've extracted it\n        diagramData: {\n          ...diagramData,\n          hasDiagram: true,\n          svg: undefined, // Don't keep the raw SVG\n          processedAsPNG: true,\n          figureReferences: svgData.map(s => s.figureReference)\n        }\n      }\n    }\n  }];\n\n} catch (error) {\n  console.error(`‚ùå Section processing error:`, error.message);\n  console.error(`Stack:`, error.stack);\n  \n  // Pass through original data safely\n  const section = $input.first().json;\n  return [{\n    json: {\n      ...section,\n      hasSVGs: false,\n      svgCount: 0,\n      skipImageProcessing: true,\n      processingStatus: 'error',\n      processingError: error.message,\n      processedContent: section.content || section.output?.content || ''\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2224,
        2672
      ],
      "id": "3a9375c3-4d58-476c-8794-7c7c20723fe7",
      "name": "Extract_And_Process_SVGs"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "fe001bb5-3196-4b26-b3d5-b8e84facd728",
              "leftValue": "=true",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2736,
        3040
      ],
      "id": "a5b31d43-b206-4e80-9fe7-10fdfadf3938",
      "name": "Check_If_Has_SVGs"
    },
    {
      "parameters": {
        "jsCode": "try {\n  const input = $input.first().json;\n  // const section = $('Extract_Media_Assets').first().json;\n  // Get section metadata with fallbacks\n  const sectionNumber = $input.first().json.output.sectionNumber || $('Extract_And_Process_SVGs').first().json.output.sectionNumber;\n  const title = $input.first().json.output.title || $('Extract_And_Process_SVGs').first().json.output.title;\n  \n  // Get content - prioritize processedContent (has figure references)\n  const content = input.processedContent || \n                  input.content || \n                  input.output?.content || \n                  '';\n\n  // Diagram data (could be separate from SVGs)\n  const diagramData = input.diagramData || input.output?.diagramData || null;\n  const hasDiagram = diagramData && diagramData.hasDiagram === true;\n\n  // Images (from SVG processing)\n  const images = input.images || [];\n  const hasImages = images.length > 0;\n  const failedImages = input.failedImages || [];\n  \n  // GitHub config\n  const github = input.github || input.documentMetadata?.github || input.sectionData?.github || null;\n\n  if (!github) {\n    console.warn(`‚ö†Ô∏è Section ${sectionNumber}: GitHub config not found!`);\n  }\n\n  // Create safe folder name\n  const folderName = `section_${sectionNumber}_${title}`\n    .replace(/[^a-zA-Z0-9_-]/g, '_')\n    .replace(/_+/g, '_')\n    .toLowerCase();\n\n  console.log(`‚úÖ Section ${sectionNumber} extracted:`, {\n    title,\n    folderName,\n    hasDiagram,\n    hasContent: !!content,\n    hasImages,\n    imageCount: images.length,\n    failedImageCount: failedImages.length,\n    hasGithub: !!github,\n    githubRepo: github?.repo || 'NOT FOUND'\n  });\n\n  return [{\n    json: {\n      // Section metadata\n      sectionNumber: sectionNumber,\n      title: title,\n      content: content, // This is processedContent with figure references\n      sectionIndex: input.sectionIndex || 0,\n      \n      // Parsed output\n      output: input.output || {},\n      \n      // Media assets\n      folderName: folderName,\n      hasDiagram: hasDiagram,\n      diagramData: diagramData,\n      \n      // Images (from SVG processing)\n      images: images,\n      hasImages: hasImages,\n      imageCount: images.length,\n      failedImages: failedImages,\n      hasImageFailures: failedImages.length > 0,\n      \n      // Upload flag\n      shouldUploadToGithub: true,\n      \n      // Document-level metadata\n      documentTitle: input.documentTitle || input.sectionData?.documentTitle || 'Unknown Document',\n      documentType: input.documentType || input.sectionData?.documentType || 'Technical Document',\n      targetAudience: input.targetAudience || input.sectionData?.targetAudience || 'Technical Teams',\n      chatId: input.chatId || input.sectionData?.chatId || 'unknown',\n      totalSections: input.totalSections || input.sectionData?.totalSections || 0,\n      \n      // GitHub config\n      github: github,\n      \n      // Preserve everything else\n      documentMetadata: input.documentMetadata || {},\n      userRequest: input.userRequest || input.sectionData?.userRequest || ''\n    }\n  }];\n\n} catch (error) {\n  console.error(`‚ùå Extract_Media_Assets error:`, error.message);\n  \n  // Return minimal valid data to prevent workflow failure\n  const input = $input.first().json;\n  return [{\n    json: {\n      sectionNumber: input.sectionNumber || 'error',\n      title: input.title || 'Error Processing Section',\n      content: input.content || '',\n      hasError: true,\n      errorMessage: error.message,\n      shouldUploadToGithub: false\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3056,
        3024
      ],
      "id": "9db193e7-e843-431e-88dc-c8d3f0e3effc",
      "name": "Extract_Media_Assets1"
    },
    {
      "parameters": {
        "jsCode": "// ================================================\n// Direct_Upload_Content - Fixed Naming Convention\n// ================================================\n\nconst section = $input.first().json;\n\nconsole.log('=== Direct_Upload_Content ===');\n\n// ================================================\n// 1Ô∏è‚É£ Get GitHub Configuration\n// ================================================\n\nlet github = null;\n\nconst sources = [\n  section.github,\n  section.documentMetadata?.github,\n  section.output?.github\n];\n\nfor (const config of sources) {\n  if (config?.owner && config?.repo && config?.basePath) {\n    github = config;\n    break;\n  }\n}\n\n// Fallback to previous nodes\nif (!github) {\n  try {\n    const extractNode = $('Extract_Media_Assets1');\n    if (extractNode?.first()?.json?.github) {\n      github = extractNode.first().json.github;\n    }\n  } catch (e) {}\n}\n\nif (!github) {\n  try {\n    const tocNode = $('Parse_TOC_JSON');\n    if (tocNode?.first()?.json?.github) {\n      github = tocNode.first().json.github;\n    }\n  } catch (e) {}\n}\n\nif (!github || !github.owner || !github.repo || !github.basePath) {\n  throw new Error('‚ùå GitHub config not found or incomplete!');\n}\n\nconsole.log('üì¶ Repository:', github.repo);\nconsole.log('üìÇ Base path:', github.basePath);\n\n// ================================================\n// 2Ô∏è‚É£ Validate Section Data\n// ================================================\n\nif (!section.sectionNumber || section.sectionNumber === 'undefined') {\n  throw new Error('‚ùå Missing sectionNumber!');\n}\nif (!section.title || section.title === 'undefined') {\n  throw new Error('‚ùå Missing title!');\n}\n\n// ================================================\n// 3Ô∏è‚É£ Create Descriptive Filename (FIXED)\n// ================================================\n\n// Create clean section folder name\nconst sectionFolder = section.folderName || \n  `section_${section.sectionNumber}_${section.title}`\n    .replace(/[^a-zA-Z0-9_-]/g, '_')\n    .replace(/_+/g, '_')\n    .toLowerCase();\n\n// Create descriptive filename instead of timestamp\nconst sectionTitle = section.title\n  .replace(/[^a-zA-Z0-9\\s]/g, '')  // Remove special chars\n  .replace(/\\s+/g, '_')             // Replace spaces with underscores\n  .toLowerCase()\n  .substring(0, 50);                // Limit length\n\nconst filename = `section_${section.sectionNumber}_${sectionTitle}.md`;\n\nconsole.log(`üìù Filename: ${filename}`);\n\n// ================================================\n// 4Ô∏è‚É£ Get Content\n// ================================================\n\nconst contentText = section.output?.content || section.content || \"\";\n\nif (!contentText) {\n  throw new Error('‚ùå No content to upload!');\n}\n\nconsole.log(`üìÑ Content length: ${contentText.length} characters`);\n\n// ================================================\n// 5Ô∏è‚É£ Prepare Upload\n// ================================================\n\nfunction toBase64(content) {\n  return Buffer.from(String(content)).toString('base64');\n}\n\nconst filePath = `${github.basePath}/${sectionFolder}/${filename}`;\nconst githubApiUrl = `https://api.github.com/repos/${github.owner}/${github.repo}/contents/${filePath}`;\n\nconsole.log(`üéØ Target path: ${filePath}`);\n\nreturn [{\n  json: {\n    githubApiUrl,\n    githubOwner: github.owner,\n    githubRepo: github.repo,\n    githubPath: filePath,\n    fileType: 'content',\n    filename: filename,\n    sectionFolder: sectionFolder,\n    uploadFile: {\n      message: `üìù Add Section ${section.sectionNumber}: ${section.title}`,\n      content: toBase64(contentText),\n      branch: github.branch || \"main\"\n    },\n    // Pass through all section data\n    ...section,\n    github: github,\n    uploadReady: true,\n    \n    // URLs for reference\n    rawUrl: `https://raw.githubusercontent.com/${github.owner}/${github.repo}/${github.branch || 'main'}/${filePath}`,\n    webUrl: `https://github.com/${github.owner}/${github.repo}/blob/${github.branch || 'main'}/${filePath}`\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3472,
        3024
      ],
      "id": "6692c8fa-740e-4e15-950e-faff3adb9bbe",
      "name": "Direct_Upload_Content1"
    },
    {
      "parameters": {
        "jsCode": "// Check_File_SHA (New node)\nconst fileData = $input.first().json;\n\n// Only check SHA if needed\nif (!fileData.needsShaCheck) {\n  return [{ json: fileData }];\n}\n\nconst githubApiUrl = `https://api.github.com/repos/${fileData.githubOwner}/${fileData.githubRepo}/contents/${fileData.githubPath}`;\n\ntry {\n  // Try to get existing file info\n  const response = await $httpRequest({\n    method: 'GET',\n    url: githubApiUrl,\n    headers: {\n      'Accept': 'application/vnd.github.v3+json',\n      'Authorization': `Bearer YOUR_GITHUB_TOKEN_HERE`\n    },\n    returnFullResponse: true\n  });\n  \n  // File exists - get its SHA\n  const fileInfo = response.body;\n  console.log(`üìÅ File exists, SHA: ${fileInfo.sha}`);\n  \n  return [{\n    json: {\n      ...fileData,\n      uploadFile: {\n        ...fileData.uploadFile,\n        sha: fileInfo.sha\n      }\n    }\n  }];\n  \n} catch (error) {\n  if (error.statusCode === 404) {\n    // File doesn't exist - no SHA needed\n    console.log('üìÅ File does not exist, uploading new file');\n    return [{ json: fileData }];\n  } else {\n    // Other error\n    console.error('‚ùå Error checking file:', error);\n    throw error;\n  }\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3264,
        3024
      ],
      "id": "ab87df72-c31e-488c-bf50-fec78bbc25c6",
      "name": "Check_File_SHA1"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "={{ $json.githubApiUrl }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.formattedPayload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3824,
        3024
      ],
      "id": "876444c9-8499-4dab-bd4f-a94c6869fbb6",
      "name": "GitHub Upload3"
    },
    {
      "parameters": {
        "jsCode": "const dataItems = $node[\"Section_Detail_Generator_Agent\"].json;\nconst urlItems = $node[\"Format_Upload_Body1\"].json;\n\nreturn [\n  {\n    json: {\n      data: dataItems,\n      url: urlItems.githubApiUrl\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4576,
        3024
      ],
      "id": "608cbd13-5be2-472b-87f4-ad65d0ac0232",
      "name": "Extarct items1"
    },
    {
      "parameters": {
        "mode": "insert",
        "pineconeIndex": {
          "__rl": true,
          "value": "github-docs",
          "mode": "list",
          "cachedResultName": "github-docs"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        4160,
        3024
      ],
      "id": "f6cae40d-50b1-468e-b2bc-f114793cbda5",
      "name": "Pinecone Vector Store1",
      "credentials": {
        "pineconeApi": {
          "id": "mXFlt5mM7QsngptO",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        4128,
        3232
      ],
      "id": "6505ec64-f778-4f97-8098-17f7c8ee313d",
      "name": "Embeddings OpenAI3",
      "credentials": {
        "openAiApi": {
          "id": "bhBOpGB6JIUeu4NX",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare_Section_For_Vectorization\nconst uploadResponse = $input.first().json;\nconst sectionData = uploadResponse.body || uploadResponse;\n\nconsole.log('üì¶ Preparing section for vectorization...');\n\n// Get the GitHub download URL from the upload response\nconst downloadUrl = sectionData.content?.download_url || \n                    sectionData.download_url ||\n                    uploadResponse.body?.content?.download_url;\n\nif (!downloadUrl) {\n  console.error('‚ö†Ô∏è No download URL found in response');\n  console.log('Response keys:', Object.keys(sectionData));\n}\n\n// Get section metadata (should be preserved from previous nodes)\nconst section = $('Extract_Media_Assets1').first().json;\n\n// Get the actual content text\nconst contentText = section.output?.content || section.content || '';\n\nif (!contentText || contentText.trim().length === 0) {\n  throw new Error('‚ùå No content to vectorize!');\n}\n\nconsole.log('‚úÖ Section prepared:', {\n  sectionNumber: section.sectionNumber,\n  title: section.title,\n  contentLength: contentText.length,\n  hasUrl: !!downloadUrl\n});\n\nreturn [{\n  json: {\n    // Content to be embedded\n    pageContent: contentText,\n    \n    // Metadata for Pinecone\n    metadata: {\n      sectionNumber: section.sectionNumber,\n      title: section.title,\n      documentTitle: section.documentTitle,\n      documentType: section.documentType,\n      chatId: section.chatId,\n      githubUrl: downloadUrl,\n      githubRepo: section.github?.repo || 'unknown',\n      githubPath: section.github?.basePath || 'unknown',\n      createdAt: new Date().toISOString(),\n      contentLength: contentText.length\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4000,
        3024
      ],
      "id": "7948d079-0763-455b-8cf1-8e8b68be9997",
      "name": "Prepare_Section_For_Vectorization1"
    },
    {
      "parameters": {
        "options": {
          "metadata": {
            "metadataValues": [
              {
                "name": "Filename",
                "value": "sectionNumber"
              }
            ]
          }
        }
      },
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [
        4320,
        3232
      ],
      "id": "546621d7-13e2-4697-b8cf-050ab61e889e",
      "name": "Section_Document_Loader1"
    },
    {
      "parameters": {
        "jsCode": "// Create_Drive_Folder\nconst docData = $input.first().json;\nconst folderName = docData.documentTitle || 'Technical Documentation';\n\nconsole.log('üìÅ Creating Drive folder:', folderName);\n\n// Return data for Google Drive API\nreturn [{\n  json: {\n    ...docData,\n    driveFolderName: folderName,\n    readyForDriveUpload: true\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5296,
        2384
      ],
      "id": "066bf33e-3403-441c-ba1d-d048dec6b41f",
      "name": "Create_Drive_Folder"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://www.googleapis.com/drive/v3/files",
        "authentication": "genericCredentialType",
        "genericAuthType": "oAuth2Api",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"name\": \"{{ $json.driveFolderName }}\",\n  \"mimeType\": \"application/vnd.google-apps.folder\"\n}\n",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4672,
        2640
      ],
      "id": "cdb1f82c-b3c9-4947-99f3-4a5b16e06985",
      "name": "Create_Drive_Folder_API",
      "credentials": {
        "oAuth2Api": {
          "id": "6VtG2NAOONCkC0aw",
          "name": "Google Drive Docs API Credentials"
        }
      }
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://www.googleapis.com/drive/v3/files/{{ $('Create Google Doc').item.json.documentId }}?addParents={{ $json.id }}&fields=id,parents",
        "authentication": "genericCredentialType",
        "genericAuthType": "oAuth2Api",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        4896,
        2640
      ],
      "id": "b62e2a3a-eaf9-4dc3-ad80-dce745e5a0eb",
      "name": "Copy_Doc_to_Drive_Folder",
      "credentials": {
        "oAuth2Api": {
          "id": "6VtG2NAOONCkC0aw",
          "name": "Google Drive Docs API Credentials"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ================================================\n// Collect_All_PNGs_From_Sections - FIXED\n// ================================================\n\nconsole.log('üîç Collecting images for Google Drive upload...');\n\n// ================================================\n// 1Ô∏è‚É£ Get Folder ID\n// ================================================\n\nconst folderId = $('Create_Drive_Folder_API').first().json.id;\n\nif (!folderId) {\n  throw new Error('‚ùå No Drive folder ID found!');\n}\n\nconsole.log(`üìÅ Drive Folder ID: ${folderId}`);\n\n// ================================================\n// 2Ô∏è‚É£ Collect Images from Multiple Sources\n// ================================================\n\nconst allImages = [];\n\n// METHOD 1: Check if we have aggregated section data\ntry {\n  const sectionsData = $('Collect_Section_Results').first().json;\n  if (sectionsData?.sections) {\n    sectionsData.sections.forEach(section => {\n      if (section.images && Array.isArray(section.images)) {\n        section.images.forEach(img => {\n          allImages.push({\n            ...img,\n            sectionNumber: section.sectionNumber,\n            sectionTitle: section.title,\n            folderId: folderId\n          });\n        });\n      }\n    });\n    console.log(`‚úÖ Found ${allImages.length} images from Collect_Section_Results`);\n  }\n} catch (e) {\n  console.log('‚ÑπÔ∏è Could not access Collect_Section_Results:', e.message);\n}\n\n// METHOD 2: Check Merge_Images node (processes each section)\nif (allImages.length === 0) {\n  try {\n    const mergeItems = $('Merge_Images').all();\n    mergeItems.forEach(item => {\n      const images = item.json.images || [];\n      images.forEach(img => {\n        allImages.push({\n          ...img,\n          folderId: folderId\n        });\n      });\n    });\n    console.log(`‚úÖ Found ${allImages.length} images from Merge_Images`);\n  } catch (e) {\n    console.log('‚ÑπÔ∏è Could not access Merge_Images:', e.message);\n  }\n}\n\n// METHOD 3: Check Update_Content node\nif (allImages.length === 0) {\n  try {\n    const updateItems = $('Update_Content').all();\n    updateItems.forEach(item => {\n      const images = item.json.images || [];\n      images.forEach(img => {\n        allImages.push({\n          ...img,\n          folderId: folderId\n        });\n      });\n    });\n    console.log(`‚úÖ Found ${allImages.length} images from Update_Content`);\n  } catch (e) {\n    console.log('‚ÑπÔ∏è Could not access Update_Content:', e.message);\n  }\n}\n\n// METHOD 4: Check GitHub Upload4 (successful uploads)\nif (allImages.length === 0) {\n  try {\n    const uploadItems = $('GitHub Upload4').all();\n    uploadItems.forEach(item => {\n      const json = item.json;\n      if (json.filename && json.rawUrl) {\n        allImages.push({\n          filename: json.filename,\n          figureNumber: json.figureNumber,\n          figureReference: json.figureReference,\n          sectionNumber: json.sectionNumber,\n          rawUrl: json.rawUrl,\n          webUrl: json.webUrl,\n          githubPath: json.githubPath,\n          folderId: folderId\n        });\n      }\n    });\n    console.log(`‚úÖ Found ${allImages.length} images from GitHub Upload4`);\n  } catch (e) {\n    console.log('‚ÑπÔ∏è Could not access GitHub Upload4:', e.message);\n  }\n}\n\n// ================================================\n// 3Ô∏è‚É£ Handle No Images Case\n// ================================================\n\nif (allImages.length === 0) {\n  console.log('‚ö†Ô∏è No images found to upload to Google Drive');\n  return [{\n    json: {\n      folderId: folderId,\n      imagesFound: false,\n      imageCount: 0,\n      message: 'No images to upload',\n      skipDriveUpload: true\n    }\n  }];\n}\n\n// ================================================\n// 4Ô∏è‚É£ Prepare Images for Drive Upload\n// ================================================\n\nconsole.log(`üì§ Preparing ${allImages.length} images for Drive upload`);\n\n// For each image, we need to:\n// 1. Fetch the PNG from GitHub (rawUrl)\n// 2. Upload to Google Drive folder\n\nconst imageItems = allImages.map((img, index) => ({\n  json: {\n    // Image metadata\n    filename: img.filename,\n    figureNumber: img.figureNumber,\n    figureReference: img.figureReference,\n    sectionNumber: img.sectionNumber,\n    sectionTitle: img.sectionTitle,\n    \n    // GitHub URLs\n    githubRawUrl: img.rawUrl,\n    githubWebUrl: img.webUrl,\n    githubPath: img.githubPath,\n    \n    // Drive info\n    driveFolderId: folderId,\n    needsDriveUpload: true,\n    \n    // Tracking\n    imageIndex: index + 1,\n    totalImages: allImages.length\n  }\n}));\n\nconsole.log('‚úÖ Images prepared for Drive upload:');\nimageItems.forEach((item, i) => {\n  console.log(`   ${i + 1}. ${item.json.filename} (Section ${item.json.sectionNumber})`);\n});\n\nreturn imageItems;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5120,
        2640
      ],
      "id": "5c10ccf3-b720-4ffb-94fb-564fdd2f3843",
      "name": "Upload_PNGs_to_Drive"
    },
    {
      "parameters": {
        "jsCode": "const section = $input.first().json;\nconst sectionNumber = $input.first().json.output.sectionNumber;\n\nconsole.log(`üìÅ Preparing image directory structure for Section ${sectionNumber}`);\n\n// Determine image count for this section\nconst svgData = section.svgData || [];\nconst imageCount = svgData.length;\n\nconsole.log(`   Found ${imageCount} images to process`);\n\n// Map each SVG to proper filename\nconst imagesToProcess = svgData.map((svg, index) => {\n  const figureNumber = `${sectionNumber}_${index + 1}`;\n  const filename = `Figure_${figureNumber}.png`;\n  \n  return {\n    json: {\n      // SVG data for conversion\n      svg: svg.svgCode,\n      \n      // File naming\n      figureNumber: figureNumber,\n      filename: filename,\n      localPath: `images/${filename}`,\n      \n      // Section context\n      sectionNumber: sectionNumber,\n      sectionTitle: section.title || 'Untitled',\n      imageIndex: index,\n      totalImages: imageCount,\n      \n      // Original metadata\n      figureName: svg.figureName,\n      figureReference: `Figure ${figureNumber}`,\n      \n      // Pass through section data\n      sectionData: {\n        sectionNumber: $input.first().json.output.sectionNumber,\n        title: $input.first().json.output.title,\n        documentTitle: $('Loop Over Items').first().json.documentTitle,\n        github: section.github,\n        chatId: $('Loop Over Items').first().json.chatId,\n        processedContent: section.processedContent\n      }\n    }\n  };\n});\n\nconsole.log(`‚úÖ Prepared ${imagesToProcess.length} images with proper naming`);\nimagesToProcess.forEach(img => {\n  console.log(`   ‚Üí ${img.json.filename}`);\n});\n\nreturn imagesToProcess;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2736,
        2848
      ],
      "id": "6d2170e0-f12b-4763-a18b-b1c55804b3f8",
      "name": "Create_Images_Directory"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "={{ $json.githubApiUrl }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.formattedPayload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3568,
        2656
      ],
      "id": "36ce2e61-efd5-41e9-9b30-8cb9e1d91169",
      "name": "GitHub Upload4"
    },
    {
      "parameters": {
        "jsCode": "// Save_PNG - FIXED VERSION\nconst imageData = $input.first().json;\nconst binaryData = $input.first().binary;\n\nconsole.log('üîç Binary data keys:', Object.keys(binaryData || {}));\n\n// Get the PNG binary from HTTP Request response\nconst pngBinary = binaryData?.data;\n\nif (!pngBinary) {\n  console.error('‚ùå Available binary keys:', Object.keys(binaryData || {}));\n  throw new Error('No PNG binary data received from HTTP Request');\n}\n\n// Convert binary to base64\nlet base64Data;\n\nif (Buffer.isBuffer(pngBinary.data)) {\n  // If it's a Buffer in the data property\n  base64Data = pngBinary.data.toString('base64');\n} else if (typeof pngBinary.data === 'string') {\n  // If it's already base64 string\n  base64Data = pngBinary.data;\n} else {\n  // Fallback: try to create buffer from whatever we have\n  base64Data = Buffer.from(pngBinary.data).toString('base64');\n}\n\n// ‚úÖ Clean the base64 string\nbase64Data = base64Data\n  .replace(/^data:image\\/png;base64,/, '')  // Remove data URI prefix\n  .replace(/\\s/g, '');                       // Remove whitespace\n\n// Validate base64\nconst isValidBase64 = /^[A-Za-z0-9+/]*={0,2}$/.test(base64Data);\n\nif (!isValidBase64) {\n  console.error('‚ùå Invalid base64 detected');\n  console.log('First 100 chars:', base64Data.substring(0, 100));\n  throw new Error('Invalid base64 string!');\n}\n\nconsole.log('‚úÖ Base64 validated');\nconsole.log('üìä Length:', base64Data.length);\nconsole.log('üî§ First 50 chars:', base64Data.substring(0, 50));\nconsole.log('üî§ Last 50 chars:', base64Data.substring(base64Data.length - 50));\n\nreturn [{\n  json: {\n    ...imageData,\n    pngBase64: base64Data,\n    binarySize: base64Data.length,\n    mimeType: pngBinary.mimeType || 'image/png',\n    fileExtension: pngBinary.fileExtension || 'png'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2944,
        2656
      ],
      "id": "71eaca04-fb1e-44fa-bb48-dc48cd708403",
      "name": "Save_PNG"
    },
    {
      "parameters": {
        "jsCode": "// Upload_Image node - FIXED\nconst imageData = $input.first().json;\n\n// Get PNG Base64 from Save_PNG node\nlet cleanBase64 = imageData.pngBase64;\n\n// CRITICAL: Remove data URI prefix if present\nif (typeof cleanBase64 === 'string') {\n  cleanBase64 = cleanBase64.replace(/^data:image\\/png;base64,/, '');\n  // Also remove any whitespace/newlines\n  cleanBase64 = cleanBase64.replace(/\\s/g, '');\n}\n\nconsole.log(`‚úÖ Clean base64 length: ${cleanBase64.length}`);\n\n// Validate it's proper base64\nconst isValidBase64 = /^[A-Za-z0-9+/=]+$/.test(cleanBase64);\nif (!isValidBase64) {\n  throw new Error('Invalid base64 string detected!');\n}\n\n// Rest of your code...\n// 2Ô∏è‚É£ Get GitHub Configuration\n// ================================================\n\nlet github = null;\n\nconst sources = [\n  () => imageData.sectionData?.github,\n  () => $('Extract_Media_Assets1').first()?.json?.github,\n  () => $('Parse_TOC_JSON').first()?.json?.github\n];\n\nfor (const getGithub of sources) {\n  try {\n    const config = getGithub();\n    if (config?.owner && config?.repo && config?.basePath) {\n      github = config;\n      break;\n    }\n  } catch (e) {\n    continue;\n  }\n}\n\nif (!github) {\n  throw new Error('GitHub config not found!');\n}\n\n// ================================================\n// 3Ô∏è‚É£ Prepare GitHub Upload Path\n// ================================================\n\nconst githubPath = `${github.basePath}/images/${imageData.filename}`;\nconst githubApiUrl = `https://api.github.com/repos/${github.owner}/${github.repo}/contents/${githubPath}`;\n\nconst uploadPayload = {\n  message: `Add ${imageData.figureReference || imageData.filename} for Section ${imageData.sectionNumber}`,\n  content: cleanBase64,  // ‚úÖ Clean base64, no prefix\n  branch: github.branch || 'main'\n  // ‚ùå Do NOT include sha here - Check_File_SHA will add it\n};\n\nconsole.log(`üìÇ GitHub path: ${githubPath}`);\nconsole.log(`üì§ Base64 length: ${cleanBase64.length} chars`);\nconsole.log(`‚úÖ Upload payload prepared`);\n\n// ================================================\n// 4Ô∏è‚É£ Return for Check_File_SHA\n// ================================================\n\nreturn [{\n  json: {\n    // For HTTP Request node\n    githubApiUrl,\n    githubPath,\n    uploadPayload,  // ‚úÖ Will be updated with SHA by Check_File_SHA\n    \n    // Image metadata\n    ...imageData,\n    \n    // URLs for reference\n    rawUrl: `https://raw.githubusercontent.com/${github.owner}/${github.repo}/${github.branch || 'main'}/${githubPath}`,\n    webUrl: `https://github.com/${github.owner}/${github.repo}/blob/${github.branch || 'main'}/${githubPath}`,\n    \n    // Debug info\n    base64Length: cleanBase64.length,\n    uploadReady: true\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3136,
        2656
      ],
      "id": "6e21e199-95fc-459d-9990-bddb1c4f6e6b",
      "name": "Upload_Image"
    },
    {
      "parameters": {
        "jsCode": "// Correct way to access node data in n8n\nconst items = $('Check_File_SHA').all();\n\nif (!items || items.length === 0) {\n  console.log('‚ö†Ô∏è No images to merge');\n  return [{\n    json: {\n      imagesProcessed: false,\n      imageCount: 0,\n      images: []\n    }\n  }];\n}\n\n// Get section data from first item\nconst sectionData = items[0].json.sectionData;\n\n// Collect all uploaded images\nconst images = items.map(item => ({\n  figureNumber: item.json.figureNumber,\n  filename: item.json.filename,\n  figureReference: item.json.figureReference,\n  \n  // File system paths\n  localPath: item.json.localPath,\n  relativePath: item.json.relativePath,\n  \n  // GitHub URLs\n  githubPath: item.json.githubPath,\n  rawUrl: item.json.rawUrl,\n  webUrl: item.json.webUrl,\n  \n  // Metadata\n  sectionNumber: item.json.sectionNumber,\n  imageIndex: item.json.imageIndex,\n  fileSize: item.json.fileSize\n}));\n\n// Sort by index\nimages.sort((a, b) => a.imageIndex - b.imageIndex);\n\nconsole.log(`‚úÖ Merged ${images.length} images for Section ${sectionData.sectionNumber}`);\nimages.forEach(img => {\n  console.log(`   ‚úì ${img.figureReference}: ${img.filename}`);\n});\n\nreturn [{\n  json: {\n    ...sectionData,\n    \n    // Image collection\n    images: images,\n    imagesProcessed: true,\n    imageCount: images.length,\n    \n    // All image URLs for easy reference\n    imageUrls: images.map(img => img.rawUrl),\n    imagePaths: images.map(img => img.relativePath),\n    \n    // Status\n    allImagesSuccessful: true,\n    hasImageFailures: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3712,
        2656
      ],
      "id": "3f3dbfe6-5649-43c9-9b3b-395b94b9c625",
      "name": "Merge_Images"
    },
    {
      "parameters": {
        "jsCode": "const section = $('Merge_Images').first().json;\nlet content = section.processedContent || section.content || '';\n\nconsole.log(`üìù Updating image references in Section ${section.sectionNumber}`);\n\nif (!section.images || section.images.length === 0) {\n  console.log('   No images to reference');\n  return [{\n    json: {\n      ...section,\n      contentUpdated: false\n    }\n  }];\n}\n\n// Replace image placeholders with actual references\nsection.images.forEach(image => {\n  const oldReference = `*[Diagram: Section_1_Figure_1.png]*`;\n  const newReference = `![${image.figureReference}](${image.relativePath})`;\n  \n  // Also update diagram references\n  const oldDiagramRef = `*[Diagram: ${image.figureName}.png]*`;\n  \n  content = content.replace(oldReference, newReference);\n  content = content.replace(oldDiagramRef, newReference);\n  \n  console.log(`   ‚úì Updated reference: ${image.figureReference}`);\n});\n\nconsole.log(`‚úÖ Content updated with ${section.images.length} image references`);\n\nreturn [{\n  json: {\n    ...section,\n    content: content,\n    processedContent: content,\n    contentUpdated: true,\n    imageReferencesUpdated: section.images.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3856,
        2656
      ],
      "id": "8966109a-dc64-442e-91a1-cef178b7240e",
      "name": "Update_Content"
    },
    {
      "parameters": {
        "jsCode": "// Check_File_SHA (FIXED - Proper SHA handling)\nconst fileData = $input.first().json;\n\ntry {\n  const response = await this.helpers.httpRequest({\n    method: 'GET',\n    url: fileData.githubApiUrl,\n    headers: {\n      Accept: 'application/vnd.github.v3+json',\n      Authorization: `Bearer YOUR_GITHUB_TOKEN_HERE`,\n      'User-Agent': 'n8n',\n    },\n    returnFullResponse: true,\n  });\n\n  // File exists ‚Üí include SHA in payload\n  const sha = response.body.sha;\n  const updatedPayload = { \n    ...fileData.uploadPayload, \n    sha: sha  // ‚úÖ No extra = prefix\n  };\n  \n  console.log(`‚úÖ File exists, SHA: ${sha}`);\n  \n  return [{ \n    json: { \n      ...fileData, \n      uploadPayload: updatedPayload\n    } \n  }];\n\n} catch (err) {\n  if (err.response?.status === 404 || err.status === 404) {\n    // File does not exist ‚Üí DO NOT include sha field\n    console.log('üìù File not found (404) ‚Äì will create new file');\n    \n    // Remove sha from payload if it exists\n    const cleanPayload = { ...fileData.uploadPayload };\n    delete cleanPayload.sha;\n    \n    return [{ \n      json: { \n        ...fileData,\n        uploadPayload: cleanPayload\n      } \n    }];\n  }\n\n  throw err;\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3296,
        2656
      ],
      "id": "6da68d78-d7f8-4114-8485-f37167ecb5f9",
      "name": "Check_File_SHA"
    },
    {
      "parameters": {
        "jsCode": "// ================================================\n// Fetch_And_Upload_To_Drive\n// This node should be placed AFTER Upload_PNGs_to_Drive\n// ================================================\n\nconst imageData = $input.first().json;\n\nconsole.log(`üì• Fetching ${imageData.filename} from GitHub...`);\n\n// Skip if no upload needed\nif (imageData.skipDriveUpload) {\n  return [{\n    json: {\n      ...imageData,\n      driveUploadSkipped: true\n    }\n  }];\n}\n\n// ================================================\n// 1Ô∏è‚É£ Fetch PNG from GitHub\n// ================================================\n\ntry {\n  const response = await this.helpers.httpRequest({\n    method: 'GET',\n    url: imageData.githubRawUrl,\n    encoding: null,  // Get binary data\n    returnFullResponse: true\n  });\n\n  const imageBuffer = Buffer.from(response.body);\n  const base64Image = imageBuffer.toString('base64');\n  \n  console.log(`‚úÖ Fetched ${imageData.filename}: ${imageBuffer.length} bytes`);\n\n  // ================================================\n  // 2Ô∏è‚É£ Prepare for Drive Upload\n  // ================================================\n\n  // Google Drive requires multipart/form-data for file upload\n  // We'll return the data needed for the next HTTP Request node\n  \n  return [{\n    json: {\n      ...imageData,\n      \n      // For Drive API\n      driveFileName: imageData.filename,\n      driveFolderId: imageData.driveFolderId,\n      \n      // Metadata for Drive API\n      driveMetadata: {\n        name: imageData.filename,\n        parents: [imageData.driveFolderId],\n        mimeType: 'image/png',\n        description: `${imageData.figureReference} from Section ${imageData.sectionNumber}`\n      },\n      \n      // Image data\n      imageBase64: base64Image,\n      imageSizeBytes: imageBuffer.length,\n      \n      // Status\n      readyForDriveUpload: true,\n      fetchedFromGithub: true\n    },\n    \n    // Also attach as binary for Drive upload\n    binary: {\n      data: {\n        data: imageBuffer,\n        mimeType: 'image/png',\n        fileName: imageData.filename\n      }\n    }\n  }];\n\n} catch (error) {\n  console.error(`‚ùå Failed to fetch ${imageData.filename}:`, error.message);\n  \n  return [{\n    json: {\n      ...imageData,\n      driveUploadFailed: true,\n      errorMessage: error.message\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5328,
        2640
      ],
      "id": "df753bf9-3de7-4b83-8113-002d07f8776e",
      "name": "Fetch_And_Upload_To_Drive"
    },
    {
      "parameters": {
        "jsCode": "// Format_Upload_Body - Creates clean JSON payload\nconst fileData = $input.first().json;\n\n// Build payload object\nconst payload = {\n  message: fileData.uploadPayload.message,\n  content: fileData.uploadPayload.content,\n  branch: fileData.uploadPayload.branch || \"main\"\n};\n\n// Only add SHA if it exists and is valid\nif (fileData.uploadPayload.sha && \n    fileData.uploadPayload.sha !== \"undefined\" && \n    fileData.uploadPayload.sha !== \"null\") {\n  payload.sha = fileData.uploadPayload.sha;\n}\n\nconsole.log('‚úÖ Upload payload prepared:', {\n  hasSHA: !!payload.sha,\n  messageLength: payload.message?.length,\n  contentLength: payload.content?.length\n});\n\nreturn [{\n  json: {\n    ...fileData,\n    formattedPayload: payload,  // ‚úÖ Clean payload\n    payloadJSON: JSON.stringify(payload)  // ‚úÖ As JSON string\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3424,
        2544
      ],
      "id": "9826ab0f-88c9-42bd-9476-0588f0fd9461",
      "name": "Format_Upload_Body"
    },
    {
      "parameters": {
        "jsCode": "// Format_Upload_Body - Creates clean JSON payload\nconst fileData = $input.first().json;\n\n// Build payload object\nconst payload = {\n  message: fileData.uploadFile.message,\n  content: fileData.uploadFile.content,\n  branch: fileData.uploadFile.branch || \"main\"\n};\n\n// Only add SHA if it exists and is valid\nif (fileData.uploadFile.sha && \n    fileData.uploadFile.sha !== \"undefined\" && \n    fileData.uploadFile.sha !== \"null\") {\n  payload.sha = fileData.uploadFile.sha;\n}\n\nconsole.log('‚úÖ Upload payload prepared:', {\n  hasSHA: !!payload.sha,\n  messageLength: payload.message?.length,\n  contentLength: payload.content?.length\n});\n\nreturn [{\n  json: {\n    ...fileData,\n    formattedPayload: payload,  // ‚úÖ Clean payload\n    payloadJSON: JSON.stringify(payload)  // ‚úÖ As JSON string\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3648,
        2944
      ],
      "id": "f63e0dff-8f29-47e5-8ae2-9385d1f34a5d",
      "name": "Format_Upload_Body1"
    },
    {
      "parameters": {
        "jsCode": "// Generate_Metadata_Files - COMPLETE FIXED VERSION (Handles undefined basePath)\nconst structuredDoc = $input.first().json.structuredDocument;\nconst metadata = structuredDoc.metadata;\nconst sections = structuredDoc.sections;\n\nconsole.log('üìÑ Generating metadata files...');\n\n// ================================================\n// 1Ô∏è‚É£ VERSION.md\n// ================================================\nconst versionContent = `# Document Version\n\n**Version**: 1.0.0\n**Document**: ${metadata.documentTitle}\n**Type**: ${metadata.documentType}\n**Created**: ${new Date(metadata.createdAt).toISOString().split('T')[0]}\n**Status**: Published\n\n---\n\n## Version History\n\n| Version | Date | Author | Description |\n|---------|------|--------|-------------|\n| 1.0.0 | ${new Date(metadata.createdAt).toISOString().split('T')[0]} | AI Documentation System | Initial release |\n\n---\n\n## Metadata\n\n- **Target Audience**: ${metadata.targetAudience}\n- **Total Sections**: ${metadata.totalSections}\n- **Chat ID**: ${metadata.chatId}\n\n---\n\n## Notes\n\nThis is the initial version of the document. Future updates will be tracked here.\n`;\n\n// ================================================\n// 2Ô∏è‚É£ CHANGELOG.md\n// ================================================\nconst changelogContent = `# Changelog\n\nAll notable changes to **${metadata.documentTitle}** will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n---\n\n## [1.0.0] - ${new Date(metadata.createdAt).toISOString().split('T')[0]}\n\n### Added\n- ‚úÖ Initial document structure with ${metadata.totalSections} sections\n- ‚úÖ Complete technical documentation for ${metadata.documentTitle}\n- ‚úÖ ${Object.values(sections).filter(s => s.diagram).length} diagrams and visual aids\n- ‚úÖ Comprehensive coverage of key topics\n\n### Document Features\n${Object.keys(sections).map(sectionNum => {\n  const section = sections[sectionNum];\n  const subsectionCount = section.subsections ? Object.keys(section.subsections).length : 0;\n  return `- **Section ${sectionNum}**: ${section.title} (${subsectionCount} subsections)`;\n}).join('\\n')}\n\n### Metadata\n- **Document Type**: ${metadata.documentType}\n- **Target Audience**: ${metadata.targetAudience}\n- **User Request**: ${metadata.userRequest}\n\n---\n\n## How to Read This Changelog\n\n- **Added**: New sections or features\n- **Changed**: Updates to existing sections\n- **Deprecated**: Features to be removed in future versions\n- **Removed**: Deleted sections or content\n- **Fixed**: Bug fixes or corrections\n- **Security**: Security-related changes\n`;\n\n// ================================================\n// 3Ô∏è‚É£ IMPACT_MATRIX.md\n// ================================================\n\n// Calculate impact scores for each section\nconst impactScores = Object.keys(sections).map(sectionNum => {\n  const section = sections[sectionNum];\n  \n  const contentLength = section.content?.length || 0;\n  const subsectionCount = section.subsections ? Object.keys(section.subsections).length : 0;\n  const hasDiagram = section.diagram ? 1 : 0;\n  \n  // Scoring formula (0-100)\n  const lengthScore = Math.min((contentLength / 100), 40);\n  const subsectionScore = subsectionCount * 10;\n  const diagramScore = hasDiagram * 20;\n  \n  const totalScore = Math.min(lengthScore + subsectionScore + diagramScore, 100);\n  \n  let criticality = 'Low';\n  if (totalScore >= 70) criticality = 'Critical';\n  else if (totalScore >= 50) criticality = 'High';\n  else if (totalScore >= 30) criticality = 'Medium';\n  \n  return {\n    sectionNum,\n    title: section.title,\n    score: Math.round(totalScore),\n    criticality,\n    contentLength,\n    subsectionCount,\n    hasDiagram,\n    dependencies: []\n  };\n});\n\nimpactScores.sort((a, b) => b.score - a.score);\n\nconst impactMatrixContent = `# Impact Matrix\n\n**Document**: ${metadata.documentTitle}\n**Generated**: ${new Date().toISOString().split('T')[0]}\n\n---\n\n## Overview\n\nThis matrix analyzes the relative importance and impact of each section in the document. \nThe impact score (0-100) is calculated based on:\n\n- **Content Depth**: Length and detail of section content (40%)\n- **Subsection Coverage**: Number of subsections (30%)\n- **Visual Aids**: Presence of diagrams (20%)\n- **Key Topics**: Breadth of topics covered (10%)\n\n---\n\n## Impact Rankings\n\n| Rank | Section | Title | Impact Score | Criticality | Content Size | Subsections | Diagram |\n|------|---------|-------|--------------|-------------|--------------|-------------|---------|\n${impactScores.map((item, index) => {\n  return `| ${index + 1} | ${item.sectionNum} | ${item.title} | ${item.score}/100 | ${item.criticality} | ${item.contentLength} chars | ${item.subsectionCount} | ${item.hasDiagram ? '‚úÖ' : '‚ùå'} |`;\n}).join('\\n')}\n\n---\n\n## Criticality Levels\n\n### Critical (Score: 70-100)\n**High-priority sections that form the foundation of the document.**\n\n${impactScores.filter(s => s.criticality === 'Critical').map(s => \n  `- **Section ${s.sectionNum}**: ${s.title} (${s.score}/100)`\n).join('\\n') || '_No critical sections_'}\n\n### High (Score: 50-69)\n**Important sections that provide significant value.**\n\n${impactScores.filter(s => s.criticality === 'High').map(s => \n  `- **Section ${s.sectionNum}**: ${s.title} (${s.score}/100)`\n).join('\\n') || '_No high-impact sections_'}\n\n### Medium (Score: 30-49)\n**Supporting sections that add context and detail.**\n\n${impactScores.filter(s => s.criticality === 'Medium').map(s => \n  `- **Section ${s.sectionNum}**: ${s.title} (${s.score}/100)`\n).join('\\n') || '_No medium-impact sections_'}\n\n### Low (Score: 0-29)\n**Supplementary sections with minimal direct impact.**\n\n${impactScores.filter(s => s.criticality === 'Low').map(s => \n  `- **Section ${s.sectionNum}**: ${s.title} (${s.score}/100)`\n).join('\\n') || '_No low-impact sections_'}\n\n---\n\n## Document Health Metrics\n\n- **Total Sections**: ${metadata.totalSections}\n- **Average Impact Score**: ${Math.round(impactScores.reduce((sum, s) => sum + s.score, 0) / impactScores.length)}\n- **Critical Sections**: ${impactScores.filter(s => s.criticality === 'Critical').length}\n- **Sections with Diagrams**: ${impactScores.filter(s => s.hasDiagram).length}\n- **Total Subsections**: ${impactScores.reduce((sum, s) => sum + s.subsectionCount, 0)}\n\n---\n\n## Recommendations\n\n${impactScores[0].score >= 70 \n  ? `‚úÖ **Strong Foundation**: Section ${impactScores[0].sectionNum} (${impactScores[0].title}) provides excellent coverage.`\n  : `‚ö†Ô∏è **Consider Enhancement**: Top section scores below 70. Consider adding more detail or diagrams.`\n}\n\n${impactScores.filter(s => s.criticality === 'Critical').length >= 3\n  ? `‚úÖ **Good Distribution**: ${impactScores.filter(s => s.criticality === 'Critical').length} critical sections ensure comprehensive coverage.`\n  : `‚ö†Ô∏è **Coverage Gap**: Only ${impactScores.filter(s => s.criticality === 'Critical').length} critical sections. Consider expanding key areas.`\n}\n\n${impactScores.filter(s => s.hasDiagram).length / metadata.totalSections >= 0.5\n  ? `‚úÖ **Visual Support**: ${Math.round((impactScores.filter(s => s.hasDiagram).length / metadata.totalSections) * 100)}% of sections include diagrams.`\n  : `üí° **Visualization Opportunity**: Only ${impactScores.filter(s => s.hasDiagram).length} sections have diagrams. Visual aids improve comprehension.`\n}\n`;\n\n// ================================================\n// 4Ô∏è‚É£ Get GitHub Config - FIXED to handle undefined basePath\n// ================================================\n\nlet github = $input.first().json.github;\n\nconsole.log('üîç Original GitHub config:', JSON.stringify(github, null, 2));\n\n// ‚≠ê CRITICAL FIX: Validate and fix basePath if it's undefined\nif (!github || !github.basePath || github.basePath === 'undefined') {\n  console.warn('‚ö†Ô∏è basePath is undefined, fixing...');\n  \n  // Get basePath from metadata.github (alternative source)\n  const metadataGithub = metadata.github;\n  \n  if (metadataGithub && metadataGithub.basePath && metadataGithub.basePath !== 'undefined') {\n    github = metadataGithub;\n    console.log('‚úÖ Using basePath from metadata.github:', github.basePath);\n  } else {\n    // Last resort: create a valid basePath\n    const timestamp = Date.now();\n    const safeTitle = metadata.documentTitle\n      .replace(/[^a-zA-Z0-9]/g, '_')\n      .toLowerCase()\n      .substring(0, 50);\n    \n    github = {\n      ...github,\n      basePath: `${safeTitle}_${timestamp}`,\n      owner: github?.owner || 'codewithshahzaib',\n      repo: github?.repo || 'Documentation_Upload_Project',\n      branch: github?.branch || 'main'\n    };\n    \n    console.log('üîß Created new basePath:', github.basePath);\n  }\n}\n\nconsole.log('‚úÖ Final GitHub config:', JSON.stringify(github, null, 2));\n\n// ‚≠ê FIXED: Proper metadata folder structure\nconst metadataFolder = 'Version_and_Impact_Analysis';\n\nconst metadataFiles = [\n  {\n    filename: 'VERSION.md',\n    content: versionContent,\n    description: 'Document version information'\n  },\n  {\n    filename: 'CHANGELOG.md',\n    content: changelogContent,\n    description: 'Document change history'\n  },\n  {\n    filename: 'IMPACT_MATRIX.md',\n    content: impactMatrixContent,\n    description: 'Section impact analysis'\n  }\n];\n\nconsole.log(`‚úÖ Generated ${metadataFiles.length} metadata files`);\nconsole.log(`üìÅ Base path: ${github.basePath}`);\nconsole.log(`üìÅ Metadata folder: ${metadataFolder}`);\nconsole.log(`üìÅ Full path: ${github.basePath}/${metadataFolder}`);\n\n// Return array of files to upload\nreturn metadataFiles.map(file => {\n  const fullPath = `${github.basePath}/${metadataFolder}/${file.filename}`;\n  const apiUrl = `https://api.github.com/repos/${github.owner}/${github.repo}/contents/${fullPath}`;\n  \n  console.log(`üìÑ Preparing ${file.filename}:`);\n  console.log(`   Path: ${fullPath}`);\n  console.log(`   API: ${apiUrl}`);\n  \n  return {\n    json: {\n      // File data\n      filename: file.filename,\n      content: file.content,\n      description: file.description,\n      \n      // GitHub config - ‚≠ê FIXED: Proper path construction\n      github: github,\n      githubPath: fullPath,\n      githubApiUrl: apiUrl,\n      \n      // Metadata\n      documentTitle: metadata.documentTitle,\n      chatId: metadata.chatId,\n      isMetadataFile: true,\n      metadataFolder: metadataFolder,\n      \n      // For GitHub upload\n      uploadPayload: {\n        message: `üìÑ Add ${file.description} for ${metadata.documentTitle}`,\n        content: Buffer.from(file.content).toString('base64'),\n        branch: github.branch || 'main'\n      }\n    }\n  };\n});\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4480,
        1744
      ],
      "id": "5f6d95c3-a5ed-4ff3-bdca-a829ede24cee",
      "name": "Generate_Metadata_Files"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "name": "Replace Me2",
      "typeVersion": 1,
      "position": [
        4896,
        1744
      ],
      "id": "5382231e-10c2-463a-bca8-219bd3869ba5"
    },
    {
      "parameters": {
        "jsCode": "// Check_Metadata_File_SHA - FIXED\nconst fileData = $input.first().json;\n\nconsole.log(`üîç Checking if ${fileData.filename} exists...`);\nconsole.log(`üìç URL: ${fileData.githubApiUrl}`);\n\ntry {\n  const response = await this.helpers.httpRequest({\n    method: 'GET',\n    url: fileData.githubApiUrl,\n    headers: {\n      'Accept': 'application/vnd.github.v3+json',\n      'Authorization': 'Bearer YOUR_GITHUB_TOKEN_HERE',\n      'User-Agent': 'n8n-workflow'\n    },\n    json: true,\n    returnFullResponse: true\n  });\n\n  // File exists - update payload with SHA\n  const sha = response.body.sha;\n  console.log(`‚úÖ File exists, SHA: ${sha.substring(0, 10)}...`);\n  \n  return [{\n    json: {\n      ...fileData,\n      uploadPayload: {\n        ...fileData.uploadPayload,\n        sha: sha  // Add SHA for update\n      },\n      fileExists: true,\n      mode: 'update'\n    }\n  }];\n\n} catch (error) {\n  // Check if it's a 404 (file doesn't exist)\n  if (error.response?.status === 404 || \n      error.statusCode === 404 || \n      error.message?.includes('404')) {\n    \n    console.log(`üìù ${fileData.filename} does not exist - will create new file`);\n    \n    // Return payload WITHOUT sha field (for new file creation)\n    return [{\n      json: {\n        ...fileData,\n        fileExists: false,\n        mode: 'create'\n      }\n    }];\n  }\n  \n  // For other errors, log details and throw\n  console.error('‚ùå GitHub API Error:', {\n    status: error.response?.status || error.statusCode,\n    message: error.message,\n    url: fileData.githubApiUrl\n  });\n  \n  throw new Error(`GitHub API error: ${error.message}`);\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5104,
        1744
      ],
      "id": "72907a13-03d5-4d3e-84d8-1c3bf5bda778",
      "name": "Check_Metadata_File_SHA"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        4688,
        1744
      ],
      "id": "b97158dc-dfda-4af0-aa42-b7e4606dd5af",
      "name": "Upload_Metadata_Files_Loop"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "={{ $json.githubApiUrl }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.uploadPayload) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        5296,
        1744
      ],
      "id": "0244da5f-cfc6-4e73-9679-977fdc794a3f",
      "name": "Upload_Metadata_To_GitHub"
    },
    {
      "parameters": {
        "jsCode": "// Merge_Metadata_Results\nconst uploadedFiles = $input.all();\n\nconsole.log(`‚úÖ Uploaded ${uploadedFiles.length} metadata files`);\n\nconst results = uploadedFiles.map(item => ({\n  filename: item.json.filename,\n  githubUrl: item.json.body?.content?.html_url || item.json.githubApiUrl,\n  uploaded: true\n}));\n\n// Pass through original structured document data\nconst originalData = $('Parse_Sections_to_Structured_JSON').first().json;\n\nreturn [{\n  json: {\n    ...originalData,\n    metadataFiles: results,\n    metadataUploaded: true\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4688,
        1952
      ],
      "id": "4da145de-91b4-4131-9f88-894a5f5fd165",
      "name": "Merge_Metadata_Results"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://bilalkhan.webzone.pk/convert",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "text/plain"
            }
          ]
        },
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "text/html",
        "body": "={{ $json.svg }}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2736,
        2656
      ],
      "id": "34d52831-748f-486e-9d0b-ebcf10a19df2",
      "name": "HTTP Request2",
      "retryOnFail": false,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "content": "Creating Medata files",
        "height": 384,
        "width": 1296
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        4368,
        1696
      ],
      "typeVersion": 1,
      "id": "39720cc0-d24c-4090-bb47-6a4a0e0da3c5",
      "name": "Sticky Note14"
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare_For_TOC_Generation\nconst repoInfo = $input.first().json;\n\n// This node formats data to match the expected input for TOC_Generator_Agent\nreturn [{\n  json: {\n    // Repository configuration (will override default hardcoded values)\n    github: repoInfo.github,\n    \n    // User context\n    chatId: repoInfo.chatId,\n    userMessage: repoInfo.userMessage,\n    \n    // Chat history (from Load Chat History node)\n    chatHistory: $('Load Chat History').first().json.chatHistory || '',\n    \n    // Flag for downstream nodes\n    usingNewRepo: true\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        912,
        2480
      ],
      "id": "c0387013-1aeb-4742-a6cf-38f0e9d59059",
      "name": "Prepare_For_TOC_Generation"
    },
    {
      "parameters": {
        "content": "Creating a feedback loop",
        "height": 464,
        "width": 2960
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -496,
        2944
      ],
      "typeVersion": 1,
      "id": "6adffe6e-5d3b-40ab-b143-f15c115673a0",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "jsCode": "// Node: Identify_Section_to_Update\n// Place this after \"Updating a section\" Telegram node\n\n// const userMessage = $('Telegram Trigger1').first().json.message.text;\n\n\nconst userMessage = $('Telegram Trigger1').first().json.message.text ?? $('Transcribes Audio1').first().json.text\nconst chatId = $('Telegram Trigger1').first().json.message.chat.id.toString();\n\nconsole.log('üîç Analyzing update request...');\nconsole.log('User message:', userMessage);\n\n// Extract section identifier using multiple patterns\nlet sectionNumber = null;\nlet updateInstruction = '';\n\n// Pattern 1: \"Update section 2.1 to include...\"\nconst pattern1 = userMessage.match(/update\\s+section\\s+([\\d.]+)\\s+to\\s+(.+)/i);\nif (pattern1) {\n  sectionNumber = pattern1[1];\n  updateInstruction = pattern1[2];\n}\n\n// Pattern 2: \"Modify section 3: add more details about...\"\nconst pattern2 = userMessage.match(/(?:modify|change|edit)\\s+section\\s+([\\d.]+)[\\s:]+(.+)/i);\nif (pattern2) {\n  sectionNumber = pattern2[1];\n  updateInstruction = pattern2[2];\n}\n\n// Pattern 3: \"In section 1.2, please...\"\nconst pattern3 = userMessage.match(/in\\s+section\\s+([\\d.]+)[,\\s]+(.+)/i);\nif (pattern3) {\n  sectionNumber = pattern3[1];\n  updateInstruction = pattern3[2];\n}\n\n// Pattern 4: Generic section mention\nconst pattern4 = userMessage.match(/section\\s+([\\d.]+)/i);\nif (pattern4 && !sectionNumber) {\n  sectionNumber = pattern4[1];\n  updateInstruction = userMessage;\n}\n\nif (!sectionNumber) {\n  throw new Error('‚ùå Could not identify section number. Please specify like \"Update section 2.1\"');\n}\n\nconsole.log('‚úÖ Identified section:', sectionNumber);\nconsole.log('üìù Update instruction:', updateInstruction);\n\nreturn [{\n  json: {\n    sectionNumber: sectionNumber,\n    updateInstruction: updateInstruction,\n    originalMessage: userMessage,\n    chatId: chatId,\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -224,
        2992
      ],
      "id": "854a77d5-0dcd-41fb-9a5c-564691af542d",
      "name": "Identify_Section_to_Update"
    },
    {
      "parameters": {
        "jsCode": "// Node: Fetch_Current_Document_State\n// Place after Identify_Section_to_Update\n\nconst sectionInfo = $input.first().json;\nconst chatId = sectionInfo.chatId;\n\nconsole.log('üì• Fetching current document state from chat history...');\n\n// Access workflow static data to get chat history\nconst staticData = $getWorkflowStaticData('global');\nconst chatHistory = staticData.chatHistory?.[chatId];\n\nif (!chatHistory) {\n  throw new Error('‚ùå No document found for this chat. Please generate a document first.');\n}\n\n// Find the most recent document generation\nlet lastDocumentData = null;\nlet lastGitHubData = null;\nlet lastGoogleDocData = null;\n\n// Search backwards through chat history for document metadata\nfor (let i = chatHistory.length - 1; i >= 0; i--) {\n  const entry = chatHistory[i];\n  \n  // Look for document generation markers\n  if (entry.content && typeof entry.content === 'string') {\n    if (entry.content.includes('documentId') || entry.content.includes('github.repo')) {\n      try {\n        // Try to extract JSON from the message\n        const jsonMatch = entry.content.match(/\\{[\\s\\S]*\\}/);\n        if (jsonMatch) {\n          const data = JSON.parse(jsonMatch[0]);\n          if (data.documentId) lastGoogleDocData = data;\n          if (data.github) lastGitHubData = data;\n          if (data.sections) lastDocumentData = data;\n        }\n      } catch (e) {\n        // Continue searching\n      }\n    }\n  }\n}\n\n// Alternative: Try to fetch from workflow execution history\n// This requires checking recent workflow executions\nlet documentStructure = null;\nlet githubConfig = null;\nlet googleDocId = null;\n\ntry {\n  // Attempt to get from Parse_Sections_to_Structured_JSON node\n  const parseNode = $('Parse_Sections_to_Structured_JSON');\n  if (parseNode && parseNode.first()) {\n    documentStructure = parseNode.first().json.structuredDocument;\n    githubConfig = parseNode.first().json.github;\n  }\n} catch (e) {\n  console.log('‚ö†Ô∏è Could not access Parse_Sections_to_Structured_JSON');\n}\n\ntry {\n  // Attempt to get Google Doc ID\n  const docNode = $('Create Google Doc');\n  if (docNode && docNode.first()) {\n    googleDocId = docNode.first().json.documentId;\n  }\n} catch (e) {\n  console.log('‚ö†Ô∏è Could not access Create Google Doc');\n}\n\n// Fallback: Use hardcoded default repository\nif (!githubConfig) {\n  githubConfig = {\n    owner: 'codewithshahzaib',\n    repo: 'Documentation_Upload_Project',\n    branch: 'main',\n    basePath: 'documents'\n  };\n  console.log('‚ö†Ô∏è Using default GitHub configuration');\n}\n\nconsole.log('‚úÖ Document state retrieved');\nconsole.log('üì¶ GitHub:', githubConfig?.repo);\nconsole.log('üìÑ Google Doc:', googleDocId || 'Not found');\n\nreturn [{\n  json: {\n    // Section update info\n    sectionNumber: sectionInfo.sectionNumber,\n    updateInstruction: sectionInfo.updateInstruction,\n    originalMessage: sectionInfo.originalMessage,\n    chatId: chatId,\n    \n    // Document state\n    documentStructure: documentStructure,\n    githubConfig: githubConfig,\n    googleDocId: googleDocId,\n    \n    // Metadata\n    timestamp: new Date().toISOString(),\n    hasDocumentState: !!documentStructure,\n    hasGitHubConfig: !!githubConfig,\n    hasGoogleDocId: !!googleDocId\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -16,
        2992
      ],
      "id": "15beb6cc-ae58-4ce4-b421-f86040b6644d",
      "name": "Fetch_Current_Document_State"
    },
    {
      "parameters": {
        "jsCode": "// Node: Fetch_Section_from_GitHub (FIXED)\n// This now searches in the correct timestamped folder\n\nconst data = $input.first().json;\nconst github = data.githubConfig;\nconst sectionNumber = data.sectionNumber;\n\nconsole.log('üì• Fetching document from GitHub...');\n\nif (!github || !github.owner || !github.repo) {\n  throw new Error('‚ùå GitHub configuration not found');\n}\n\n// CRITICAL FIX: Search in the correct basePath\n// For new documents, basePath is like \"Documentation_Sections\" or \"technical_doc_1234567890\"\n// For old default repo, it's \"documents\"\nconst searchPath = github.basePath || 'documents';\n\nconsole.log('üîç Searching in:', `${github.owner}/${github.repo}/${searchPath}`);\n\n// Strategy:\n// 1. List all files in the basePath\n// 2. Find JSON files\n// 3. Get the most recent one by timestamp or modification date\n\nreturn [{\n  json: {\n    ...data,\n    githubListUrl: `https://api.github.com/repos/${github.owner}/${github.repo}/contents/${searchPath}`,\n    needsFileListing: true,\n    searchingInPath: searchPath\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        656,
        2992
      ],
      "id": "cb60e4c1-21e9-41d3-b7cd-2236805dba47",
      "name": "Fetch_Section_from_GitHub"
    },
    {
      "parameters": {
        "url": "={{ $json.githubListUrl }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        864,
        2992
      ],
      "id": "15cc055b-c4db-444e-a6bd-b80017942811",
      "name": "List GitHub Files"
    },
    {
      "parameters": {
        "jsCode": "// Get the input data from the previous node\nconst inputData = $input.first().json;\n\nconsole.log('Input keys:', Object.keys(inputData));\n\n// The data is wrapped in a 'data' key, so extract it first\nlet documentJson = inputData.data || inputData.fullDocument || inputData;\n\n// If it's still wrapped, try to unwrap further\nif (documentJson && documentJson.data) {\n  documentJson = documentJson.data;\n}\n\n// If there's a string field that needs parsing, handle it\nif (typeof documentJson === 'string') {\n  try {\n    documentJson = JSON.parse(documentJson);\n  } catch (e) {\n    console.error('Failed to parse JSON string:', e);\n    return [{\n      json: {\n        error: 'Failed to parse document JSON',\n        rawInput: inputData\n      }\n    }];\n  }\n}\n\nconsole.log('Document keys after extraction:', Object.keys(documentJson));\nconsole.log('Has metadata?', !!documentJson.metadata);\nconsole.log('Has sections?', !!documentJson.sections);\nconsole.log('Total sections in metadata:', documentJson.metadata?.totalSections);\nconsole.log('Actual sections found:', documentJson.sections ? Object.keys(documentJson.sections) : 'No sections found');\nconsole.log('Section keys:', documentJson.sections ? Object.keys(documentJson.sections).join(', ') : 'none');\n\nconst results = [];\n\n// Extract metadata\nif (documentJson.metadata) {\n  results.push({\n    json: {\n      type: 'metadata',\n      documentTitle: documentJson.metadata.documentTitle || null,\n      documentType: documentJson.metadata.documentType || null,\n      targetAudience: documentJson.metadata.targetAudience || null,\n      chatId: documentJson.metadata.chatId || null,\n      totalSections: documentJson.metadata.totalSections || null,\n      createdAt: documentJson.metadata.createdAt || null,\n      version: documentJson.metadata.version || null,\n      userRequest: documentJson.metadata.userRequest || null\n    }\n  });\n}\n\n// Extract sections and subsections\nif (documentJson.sections && typeof documentJson.sections === 'object') {\n  for (const sectionNum in documentJson.sections) {\n    const section = documentJson.sections[sectionNum];\n    \n    // Add the main section\n    results.push({\n      json: {\n        type: 'section',\n        sectionNumber: sectionNum,\n        title: section.title || null,\n        content: section.content || null,\n        contentLength: section.content ? section.content.length : 0,\n        hasSubsections: section.subsections ? Object.keys(section.subsections).length > 0 : false,\n        subsectionCount: section.subsections ? Object.keys(section.subsections).length : 0,\n        url:section.url\n      }\n    });\n    \n    // Extract subsections\n    if (section.subsections && typeof section.subsections === 'object') {\n      for (const subNum in section.subsections) {\n        const subsection = section.subsections[subNum];\n        \n        results.push({\n          json: {\n            type: 'subsection',\n            sectionNumber: sectionNum,\n            subsectionNumber: subNum,\n            fullNumber: `${sectionNum}.${subNum}`,\n            title: subsection.title || null,\n            content: subsection.content || null,\n            contentLength: subsection.content ? subsection.content.length : 0,\n            hasKeyConsiderations: !!subsection.keyConsiderations,\n            hasBestPractices: !!subsection.bestPractices,\n            hasNotes: !!subsection.notes,\n            // Include the actual data if present\n            keyConsiderations: subsection.keyConsiderations || null,\n            bestPractices: subsection.bestPractices || null,\n            notes: subsection.notes || null\n          }\n        });\n      }\n    }\n  }\n}\n\nconsole.log(`‚úÖ Extracted ${results.length} items`);\nconsole.log('Items breakdown:');\nconsole.log('- Metadata items:', results.filter(r => r.json.type === 'metadata').length);\nconsole.log('- Section items:', results.filter(r => r.json.type === 'section').length);\nconsole.log('- Subsection items:', results.filter(r => r.json.type === 'subsection').length);\n\n// If no results, return debug info\nif (results.length === 0) {\n  return [{\n    json: {\n      error: 'No data extracted',\n      inputKeys: Object.keys(inputData),\n      documentKeys: Object.keys(documentJson),\n      hasMetadata: !!documentJson.metadata,\n      hasSections: !!documentJson.sections,\n      sectionKeys: documentJson.sections ? Object.keys(documentJson.sections) : [],\n      rawDataSample: JSON.stringify(documentJson).substring(0, 500)\n    }\n  }];\n}\n\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1440,
        2992
      ],
      "id": "91ae23ec-44f1-44b5-93ff-2bea886b829c",
      "name": "Fetch_Document_JSON"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are an Enterprise Technical Writer responsible for updating an existing document section.\n\n**IMPORTANT RULES ‚Äî DO NOT VIOLATE THESE:**\n1. This is an UPDATE, not a rewrite or new section.\n2. You MUST return the **entire section**, including ALL subsections (e.g., 2.1, 2.2, 2.3, etc.).\n3. DO NOT remove, merge, or renumber any subsections.\n4. Only change content that the update request explicitly addresses.\n5. Preserve the document‚Äôs tone, structure, formatting style, and technical depth.\n6. Maintain Markdown formatting, headings, ordered hierarchy, and bullet structure.\n7. If a subsection is not touched by the update request, return its ORIGINAL content unchanged.\n8. The ‚Äúcontent‚Äù field must contain the **full parent section**, including all subsections rendered inline in Markdown.\n\n---\n\n# DOCUMENT CONTEXT\nDocument Title: {{ $json._originalData.allSections[0].documentTitle }}\nDocument Type: {{ $json._originalData.allSections[0].documentType }}\nTarget Audience: {{ $json._originalData.allSections[0].targetAudience }}\n\n---\n\n# SECTION TO UPDATE\nSection Number: **{{ $json._originalData.mainSectionNumber }}**\nSection Title: **{{ $json._originalData.mainSectionTitle }}**\n\n## Current Main Section Content:\n{{ $json._originalData.mainSectionContent }}\n\n## Current Subsections (FULL STRUCTURE):\n{{ $json._originalData.subsections }}\n\n---\n\n# UPDATE REQUEST\n{{ $json._originalData.updateRequest }}\n\n# Original User Message\n{{ $json._originalData.originalUserMessage }}\n\n---\n\n# YOUR TASK\nYour job is to:\n\n1. Review the update request carefully.\n2. Identify exactly what should be changed.\n3. Apply modifications ONLY where relevant.\n4. Regenerate:\n   - the entire **parent section**, and\n   - ALL subsections\n   even if only one subsection is updated.\n5. Ensure the final output reads cohesively and professionally.\n6. Add clarifying details when appropriate, but do NOT invent new functionality or content beyond the request.\n7. Produce a clean and complete JSON object that matches the required schema EXACTLY.\n\n---\n\n# REQUIRED OUTPUT JSON SCHEMA\nReturn your final answer in this exact structure:\n\n```json\n{\n  \"sectionNumber\": \"{{ $json._originalData.mainSectionNumber }}\",\n  \"title\": \"Updated or original section title\",\n  \"content\": \"Full updated section content in Markdown format, including all subsections in order\",\n  \"changesSummary\": \"Bullet-point summary of exactly what was changed\",\n  \"subsections\": {\n    \"X.Y\": {\n      \"title\": \"Subsection title\",\n      \"content\": \"Updated or original subsection content\"\n    }\n  }\n}\nCRITICAL:\n\n\nThe \"content\" field MUST contain the entire rendered section, including all subsection headings.\n\n\nThe \"subsections\" object MUST contain each subsection individually as separate entries.\n\n\nNo fields may be omitted, renamed or reformatted.\n\n\n\nEXAMPLE OF WHAT ‚ÄúCONTENT‚Äù MUST LOOK LIKE (STRUCTURE ONLY)\n## 2. MLOps Lifecycle and Workflow\n\nIntro paragraph...\n\n### 2.1 First Subsection Title\nContent...\n\n### 2.2 Second Subsection Title\nContent...\n\n### 2.3 Third Subsection Title\nContent...\n\nThis is an example of required format, NOT actual content.\n\nFINAL INSTRUCTION\nReturn ONLY the JSON object. Do NOT include explanations, notes, or commentary.\n",
        "hasOutputParser": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        2016,
        2992
      ],
      "id": "b590e75b-6154-4b72-ae68-ade4717243a0",
      "name": "Regenerate_Section_Agent",
      "executeOnce": false
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2016,
        3280
      ],
      "id": "c62e78ed-8959-4a84-9bf7-3ac95a67e8ca",
      "name": "OpenAI Chat Model5",
      "credentials": {
        "openAiApi": {
          "id": "bhBOpGB6JIUeu4NX",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "=üìù *Updating the Exisiting section*\n\n   I'll update your document based on your requirements.\n   \n   Specifications: \"{{ $('Telegram Trigger1').first().json.message.text }}\"\n   \n   Starting generation process...",
        "additionalFields": {
          "appendAttribution": false,
          "parse_mode": "HTML"
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -400,
        2992
      ],
      "id": "d8af9a26-39f5-493d-9d8d-0f3a82061446",
      "name": "Updating Existing Document",
      "webhookId": "4e0b5441-1c50-43a0-9473-ea2b81339dc2",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "url": "={{ $json.githubFileUrl }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1248,
        2992
      ],
      "id": "d74f514a-c59d-4a51-8c85-7bb99a15864e",
      "name": "Fetch_JSON_Directly"
    },
    {
      "parameters": {
        "jsCode": "// ==============================\n// Extract entire main section with all subsections\n// ==============================\n\n// User requested section/subsection (e.g., \"2.3\")\nconst requestedSection = $('Find_Technical_Doc_JSON').first().json.sectionNumber;\nconst allItems = $input.all();\n\nconsole.log('üéØ Requested section/subsection:', requestedSection);\nconsole.log('üì¶ Total items in document:', allItems.length);\n\n// Normalize numbers for comparison\nconst normalize = (num) => num?.toString().trim();\n\n// Step 1: Find the main section number from the requested input\n// If input is \"2.3\", main section is \"2\"\nconst mainSectionNumber = requestedSection.split('.')[0];\n\n// Step 2: Find main section\nconst mainSection = allItems.find(item =>\n  item.json.type === 'subsection' && normalize(item.json.sectionNumber) === mainSectionNumber\n)?.json;\n\nif (!mainSection) {\n  console.error('‚ùå Main section not found:', mainSectionNumber);\n  return [{\n    json: {\n      error: 'Main section not found',\n      requestedSection,\n      message: `No main section found for \"${mainSectionNumber}\"`\n    }\n  }];\n}\n\n// Step 3: Collect all subsections that belong to this main section\nconst subsections = allItems\n  .filter(item => item.json.type === 'subsection' && normalize(item.json.sectionNumber) === mainSectionNumber)\n  .map(item => item.json);\n\nconsole.log(`‚úÖ Found main section: ${mainSectionNumber} with ${subsections.length} subsections.`);\n\n// Step 4: Get metadata\nconst metadata = allItems.find(item => item.json.type === 'metadata')?.json || {};\n\n// Step 5: Get user update instructions\nconst userUpdate = $('Find_Technical_Doc_JSON').first().json.updateInstruction || \"\";\nconst originalMessage = $('Find_Technical_Doc_JSON').first().json.originalMessage || userUpdate;\n\n// Step 6: Build output\nconst output = {\n  found: true,\n  requestedSection,\n  mainSectionNumber,\n  mainSectionTitle: mainSection.title,\n  mainSectionContent: mainSection.content || '',\n  mainSectionContentLength: mainSection.content?.length || 0,\n  sectionType: mainSection.type,\n  subsections: subsections, // All subsections included\n  updateRequest: userUpdate,\n  originalUserMessage: originalMessage,\n  promptData: {\n    mainSectionNumber,\n    mainSectionTitle: mainSection.title,\n    mainSectionContent: mainSection.content || '',\n    subsections: subsections.length ? subsections.map(s => ({ number: s.subsectionNumber, title: s.title, content: s.content })) : 'No subsections',\n    updateRequest: userUpdate,\n    originalUserMessage: originalMessage\n  },\n  documentTitle: metadata.documentTitle || 'Unknown',\n  documentType: metadata.documentType || 'Unknown',\n  targetAudience: metadata.targetAudience || 'Unknown',\n  originalData: mainSection,\n  allSections: allItems.map(item => item.json)\n};\n\nconsole.log('üéØ Output mainSectionNumber:', output.mainSectionNumber);\n\nreturn [{ json: output }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1632,
        2992
      ],
      "id": "97db5f17-d740-483c-b56a-88cd8444168b",
      "name": "Extract Specific Section"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"sectionNumber\": \"string\",\n  \"title\": \"string\",\n  \"content\": \"string\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        2176,
        3296
      ],
      "id": "27f528e7-be89-45fd-9e49-fcbb319d78b9",
      "name": "Structured Output Parser1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://docs.googleapis.com/v1/documents",
        "authentication": "genericCredentialType",
        "genericAuthType": "oAuth2Api",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "ID",
              "value": "https://drive.google.com/drive/folders/1gQ1KI3WFQzhbG-ht2KtGIQKz1rS50wYl"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"title\": \"{{ $('Merge_Updated_Section_into_Document').item.json.structuredDocument.metadata.documentTitle }}\"\n\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2448,
        3488
      ],
      "id": "bf3d6b2e-6957-4f04-8a82-c133d06011c9",
      "name": "Create Google Doc1",
      "credentials": {
        "oAuth2Api": {
          "id": "6VtG2NAOONCkC0aw",
          "name": "Google Drive Docs API Credentials"
        },
        "googleApi": {
          "id": "VAyf52O8khcSNbmc",
          "name": "Google Service Account account 4"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Google Docs Document Generator for n8n\n// This node creates a fully formatted Google Doc from structured JSON\n\n// FIX: Use the merged document from the previous node (Merge_Updated_Section_into_Document) instead of the non-executed 'Parse_Sections_to_Structured_JSON'\nconst inputData = $input.first().json;\n\n// Add error handling: Check if structuredDocument exists\nif (!inputData || !inputData.structuredDocument) {\n  throw new Error('‚ùå No structuredDocument found in input. Ensure the previous node (Merge_Updated_Section_into_Document) has executed and passed the data correctly.');\n}\n\nconst structuredDoc = inputData.structuredDocument;\n\n// Add check for metadata\nif (!structuredDoc.metadata) {\n  throw new Error('‚ùå Metadata not found in structuredDocument. Check the document structure.');\n}\n\nconst metadata = structuredDoc.metadata;\n\nconsole.log(`üìÑ Generating Google Docs requests for: ${metadata.documentTitle}`);\n\n// Google Docs API batch requests array\nconst requests = [];\nlet currentIndex = 1; // Start after the title\n\n// Helper: Create text style\nfunction createTextStyle(bold = false, fontSize = 11, namedStyleType = 'NORMAL_TEXT') {\n  return {\n    bold: bold,\n    fontSize: { magnitude: fontSize, unit: 'PT' },\n    weightedFontFamily: { fontFamily: 'Arial' }\n  };\n}\n\n// Helper: Create paragraph style\nfunction createParagraphStyle(namedStyleType = 'NORMAL_TEXT', alignment = 'START', spaceAbove = 0, spaceBelow = 0) {\n  return {\n    namedStyleType: namedStyleType,\n    alignment: alignment,\n    spaceAbove: { magnitude: spaceAbove, unit: 'PT' },\n    spaceBelow: { magnitude: spaceBelow, unit: 'PT' }\n  };\n}\n\n// 1. Insert Document Title\nrequests.push({\n  insertText: {\n    location: { index: 1 },\n    text: `${metadata.documentTitle}\\n\\n`\n  }\n});\n\nrequests.push({\n  updateParagraphStyle: {\n    range: { startIndex: 1, endIndex: metadata.documentTitle.length + 1 },\n    paragraphStyle: createParagraphStyle('TITLE', 'CENTER', 0, 12),\n    fields: 'namedStyleType,alignment,spaceBelow'\n  }\n});\n\ncurrentIndex += metadata.documentTitle.length + 2;\n\n// 2. Insert Document Metadata\nconst metadataText = `Document Type: ${metadata.documentType}\\nTarget Audience: ${metadata.targetAudience}\\nGenerated: ${new Date(metadata.createdAt).toLocaleDateString()}\\n\\n`;\n\nrequests.push({\n  insertText: {\n    location: { index: currentIndex },\n    text: metadataText\n  }\n});\n\nrequests.push({\n  updateTextStyle: {\n    range: { startIndex: currentIndex, endIndex: currentIndex + metadataText.length },\n    textStyle: createTextStyle(false, 10),\n    fields: 'fontSize,weightedFontFamily'\n  }\n});\n\nrequests.push({\n  updateParagraphStyle: {\n    range: { startIndex: currentIndex, endIndex: currentIndex + metadataText.length },\n    paragraphStyle: createParagraphStyle('NORMAL_TEXT', 'CENTER', 0, 12),\n    fields: 'alignment,spaceBelow'\n  }\n});\n\ncurrentIndex += metadataText.length;\n\n// 3. Insert Page Break before content\nrequests.push({\n  insertPageBreak: {\n    location: { index: currentIndex }\n  }\n});\n\ncurrentIndex += 1;\n\n// 4. Process each section\nconst sectionNumbers = Object.keys(structuredDoc.sections).sort((a, b) => {\n  const numA = parseFloat(a);\n  const numB = parseFloat(b);\n  return numA - numB;\n});\n\nfor (const sectionNum of sectionNumbers) {\n  const section = structuredDoc.sections[sectionNum];\n  \n  console.log(`Processing Section ${sectionNum}: ${section.title}`);\n  \n  // Section Header (## X. Title)\n  const sectionHeader = `${sectionNum}. ${section.title}\\n\\n`;\n  const sectionHeaderStart = currentIndex;\n  \n  requests.push({\n    insertText: {\n      location: { index: currentIndex },\n      text: sectionHeader\n    }\n  });\n  \n  requests.push({\n    updateParagraphStyle: {\n      range: { startIndex: sectionHeaderStart, endIndex: sectionHeaderStart + sectionHeader.length },\n      paragraphStyle: createParagraphStyle('HEADING_1', 'START', 12, 6),\n      fields: 'namedStyleType,spaceAbove,spaceBelow'\n    }\n  });\n  \n  currentIndex += sectionHeader.length;\n  \n  // Section Main Content\n  if (section.content && section.content.trim()) {\n    const contentText = `${section.content.trim()}\\n\\n`;\n    \n    requests.push({\n      insertText: {\n        location: { index: currentIndex },\n        text: contentText\n      }\n    });\n    \n    requests.push({\n      updateParagraphStyle: {\n        range: { startIndex: currentIndex, endIndex: currentIndex + contentText.length },\n        paragraphStyle: createParagraphStyle('NORMAL_TEXT', 'START', 0, 6),\n        fields: 'namedStyleType,spaceBelow'\n      }\n    });\n    \n    currentIndex += contentText.length;\n  }\n  \n  // Process Subsections\n  if (section.subsections) {\n    const subsectionNumbers = Object.keys(section.subsections).sort((a, b) => {\n      const partsA = a.split('.').map(Number);\n      const partsB = b.split('.').map(Number);\n      for (let i = 0; i < Math.max(partsA.length, partsB.length); i++) {\n        const diff = (partsA[i] || 0) - (partsB[i] || 0);\n        if (diff !== 0) return diff;\n      }\n      return 0;\n    });\n    \n    for (const subsectionNum of subsectionNumbers) {\n      const subsection = section.subsections[subsectionNum];\n      \n      console.log(`  Processing Subsection ${subsectionNum}: ${subsection.title}`);\n      \n      // Subsection Header (### X.Y Title)\n      const subsectionHeader = `${subsectionNum} ${subsection.title}\\n\\n`;\n      const subsectionHeaderStart = currentIndex;\n      \n      requests.push({\n        insertText: {\n          location: { index: currentIndex },\n          text: subsectionHeader\n        }\n      });\n      \n      requests.push({\n        updateParagraphStyle: {\n          range: { startIndex: subsectionHeaderStart, endIndex: subsectionHeaderStart + subsectionHeader.length },\n          paragraphStyle: createParagraphStyle('HEADING_2', 'START', 8, 4),\n          fields: 'namedStyleType,spaceAbove,spaceBelow'\n        }\n      });\n      \n      currentIndex += subsectionHeader.length;\n      \n      // Subsection Content\n      if (subsection.content && subsection.content.trim()) {\n        const subContentText = `${subsection.content.trim()}\\n\\n`;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: subContentText\n          }\n        });\n        \n        requests.push({\n          updateParagraphStyle: {\n            range: { startIndex: currentIndex, endIndex: currentIndex + subContentText.length },\n            paragraphStyle: createParagraphStyle('NORMAL_TEXT', 'START', 0, 6),\n            fields: 'namedStyleType,spaceBelow'\n          }\n        });\n        \n        currentIndex += subContentText.length;\n      }\n      \n      // Key Considerations\n      if (subsection.keyConsiderations) {\n        const kcHeader = 'Key Considerations:\\n';\n        const kcHeaderStart = currentIndex;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: kcHeader\n          }\n        });\n        \n        requests.push({\n          updateTextStyle: {\n            range: { startIndex: kcHeaderStart, endIndex: kcHeaderStart + kcHeader.length },\n            textStyle: createTextStyle(true, 11),\n            fields: 'bold,fontSize'\n          }\n        });\n        \n        currentIndex += kcHeader.length;\n        \n        // Process Key Considerations items\n        const kcItems = Array.isArray(subsection.keyConsiderations) \n          ? subsection.keyConsiderations \n          : Object.entries(subsection.keyConsiderations);\n        \n        for (const item of kcItems) {\n          let itemText;\n          if (Array.isArray(item)) {\n            itemText = `‚Ä¢ ${item[0]}: ${item[1]}\\n`;\n          } else {\n            itemText = `‚Ä¢ ${item}\\n`;\n          }\n          \n          requests.push({\n            insertText: {\n              location: { index: currentIndex },\n              text: itemText\n            }\n          });\n          \n          currentIndex += itemText.length;\n        }\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: '\\n'\n          }\n        });\n        \n        currentIndex += 1;\n      }\n      \n      // Best Practices\n      if (subsection.bestPractices) {\n        const bpHeader = 'Best Practices:\\n';\n        const bpHeaderStart = currentIndex;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: bpHeader\n          }\n        });\n        \n        requests.push({\n          updateTextStyle: {\n            range: { startIndex: bpHeaderStart, endIndex: bpHeaderStart + bpHeader.length },\n            textStyle: createTextStyle(true, 11),\n            fields: 'bold,fontSize'\n          }\n        });\n        \n        currentIndex += bpHeader.length;\n        \n        // Process Best Practices items\n        const bpItems = Array.isArray(subsection.bestPractices) \n          ? subsection.bestPractices \n          : Object.values(subsection.bestPractices);\n        \n        for (const item of bpItems) {\n          const itemText = `‚Ä¢ ${item}\\n`;\n          \n          requests.push({\n            insertText: {\n              location: { index: currentIndex },\n              text: itemText\n            }\n          });\n          \n          currentIndex += itemText.length;\n        }\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: '\\n'\n          }\n        });\n        \n        currentIndex += 1;\n      }\n      \n      // Notes\n      if (subsection.notes) {\n        const noteText = `üìù Note: ${subsection.notes}\\n\\n`;\n        const noteStart = currentIndex;\n        \n        requests.push({\n          insertText: {\n            location: { index: currentIndex },\n            text: noteText\n          }\n        });\n        \n        requests.push({\n          updateTextStyle: {\n            range: { startIndex: noteStart, endIndex: noteStart + noteText.length },\n            textStyle: {\n              italic: true,\n              fontSize: { magnitude: 10, unit: 'PT' },\n              foregroundColor: { color: { rgbColor: { red: 0.4, green: 0.4, blue: 0.4 } } }\n            },\n            fields: 'italic,fontSize,foregroundColor'\n          }\n        });\n        \n        currentIndex += noteText.length;\n      }\n    }\n  }\n  \n  // Add diagram placeholder if present\n  if (section.diagram) {\n    const diagramNote = `[Diagram: ${section.diagram.title || 'Process Flow'}]\\nDiagram available at: ${metadata.github.rawBaseUrl || 'GitHub repository'}\\n\\n`;\n    const diagramStart = currentIndex;\n    \n    requests.push({\n      insertText: {\n        location: { index: currentIndex },\n        text: diagramNote\n      }\n    });\n    \n    requests.push({\n      updateTextStyle: {\n        range: { startIndex: diagramStart, endIndex: diagramStart + diagramNote.length },\n        textStyle: {\n          italic: true,\n          fontSize: { magnitude: 10, unit: 'PT' },\n          backgroundColor: { color: { rgbColor: { red: 0.95, green: 0.95, blue: 0.95 } } }\n        },\n        fields: 'italic,fontSize,backgroundColor'\n      }\n    });\n    \n    currentIndex += diagramNote.length;\n  }\n  \n  // Add spacing between sections\n  requests.push({\n    insertText: {\n      location: { index: currentIndex },\n      text: '\\n'\n    }\n  });\n  \n  currentIndex += 1;\n}\n\nconsole.log(`‚úÖ Generated ${requests.length} Google Docs API requests`);\n\n// Return the requests array for Google Docs API\nreturn [{\n  json: {\n    requests: requests,\n    documentTitle: metadata.documentTitle,\n    totalRequests: requests.length,\n    chatId: metadata.chatId,\n    metadata: {\n      sections: Object.keys(structuredDoc.sections).length,\n      timestamp: new Date().toISOString()\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2224,
        3488
      ],
      "id": "b3e44107-eb86-480f-a636-438820cee9fa",
      "name": "Prepare Google Docs Requests1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://docs.googleapis.com/v1/documents/{{ $('Create Google Doc1').item.json.documentId }}:batchUpdate",
        "authentication": "genericCredentialType",
        "genericAuthType": "oAuth2Api",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"requests\": {{ JSON.stringify($('Prepare Google Docs Requests1').item.json.requests) }}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2656,
        3488
      ],
      "id": "4386246d-5b26-48ae-9eac-ea87d67776e6",
      "name": "Format Google Doc1",
      "credentials": {
        "oAuth2Api": {
          "id": "6VtG2NAOONCkC0aw",
          "name": "Google Drive Docs API Credentials"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const documentId = $('Create Google Doc1').first().json.documentId;\nconst documentTitle = $json.documentTitle;\n\nconst docLink = `https://docs.google.com/document/d/${documentId}/edit`;\nconst viewLink = `https://docs.google.com/document/d/${documentId}/view`;\n\nconsole.log(`‚úÖ Document created: ${documentTitle}`);\nconsole.log(`üîó Edit Link: ${docLink}`);\n\nreturn [{\n  json: {\n    documentId: documentId,\n    documentTitle: documentTitle,\n    editLink: docLink,\n    viewLink: viewLink,\n    createdAt: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2880,
        3488
      ],
      "id": "70bb94bd-b4a5-4454-912d-c5670125a58f",
      "name": "Generate Document Link1"
    },
    {
      "parameters": {
        "content": "Creating a feedback loop",
        "height": 208,
        "width": 3808
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -496,
        3440
      ],
      "typeVersion": 1,
      "id": "b93b5758-d260-4c4d-812c-16f8990c5227",
      "name": "Sticky Note11"
    },
    {
      "parameters": {
        "chatId": "={{ $(\"Telegram Trigger1\").first().json.message.chat.id }}",
        "text": "=üìÑ Here's your UPDATED document!\n\n\nüîó Google Doc: {{ $json.viewLink }}\n\n",
        "additionalFields": {
          "appendAttribution": false
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        3088,
        3488
      ],
      "id": "4f448370-33fa-4844-aea2-fd3d02654108",
      "name": "Send a text message5",
      "webhookId": "e39a16c4-f784-4468-8743-a76ef6b54767",
      "credentials": {
        "telegramApi": {
          "id": "a6Z9XadVmRA5aI2o",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Pass through all data to the agent\nconst data = $input.first().json;\n\nconsole.log('üîÑ Preparing data for agent...');\n\nreturn [{\n  json: {\n    // Section update info\n    sectionNumber: data.sectionNumber,\n    updateInstruction: data.updateInstruction,\n    originalMessage: data.originalMessage,\n    chatId: data.chatId,\n    \n    // Document data (this is what we need to preserve)\n    fullDocument: data.fullDocument,\n    currentSection: data.currentSection,\n    documentMetadata: data.documentMetadata,\n    \n    // GitHub info\n    githubConfig: data.githubConfig,\n    githubFile: data.githubFile,\n    \n    // Pass everything through\n    _originalData: data\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1856,
        2992
      ],
      "id": "b89e4b83-78c9-412d-920b-6ee87d05d952",
      "name": "Prepare_Agent_Input"
    },
    {
      "parameters": {
        "jsCode": "// Merge_Updated_Section_into_Document - BULLETPROOF VERSION\n// This will ONLY replace the exact section requested, nothing else\n\nconst rawInput = $('Regenerate_Section_Agent').first().json;;\n\nlet updatedSection = rawInput;\nif (rawInput.output && typeof rawInput.output === 'object') {\n  updatedSection = rawInput.output;\n}\n\n// Get the ORIGINAL section number from Extract Specific Section\nconst extractedData = $('Extract Specific Section').first().json;\nconst targetSectionNumber = extractedData.mainSectionNumber;\n\nconsole.log('=================================');\nconsole.log('üéØ TARGET SECTION TO REPLACE:', targetSectionNumber);\nconsole.log('üìù AI RETURNED SECTION:', updatedSection.sectionNumber);\nconsole.log('=================================');\n\nif (!targetSectionNumber) {\n  throw new Error('‚ùå No target section number from Extract Specific Section');\n}\n\n// Get all document items\nconst fullDocumentItems = $('Fetch_Document_JSON').all();\n\n// Build fresh document structure\nconst document = {\n  metadata: null,\n  sections: {}\n};\n\n// Extract metadata\nconst metadataItem = fullDocumentItems.find(item => item.json.type === 'metadata');\nif (metadataItem) {\n  document.metadata = {\n    documentTitle: metadataItem.json.documentTitle,\n    documentType: metadataItem.json.documentType,\n    targetAudience: metadataItem.json.targetAudience,\n    chatId: metadataItem.json.chatId,\n    totalSections: metadataItem.json.totalSections,\n    createdAt: metadataItem.json.createdAt,\n    version: metadataItem.json.version || '1.0',\n    userRequest: metadataItem.json.userRequest,\n    lastModified: new Date().toISOString()\n  };\n}\n\n// Separate items by type\nconst sectionItems = fullDocumentItems.filter(item => item.json.type === 'section');\nconst subsectionItems = fullDocumentItems.filter(item => item.json.type === 'subsection');\n\n// Build all main sections first\nfor (const sectionItem of sectionItems) {\n  const secNum = sectionItem.json.sectionNumber;\n  \n  document.sections[secNum] = {\n    title: sectionItem.json.title,\n    content: sectionItem.json.content,\n    subsections: {},\n    url:sectionItem.json.url\n  };\n}\n\n// Now add ALL subsections\nfor (const subItem of subsectionItems) {\n  const mainSecNum = subItem.json.sectionNumber; // Which main section it belongs to (e.g., \"2\")\n  const subSecNum = subItem.json.subsectionNumber; // The subsection number (e.g., \"2.1\")\n  \n  if (!document.sections[mainSecNum]) {\n    console.warn(`‚ö†Ô∏è Orphan subsection ${subSecNum} - main section ${mainSecNum} not found`);\n    continue;\n  }\n  \n  // üî• CRITICAL: Check if this is the section we're updating\n  const isTargetSection = (subSecNum === targetSectionNumber);\n  \n  if (isTargetSection) {\n    console.log(`üîÑ REPLACING subsection ${subSecNum} with updated content`);\n    \n    // Use the UPDATED content from AI\n    document.sections[mainSecNum].subsections[subSecNum] = {\n      title: updatedSection.title,\n      content: updatedSection.content,\n      keyConsiderations: updatedSection.keyConsiderations || null,\n      bestPractices: updatedSection.bestPractices || null,\n      notes: updatedSection.notes || null\n    };\n  } else {\n    console.log(`‚úì Keeping original subsection ${subSecNum}`);\n    \n    // Keep the ORIGINAL content\n    document.sections[mainSecNum].subsections[subSecNum] = {\n      title: subItem.json.title,\n      content: subItem.json.content,\n      keyConsiderations: subItem.json.keyConsiderations || null,\n      bestPractices: subItem.json.bestPractices || null,\n      notes: subItem.json.notes || null\n    };\n  }\n}\n\n// Update version\nconst currentVersion = parseFloat(document.metadata.version || '1.0');\ndocument.metadata.version = (currentVersion + 0.1).toFixed(1);\n\nconsole.log('=================================');\nconsole.log('‚úÖ MERGE COMPLETE');\nconsole.log('üìä Section 2 subsections:', Object.keys(document.sections['2']?.subsections || {}));\nconsole.log('=================================');\n\nreturn [{\n  json: {\n    structuredDocument: document,\n    updatedSectionNumber: targetSectionNumber,\n    changesSummary: updatedSection.changesSummary || 'Section updated',\n    updateType: targetSectionNumber.includes('.') ? 'subsection' : 'main_section'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        432,
        3488
      ],
      "id": "55b9e6e8-92d4-4cbc-a767-660e830953f4",
      "name": "Merge_Updated_Section_into_Document"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        2320,
        2992
      ],
      "id": "b856dddd-c614-449c-84f5-2eb92a247c22",
      "name": "Wait1",
      "webhookId": "ba42291e-eaa2-4ce0-8cfe-2d0fe3bba502"
    },
    {
      "parameters": {
        "jsCode": "// Node: Get_Latest_Repo_Config\n// Place this AFTER Fetch_User_Repos_For_Update\n// This extracts the most recently updated repo dynamically\n\nconst allRepos = $input.all();\nconst sectionInfo = $('Identify_Section_to_Update').first().json;\n\nconsole.log('üì¶ Finding latest repository...');\nconsole.log('Total repos fetched:', allRepos.length);\n\n// Extract repos and filter out forks\nlet repos = [];\nfor (const item of allRepos) {\n  if (item.json && item.json.full_name && !item.json.fork) {\n    repos.push(item.json);\n  }\n}\n\nif (repos.length === 0) {\n  throw new Error('‚ùå No repositories found');\n}\n\n// Sort by updated_at to get the most recent\nrepos.sort((a, b) => {\n  const dateA = new Date(a.updated_at || a.created_at);\n  const dateB = new Date(b.updated_at || b.created_at);\n  return dateB - dateA; // Descending (newest first)\n});\n\nconst latestRepo = repos[0];\nconst [owner, repoName] = latestRepo.full_name.split('/');\n\nconsole.log('‚úÖ Latest repository:', latestRepo.full_name);\nconsole.log('üìÖ Last updated:', latestRepo.updated_at);\n\n// Build dynamic GitHub config\nconst githubConfig = {\n  owner: owner,\n  repo: repoName,\n  branch: latestRepo.default_branch || 'main',\n  basePath: 'Documentation_Sections',\n  repoUrl: latestRepo.html_url,\n  rawBaseUrl: `https://raw.githubusercontent.com/${owner}/${repoName}/${latestRepo.default_branch || 'main'}`,\n  isNewRepo: false\n};\n\nconsole.log('üîß GitHub Config:', JSON.stringify(githubConfig, null, 2));\n\nreturn [{\n  json: {\n    // Pass through section info\n    sectionNumber: sectionInfo.sectionNumber,\n    updateInstruction: sectionInfo.updateInstruction,\n    originalMessage: sectionInfo.originalMessage,\n    chatId: sectionInfo.chatId,\n    \n    // Dynamic GitHub config\n    githubConfig: githubConfig,\n    \n    // Metadata\n    latestRepoName: latestRepo.full_name,\n    latestRepoUpdated: latestRepo.updated_at,\n    totalReposFound: repos.length,\n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        2992
      ],
      "id": "d6db5862-f6e6-4766-be51-dbe5866e5047",
      "name": "Get_Latest_Repo_Config"
    },
    {
      "parameters": {
        "jsCode": "// 1. Get original metadata (from your previous node)\nconst originalData = $('Fetch_Section_from_GitHub').first().json;\n\n// 2. Get all input items (GitHub file list)\nconst inputItems = $input.all();\n\n// 3. Flatten all JSON objects from input items\nconst allData = inputItems.flatMap(item => {\n  if (Array.isArray(item.json)) return item.json;\n  return [item.json];\n});\n\n// 4. Filter only technical documentation JSON files\nconst fileItems = allData.filter(item =>\n  item.type === \"file\" &&\n  item.name.startsWith(\"technical_documentation\") &&\n  item.name.endsWith(\".json\")\n);\n\n// If no file found ‚Üí return clean response\nif (fileItems.length === 0) {\n  return [{\n    json: {\n      ...originalData,\n      latestFile: null,\n      githubFileUrl: null,\n      githubFileSHA: null,\n      githubFilePath: null,\n      techDocFilesFound: 0,\n      totalFilesFound: allData.length,\n      fileName: null\n    }\n  }];\n}\n\n// 5. Sort newest ‚Üí oldest based on date in filename\nfileItems.sort((a, b) => {\n  const dateA = a.name.match(/(\\d{4}-\\d{2}-\\d{2})/)?.[1] || \"\";\n  const dateB = b.name.match(/(\\d{4}-\\d{2}-\\d{2})/)?.[1] || \"\";\n  return dateB.localeCompare(dateA);\n});\n\n// 6. Latest file\nconst latestFile = fileItems[0];\n\n// 7. Extract cleaned file name (remove date + .json)\nconst fileName = latestFile.name.replace(/_\\d{4}-\\d{2}-\\d{2}\\.json$/, \"\");\n\n// 8. Return final response\nreturn [{\n  json: {\n    ...originalData,\n    latestFile: latestFile,\n    githubFileUrl: latestFile.download_url,\n    githubFileSHA: latestFile.sha,\n    githubFilePath: latestFile.path,\n    techDocFilesFound: fileItems.length,\n    totalFilesFound: allData.length,\n    fileName: fileName\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1056,
        2992
      ],
      "id": "43e3a330-24cd-4740-88ee-2d58f9c18397",
      "name": "Find_Technical_Doc_JSON"
    },
    {
      "parameters": {
        "jsCode": "const sectionData = $input.first().json;\nconst fullDocumentItems = $('Fetch_Document_JSON').all();\n\n// Use either sectionNumber or mainSectionNumber\nconst sectionNumber = sectionData.sectionNumber || sectionData.mainSectionNumber;\n\nif (!sectionNumber) {\n  console.error('‚ùå No section number available in sectionData:', sectionData);\n  return [{ json: { ...sectionData, error: 'Missing sectionNumber' } }];\n}\n\nconsole.log('üéØ Extracting MD URL for section:', sectionNumber);\n\nlet sectionMdUrl = null;\nlet sectionSha = null;\n\nconst isSubsection = sectionNumber.includes('.');\n\nif (isSubsection) {\n  const mainSectionNum = sectionNumber.split('.')[0];\n  \n  const mainSection = fullDocumentItems.find(item => \n    item.json.type === 'section' && item.json.sectionNumber === mainSectionNum\n  );\n  \n  if (mainSection && mainSection.json.url) {\n    sectionMdUrl = mainSection.json.url;\n    console.log('‚úÖ Found parent section MD URL:', sectionMdUrl);\n  }\n} else {\n  const section = fullDocumentItems.find(item => \n    item.json.type === 'section' && item.json.sectionNumber === sectionNumber\n  );\n  \n  if (section && section.json.url) {\n    sectionMdUrl = section.json.url;\n    console.log('‚úÖ Found section MD URL:', sectionMdUrl);\n  }\n}\n\nif (!sectionMdUrl) {\n  console.warn('‚ö†Ô∏è No MD URL found for section, will only update JSON');\n}\n\nreturn [{\n  json: {\n    ...sectionData,\n    sectionMdUrl,\n    needsMdUpdate: !!sectionMdUrl,\n    isSubsection,\n    mainSectionNumber: isSubsection ? sectionNumber.split('.')[0] : sectionNumber\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1744,
        3168
      ],
      "id": "bc2e9fda-d54c-42e8-ad13-638b98aa5f66",
      "name": "Extract_Section_MD_URL"
    },
    {
      "parameters": {
        "jsCode": "// Node: Fetch_MD_File_SHA\n// Place AFTER Wait1 (after agent updates section)\n// Fetches the current SHA of the MD file before updating\n\nconst data = $input.first().json;\nconst githubConfig = $('Find_Technical_Doc_JSON').first().json.githubConfig;\nconst sectionMdUrl = $('Extract_Section_MD_URL').first().json.sectionMdUrl;\n\nif (!sectionMdUrl) {\n  console.log('‚ö†Ô∏è No MD file to update, skipping SHA fetch');\n  return [{\n    json: {\n      ...data,\n      mdFileSHA: null,\n      mdFilePath: null,\n      skipMdUpdate: true\n    }\n  }];\n}\n\nconsole.log('üîç Fetching MD file SHA from GitHub API URL...');\nconsole.log('MD File URL:', sectionMdUrl);\n\n// The sectionMdUrl is an API URL like:\n// https://api.github.com/repos/owner/repo/contents/Documentation_Sections/section_1_architecture_overview/section_1_architecture_overview.md\n\n// Extract the file path from the URL\nconst urlParts = sectionMdUrl.split('/contents/');\nconst mdFilePath = urlParts[1] || '';\n\nconsole.log('üìÑ MD File Path:', mdFilePath);\n\nreturn [{\n  json: {\n    ...data,\n    mdFileApiUrl: sectionMdUrl,\n    mdFilePath: mdFilePath,\n    skipMdUpdate: false,\n    githubConfig: githubConfig\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -384,
        3488
      ],
      "id": "485b9b08-c05d-408a-86a0-771adc73fea4",
      "name": "Fetch_MD_File_SHA"
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare_MD_File_Update\n// Place AFTER Get_MD_File_Details HTTP Request\n// Prepares the updated markdown content for the section\n\nconst mdFileDetails = $input.first().json;\nconst updatedSection = $('Fetch_MD_File_SHA').first().json;\nconst extractedSection = $('Extract_Section_MD_URL').first().json;\n\nconsole.log('üìù Preparing MD file update...');\nconsole.log('MD File SHA:', mdFileDetails.sha);\nconsole.log('Section Number:', extractedSection.sectionNumber);\n\n// Get the updated content from the agent\nconst updatedContent = updatedSection.output?.content || updatedSection.content || '';\nconst updatedTitle = updatedSection.output?.title || updatedSection.title || extractedSection.sectionTitle;\n\n// Build markdown content for the section\nlet mdContent = '';\n\nif (extractedSection.isSubsection) {\n  // For subsections, we need to reconstruct the entire section file\n  // This is complex - we'll need to fetch the current MD, parse it, and replace the subsection\n  \n  // Decode the current content\n  const currentContent = Buffer.from(mdFileDetails.content, 'base64').toString('utf-8');\n  \n  console.log('üìÑ Current MD length:', currentContent.length);\n  \n  // Find and replace the subsection content\n  const subsectionNumber = extractedSection.sectionNumber;\n  const subsectionRegex = new RegExp(\n    `###\\\\s*${subsectionNumber}\\\\s+[^\\\\n]*\\\\n([\\\\s\\\\S]*?)(?=###|$)`,\n    'i'\n  );\n  \n  const match = currentContent.match(subsectionRegex);\n  \n  if (match) {\n    // Replace the subsection content\n    const newSubsection = `### ${subsectionNumber} ${updatedTitle}\\n\\n${updatedContent}\\n\\n`;\n    mdContent = currentContent.replace(subsectionRegex, newSubsection);\n    console.log('‚úÖ Replaced subsection in MD');\n  } else {\n    console.warn('‚ö†Ô∏è Could not find subsection in MD, appending...');\n    mdContent = currentContent + `\\n\\n### ${subsectionNumber} ${updatedTitle}\\n\\n${updatedContent}\\n\\n`;\n  }\n  \n} else {\n  // For main sections, replace the entire content\n  mdContent = `# ${updatedTitle}\\n\\n${updatedContent}\\n`;\n  console.log('‚úÖ Created new MD content for main section');\n}\n\n// Encode content to base64 for GitHub API\nconst base64Content = Buffer.from(mdContent).toString('base64');\n\nconsole.log('üì¶ MD Content prepared, length:', mdContent.length);\nconsole.log('üì¶ Base64 length:', base64Content.length);\n\nreturn [{\n  json: {\n    mdFilePath: mdFileDetails.path,\n    mdFileSHA: mdFileDetails.sha,\n    mdFileContent: base64Content,\n    mdFileMessage: `Update section ${extractedSection.sectionNumber}: ${updatedTitle}`,\n    githubConfig: extractedSection.githubConfig || updatedSection.githubConfig,\n    updatedSectionNumber: extractedSection.sectionNumber,\n    // Pass through for JSON update\n    fullUpdatedSection: updatedSection\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        16,
        3488
      ],
      "id": "cf298db6-fcb2-4536-b793-b0f81ce46400",
      "name": "Prepare_MD_File_Update"
    },
    {
      "parameters": {
        "url": "={{ $json.mdFileApiUrl }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -192,
        3488
      ],
      "id": "d7a9daee-c5ff-4c53-a1b4-a4793674e616",
      "name": "Get_MD_File_Details"
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare_JSON_File_Update\n// Place AFTER Update_MD_on_GitHub\n// Prepares the updated JSON content with the changed section\n\nconst mdUpdateResult = $input.first().json;\nconst mergedDocument = $('Merge_Updated_Section_into_Document').first().json;\nconst githubFileInfo = $('Find_Technical_Doc_JSON').first().json;\n\nconsole.log('üìù Preparing JSON file update...');\nconsole.log('JSON File SHA:', githubFileInfo.githubFileSHA);\nconsole.log('JSON File Path:', githubFileInfo.githubFilePath);\n\n// Get the updated structured document\nconst updatedDocument = mergedDocument.structuredDocument;\n\n// Convert to JSON string with proper formatting\nconst jsonContent = JSON.stringify(updatedDocument, null, 2);\n\n// Encode to base64 for GitHub API\nconst base64Content = Buffer.from(jsonContent).toString('base64');\n\nconsole.log('üì¶ JSON Content prepared');\nconsole.log('üìä JSON size:', jsonContent.length, 'bytes');\nconsole.log('üì¶ Base64 size:', base64Content.length, 'bytes');\n\n// Extract filename from path\nconst fileName = githubFileInfo.githubFilePath.split('/').pop();\n\nreturn [{\n  json: {\n    jsonFilePath: githubFileInfo.githubFilePath,\n    jsonFileSHA: githubFileInfo.githubFileSHA,\n    jsonFileContent: base64Content,\n    jsonFileMessage: `Update section ${mergedDocument.updatedSectionNumber} in ${fileName}`,\n    githubConfig: githubFileInfo.githubConfig,\n    updatedSectionNumber: mergedDocument.updatedSectionNumber,\n    updateType: mergedDocument.updateType,\n    changesSummary: mergedDocument.changesSummary,\n    // Pass through for final message\n    mdUpdateSuccess: !!mdUpdateResult.commit,\n    structuredDocument: updatedDocument\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        640,
        3488
      ],
      "id": "ecffc140-4f14-40c3-9c9c-d1e319bb24fb",
      "name": "Prepare_JSON_File_Update"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=https://api.github.com/repos/{{ $json.githubConfig.owner }}/{{ $json.githubConfig.repo }}/contents/{{ $json.mdFilePath }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"message\": {{ JSON.stringify($json.mdFileMessage) }},\n  \"content\": {{ JSON.stringify($json.mdFileContent) }},\n  \"sha\": {{ JSON.stringify($json.mdFileSHA) }},\n  \"branch\": {{ JSON.stringify($json.githubConfig.branch) }}\n}\n",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        224,
        3488
      ],
      "id": "42d3d06c-db49-499c-a010-2e508bd966a4",
      "name": "Update_MD_on_GitHub"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=https://api.github.com/repos/{{ $json.githubConfig.owner }}/{{ $json.githubConfig.repo }}/contents/{{ $json.jsonFilePath }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "=Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"message\": \"{{ $json.jsonFileMessage }}\",\n  \"content\": \"{{ $json.jsonFileContent }}\",\n  \"sha\": \"{{ $json.jsonFileSHA }}\",\n  \"branch\": \"{{ $json.githubConfig.branch }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        912,
        3488
      ],
      "id": "662eacb6-87a1-4140-9d96-275fb3be7572",
      "name": "Update_json_on_GitHub1"
    },
    {
      "parameters": {
        "url": "https://api.github.com/user/repos",
        "authentication": "genericCredentialType",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "per_page",
              "value": "100"
            },
            {
              "name": "sort",
              "value": "updated"
            },
            {
              "name": "affiliation",
              "value": "owner"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        192,
        2992
      ],
      "id": "3cef858c-8615-43b8-b310-a1fe55245b48",
      "name": "Fetch_User_Repos_For_Update1"
    },
    {
      "parameters": {
        "content": "Backup Nodes",
        "height": 1200,
        "width": 1536,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3824,
        80
      ],
      "typeVersion": 1,
      "id": "b9997ba1-b7c3-49f7-a19b-25497d712d45",
      "name": "Sticky Note15"
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare_CHANGELOG_Update (FULLY FIXED)\n// Generates CHANGELOG entry for the section update\n\nconst jsonUpdateResult = $input.first().json;\n\n// Debug: Log what we received\nconsole.log('üì¶ Input data keys:', Object.keys(jsonUpdateResult));\nconsole.log('üì¶ Full input data:', JSON.stringify(jsonUpdateResult, null, 2));\n\n// Get structured document from the correct source\nlet structuredDocument = jsonUpdateResult.structuredDocument;\n\n// Fallback: Try to get from earlier nodes\nif (!structuredDocument) {\n  console.log('‚ö†Ô∏è No structuredDocument in input, fetching from earlier nodes...');\n  \n  try {\n    const mergeNode = $('Merge_Updated_Section_into_Document').first().json;\n    structuredDocument = mergeNode.structuredDocument;\n    console.log('‚úÖ Got structuredDocument from Merge_Updated_Section_into_Document');\n  } catch (e) {\n    console.error('‚ùå Could not get structuredDocument from Merge node:', e.message);\n  }\n}\n\n// Final check for structuredDocument\nif (!structuredDocument || !structuredDocument.metadata) {\n  throw new Error('‚ùå structuredDocument or metadata not found. Check previous nodes.');\n}\n\n// Safely get updatedSectionNumber with fallback\nlet updatedSection = jsonUpdateResult.updatedSectionNumber;\n\n// If not in input, try to get from earlier nodes\nif (!updatedSection) {\n  console.log('‚ö†Ô∏è No updatedSectionNumber in input, trying earlier nodes...');\n  \n  try {\n    const mergeNode = $('Merge_Updated_Section_into_Document').first().json;\n    updatedSection = mergeNode.updatedSectionNumber;\n    console.log('‚úÖ Got updatedSectionNumber from Merge node:', updatedSection);\n  } catch (e) {\n    console.error('‚ùå Could not get updatedSectionNumber from Merge node');\n  }\n  \n  // Try Prepare_JSON_File_Update as second fallback\n  if (!updatedSection) {\n    try {\n      const prepareNode = $('Prepare_JSON_File_Update').first().json;\n      updatedSection = prepareNode.updatedSectionNumber;\n      console.log('‚úÖ Got updatedSectionNumber from Prepare_JSON_File_Update:', updatedSection);\n    } catch (e) {\n      console.error('‚ùå Could not get updatedSectionNumber from Prepare_JSON_File_Update');\n    }\n  }\n}\n\n// Final validation for updatedSection\nif (!updatedSection) {\n  throw new Error('‚ùå updatedSectionNumber not found in any node. Cannot proceed with CHANGELOG update.');\n}\n\nconst changesSummary = jsonUpdateResult.changesSummary || 'Section updated';\nconst updateType = jsonUpdateResult.updateType || 'update';\n\nconsole.log('üìù Preparing CHANGELOG update...');\nconsole.log('Updated section:', updatedSection);\nconsole.log('Document title:', structuredDocument.metadata.documentTitle);\n\n// Get current date\nconst now = new Date();\nconst dateStr = now.toISOString().split('T')[0]; // YYYY-MM-DD\n\n// Get current version from metadata\nconst currentVersion = structuredDocument.metadata.version || '1.0';\nconst versionParts = currentVersion.toString().split('.');\nconst major = versionParts[0] || '1';\nconst minor = versionParts[1] || '0';\nconst newVersion = `${major}.${parseInt(minor) + 1}`;\n\n// Get section title safely\nlet sectionTitle = 'Unknown Section';\nconst mainSectionNum = updatedSection.toString().split('.')[0];\n\nif (structuredDocument.sections && structuredDocument.sections[mainSectionNum]) {\n  sectionTitle = structuredDocument.sections[mainSectionNum].title || 'Unknown Section';\n}\n\n// Build the new changelog entry\nconst changelogEntry = `\n## [${newVersion}] - ${dateStr}\n\n### Changed\n- üîÑ Updated Section ${updatedSection}: ${sectionTitle}\n  - ${changesSummary}\n  - Update type: ${updateType === 'subsection' ? 'Subsection modification' : 'Main section update'}\n\n### Metadata\n- **Modified By**: Automated workflow\n- **Timestamp**: ${now.toISOString()}\n- **Affected Sections**: ${updatedSection}\n- **Document**: ${structuredDocument.metadata.documentTitle}\n\n---\n`;\n\nconsole.log('‚úÖ CHANGELOG entry prepared');\nconsole.log('New version:', newVersion);\nconsole.log('Entry preview:', changelogEntry.substring(0, 200));\n\n// Get githubConfig\nlet githubConfig = jsonUpdateResult.githubConfig;\nif (!githubConfig) {\n  try {\n    const prepareNode = $('Prepare_JSON_File_Update').first().json;\n    githubConfig = prepareNode.githubConfig;\n  } catch (e) {\n    try {\n      const findNode = $('Find_Technical_Doc_JSON').first().json;\n      githubConfig = findNode.githubConfig;\n    } catch (e2) {\n      console.error('‚ö†Ô∏è Could not find githubConfig');\n    }\n  }\n}\n\nreturn [{\n  json: {\n    // Pass through all original data\n    ...jsonUpdateResult,\n    \n    // Add changelog-specific data\n    changelogEntry: changelogEntry,\n    newVersion: newVersion,\n    updateDate: dateStr,\n    changelogPath: 'Documentation_Sections/Version_and_Impact_Analysis/CHANGELOG.md',\n    \n    // Ensure critical data is passed through\n    structuredDocument: structuredDocument,\n    updatedSectionNumber: updatedSection,\n    githubConfig: githubConfig,\n    \n    // Add debug info\n    debugInfo: {\n      hasStructuredDocument: !!structuredDocument,\n      hasMetadata: !!structuredDocument?.metadata,\n      hasSections: !!structuredDocument?.sections,\n      documentTitle: structuredDocument?.metadata?.documentTitle,\n      updatedSection: updatedSection,\n      hasGithubConfig: !!githubConfig\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1120,
        3488
      ],
      "id": "cab7de2c-d044-4c60-be34-736125d3ae27",
      "name": "Prepare_CHANGELOG_Update"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.githubConfig.owner }}/{{ $json.githubConfig.repo }}/contents/{{ $json.changelogPath }}",
        "authentication": "genericCredentialType",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1328,
        3488
      ],
      "id": "a2637ba4-c150-45bd-a01b-2392a4267eaf",
      "name": "Fetch_Current_CHANGELOG"
    },
    {
      "parameters": {
        "jsCode": "// Node: Merge_CHANGELOG_Content\n// Merges new changelog entry with existing content\n\nconst currentChangelogData = $input.first().json;\nconst preparedData = $('Prepare_CHANGELOG_Update').first().json;\n\nconsole.log('üìù Merging CHANGELOG content...');\n\n// Decode current CHANGELOG content\nconst currentContent = Buffer.from(currentChangelogData.content, 'base64').toString('utf-8');\n\nconsole.log('Current CHANGELOG length:', currentContent.length);\n\n// Find the position to insert new entry (after the header, before first version)\nconst lines = currentContent.split('\\n');\nlet insertIndex = -1;\n\n// Find the line with \"---\" after the header\nfor (let i = 0; i < lines.length; i++) {\n  if (lines[i].trim() === '---' && i > 10) {\n    insertIndex = i + 1;\n    break;\n  }\n}\n\nif (insertIndex === -1) {\n  console.warn('‚ö†Ô∏è Could not find insertion point, appending to end');\n  insertIndex = lines.length;\n}\n\n// Insert the new entry\nlines.splice(insertIndex, 0, '', preparedData.changelogEntry);\n\nconst newContent = lines.join('\\n');\n\n// Encode to base64\nconst base64Content = Buffer.from(newContent).toString('base64');\n\nconsole.log('‚úÖ New CHANGELOG length:', newContent.length);\nconsole.log('üì¶ Base64 length:', base64Content.length);\n\nreturn [{\n  json: {\n    changelogPath: preparedData.changelogPath,\n    changelogSHA: currentChangelogData.sha,\n    changelogContent: base64Content,\n    changelogMessage: `Update CHANGELOG: Section ${preparedData.updatedSectionNumber} modified (v${preparedData.newVersion})`,\n    githubConfig: preparedData.githubConfig,\n    newVersion: preparedData.newVersion,\n    // Pass through for Google Doc creation\n    structuredDocument: preparedData.structuredDocument\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1536,
        3488
      ],
      "id": "44461373-ba2e-439b-b25a-c283ff134e4d",
      "name": "Merge_CHANGELOG_Content"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=https://api.github.com/repos/{{ $json.githubConfig.owner }}/{{ $json.githubConfig.repo }}/contents/{{ $json.changelogPath }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            },
            {
              "name": "Authorization",
              "value": "Bearer YOUR_GITHUB_TOKEN_HERE"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"message\": \"{{ $json.changelogMessage }}\",\n  \"content\": \"{{ $json.changelogContent }}\",\n  \"sha\": \"{{ $json.changelogSHA }}\",\n  \"branch\": \"{{ $json.githubConfig.branch }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1744,
        3488
      ],
      "id": "4dc4f4a0-2c96-4701-a7c7-599071a9064d",
      "name": "Update_CHANGELOG_on_GitHub"
    },
    {
      "parameters": {
        "jsCode": "// Node: Pass_Through_CHANGELOG_Update_Data\n// Ensures all data is passed through after CHANGELOG update\n\nconst changelogResponse = $input.first().json;\nconst preparedChangelogData = $('Merge_CHANGELOG_Content').first().json;\n\nconsole.log('üì¶ Passing through CHANGELOG update data...');\nconsole.log('CHANGELOG update successful:', !!changelogResponse.commit);\n\n// Validate critical data\nif (!preparedChangelogData.structuredDocument) {\n  console.error('‚ùå No structuredDocument in Merge_CHANGELOG_Content');\n  throw new Error('structuredDocument missing from CHANGELOG data');\n}\n\nconsole.log('‚úÖ structuredDocument found');\nconsole.log('Document title:', preparedChangelogData.structuredDocument.metadata.documentTitle);\nconsole.log('Total sections:', Object.keys(preparedChangelogData.structuredDocument.sections).length);\n\nreturn [{\n  json: {\n    // CHANGELOG GitHub response\n    changelogCommit: changelogResponse.commit,\n    changelogContent: changelogResponse.content,\n    \n    // Critical data for Google Docs creation\n    structuredDocument: preparedChangelogData.structuredDocument,\n    \n    // Additional metadata\n    newVersion: preparedChangelogData.newVersion,\n    githubConfig: preparedChangelogData.githubConfig,\n    updatedSectionNumber: preparedChangelogData.structuredDocument.metadata.updatedSectionNumber,\n    \n    // Success flags\n    changelogUpdateSuccess: true,\n    jsonUpdateSuccess: true,\n    mdUpdateSuccess: true,\n    \n    timestamp: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1952,
        3488
      ],
      "id": "b0291650-2c2b-48d7-bd6d-cf8d3493ccf4",
      "name": "Pass_Through_CHANGELOG_Update_Data"
    }
  ],
  "pinData": {
    "Fetch_And_Upload_To_Drive": [
      {
        "json": {
          "folderId": "1QjNraY6OHwrf9_Y5V7B-W84caUnLUNdm",
          "imagesFound": false,
          "imageCount": 0,
          "message": "No images to upload",
          "skipDriveUpload": true,
          "driveUploadSkipped": true
        }
      }
    ]
  },
  "connections": {
    "Process Tree Response": {
      "main": [
        [
          {
            "node": "Filter_Documents1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter_Documents1": {
      "main": [
        [
          {
            "node": "Check_First_Run_Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request1": {
      "main": [
        [
          {
            "node": "Loop Over Items1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items1": {
      "main": [
        [
          {
            "node": "Vector_Store_Insert1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Replace Me1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Replace Me1": {
      "main": [
        [
          {
            "node": "HTTP Request1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI1": {
      "ai_embedding": [
        [
          {
            "node": "Vector_Store_Insert1",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader1": {
      "ai_document": [
        [
          {
            "node": "Vector_Store_Insert1",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Vector_Store_Insert1": {
      "main": [
        [
          {
            "node": "Brain Storming Mode Activation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is_First_Run": {
      "main": [
        [
          {
            "node": "Fetch_User_Repos",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Get Stored State",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Github Api GetTree": {
      "main": [
        [
          {
            "node": "Process Tree Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Tree Response1": {
      "main": [
        [
          {
            "node": "Filter_Documents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter_Documents": {
      "main": [
        [
          {
            "node": "Loop Over Items1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Decode Stored State": {
      "main": [
        [
          {
            "node": "Detect Changes",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Detect Changes": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Prepare_Deletions",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Load Chat History",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Stored State": {
      "main": [
        [
          {
            "node": "Decode Stored State",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_Deletions": {
      "main": [
        [
          {
            "node": "Skip Deletion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_Updates": {
      "main": [
        [
          {
            "node": "If1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Skip Deletion": {
      "main": [
        [
          {
            "node": "Prepare_Updates",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Delete From Pinecorn",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items2": {
      "main": [
        [
          {
            "node": "Pinecone Vector Store2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Download Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Files": {
      "main": [
        [
          {
            "node": "Loop Over Items2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store2": {
      "main": [
        [
          {
            "node": "Get Stored State2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI2": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store2",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Pinecone Vector Store2",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Store_Repository_State1": {
      "main": [
        [
          {
            "node": "Commit State1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Decode Stored State2": {
      "main": [
        [
          {
            "node": "Store_Repository_State1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Stored State2": {
      "main": [
        [
          {
            "node": "Decode Stored State2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Delete From Pinecorn": {
      "main": [
        [
          {
            "node": "Verify Deletions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Verify Deletions": {
      "main": [
        [
          {
            "node": "Prepare_Updates",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If1": {
      "main": [
        [
          {
            "node": "Loop Over Items2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Get Stored State2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch1": {
      "main": [
        [
          {
            "node": "Get a file1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Text Message1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Parse_Navigation_Callback",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get a file1": {
      "main": [
        [
          {
            "node": "Transcribes Audio1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Transcribes Audio1": {
      "main": [
        [
          {
            "node": "Github Api GetTree",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Text Message1": {
      "main": [
        [
          {
            "node": "Github Api GetTree",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Telegram Trigger1": {
      "main": [
        [
          {
            "node": "Switch1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check_First_Run_Text": {
      "main": [
        [
          {
            "node": "Is_First_Run",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_User_Repos": {
      "main": [
        [
          {
            "node": "Extract_Array",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Selected_Repo": {
      "main": [
        [
          {
            "node": "Github_Api_GetTree_Dynamic",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Github_Api_GetTree_Dynamic": {
      "main": [
        [
          {
            "node": "Process Tree Response1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Array": {
      "main": [
        [
          {
            "node": "Send a Reply Back",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store4": {
      "ai_tool": [
        [
          {
            "node": "Brainstorming Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI4": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store4",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store6": {
      "ai_tool": [
        [
          {
            "node": "QA Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI6": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store6",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "QA Agent": {
      "main": [
        [
          {
            "node": "Response Saver1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Saver": {
      "main": [
        [
          {
            "node": "Brain Storming Mode Activation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Saver1": {
      "main": [
        [
          {
            "node": "QA Agent Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "QA Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Brainstorming Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Brain Storming Mode Activation2": {
      "main": [
        [
          {
            "node": "Brainstorming Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Q/A Mode Activation1": {
      "main": [
        [
          {
            "node": "QA Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [
          {
            "node": "Brain Storming Mode Activation2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Q/A Mode Activation1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "TOC_Generator_Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Create a Repo Name",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Updating Existing Document",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "GitHub_Update_Mode_Activation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Store_Update_Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent1": {
      "main": [
        [
          {
            "node": "Save Chat Message1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Chat Message1": {
      "main": [
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store5": {
      "ai_tool": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI5": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store5",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Load Chat History": {
      "main": [
        [
          {
            "node": "AI Agent1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Repository Details": {
      "main": [
        [
          {
            "node": "Create GitHub Repository",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create GitHub Repository": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Store_New_Repo_Info",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store_New_Repo_Info": {
      "main": [
        [
          {
            "node": "Send a text message2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send a text message2": {
      "main": [
        [
          {
            "node": "Prepare_For_TOC_Generation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create a Repo Name": {
      "main": [
        [
          {
            "node": "Extract Repository Details",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Brainstorming Agent": {
      "main": [
        [
          {
            "node": "Response Saver",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Show_User_Repos": {
      "main": [
        [
          {
            "node": "Format_Repo_List_For_Telegram",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_Repo_List_For_Telegram": {
      "main": [
        [
          {
            "node": "Send_Repo_Selection_Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Selected_Repo_For_Edit": {
      "main": [
        [
          {
            "node": "List_Folders_In_Repo",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_User_Repos_For_Update": {
      "main": [
        [
          {
            "node": "Format_Repo_List_For_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_Repo_List_For_Update": {
      "main": [
        [
          {
            "node": "Send_Repo_Selection_Message_1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Selected_Repo_For_Update": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Repo Structure": {
      "main": [
        [
          {
            "node": "Format Directory Structure",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Directory Structure": {
      "main": [
        [
          {
            "node": "Send a Reply Back1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Repo_Contents": {
      "main": [
        [
          {
            "node": "Format_File_Folder_List",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_File_Folder_List": {
      "main": [
        [
          {
            "node": "Send_File_Selection_Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Handle_File_Selection": {
      "main": [
        [
          {
            "node": "Fetch_File_Contents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_File_Contents": {
      "main": [
        [
          {
            "node": "Decode_File_And_Prepare_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Decode_File_And_Prepare_Update": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "Commit_Updated_File_To_GitHub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Commit_Updated_File_To_GitHub": {
      "main": [
        [
          {
            "node": "Send_Update_Confirmation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Selected_Repo_For_Update1": {
      "main": [
        [
          {
            "node": "Fetch_Repo_Contents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Folder_Contents": {
      "main": [
        [
          {
            "node": "Format_Subfolder_Contents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_Subfolder_Contents": {
      "main": [
        [
          {
            "node": "Send_Folder_Contents_Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse_Navigation_Callback": {
      "main": [
        [
          {
            "node": "Route_Navigation_Action",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route_Navigation_Action": {
      "main": [
        [
          {
            "node": "Decode_Legacy_Navigation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare_Folder_Fetch",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Extract_Selected_Repo_For_Update2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Handle_File_Selection1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Extract_Selected_Repo",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Repo_Contents1": {
      "main": [
        [
          {
            "node": "Format_File_Folder_List1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_File_Folder_List1": {
      "main": [
        [
          {
            "node": "Send_File_Selection_Message1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_File_Contents1": {
      "main": [
        [
          {
            "node": "Decode_File_And_Prepare_Update1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Decode_File_And_Prepare_Update1": {
      "main": [
        [
          {
            "node": "AI Agent2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent2": {
      "main": [
        [
          {
            "node": "Prepare_GitHub_Commit",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Commit_Updated_File_To_GitHub1": {
      "main": [
        [
          {
            "node": "Send_Update_Confirmation1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Selected_Repo_For_Update2": {
      "main": [
        [
          {
            "node": "Fetch_Repo_Contents1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Decode_Legacy_Navigation": {
      "main": [
        [
          {
            "node": "Switch2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch2": {
      "main": [
        [
          {
            "node": "Fetch_Folder_Contents",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Fetch_File_Contents1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_Folder_Fetch": {
      "main": [
        [
          {
            "node": "Fetch_Folder_Contents1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Folder_Contents1": {
      "main": [
        [
          {
            "node": "Format_Subfolder_Contents1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_Subfolder_Contents1": {
      "main": [
        [
          {
            "node": "Send_Folder_Contents_Message1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_GitHub_Commit": {
      "main": [
        [
          {
            "node": "Commit_Updated_File_To_GitHub1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store_Update_Prompt": {
      "main": [
        [
          {
            "node": "Fetch_User_Repos_For_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Handle_File_Selection1": {
      "main": [
        [
          {
            "node": "Fetch_File_Contents1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store7": {
      "ai_tool": [
        [
          {
            "node": "TOC_Generator_Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI7": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store7",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "TOC_Generator_Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Parse_TOC_JSON": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [
          {
            "node": "Collect_Section_Results",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Replace Me",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Section_Detail_Generator_Agent": {
      "main": [
        [
          {
            "node": "Extract_And_Process_SVGs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Section_Detail_Generator_Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI8": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store8",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "TOC_Generator_Agent": {
      "main": [
        [
          {
            "node": "Parse_TOC_JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Replace Me": {
      "main": [
        [
          {
            "node": "Section_Detail_Generator_Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store8": {
      "ai_tool": [
        [
          {
            "node": "Section_Detail_Generator_Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Section_Detail_Generator_Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Parse_Sections_to_Structured_JSON": {
      "main": [
        [
          {
            "node": "Generate_Metadata_Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Google Doc": {
      "main": [
        [
          {
            "node": "Prepare Google Docs Requests",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Google Docs Requests": {
      "main": [
        [
          {
            "node": "Format Google Doc",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Google Doc": {
      "main": [
        [
          {
            "node": "Generate Document Link",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Document Link": {
      "main": [
        [
          {
            "node": "Create_Drive_Folder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GitHub Upload": {
      "main": [
        [
          {
            "node": "Create Google Doc",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Collect_Section_Results": {
      "main": [
        [
          {
            "node": "Parse_Sections_to_Structured_JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_GitHub_Payload_With_SHA": {
      "main": [
        [
          {
            "node": "GitHub Upload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Getting Sha2": {
      "main": [
        [
          {
            "node": "Prepare_GitHub_Payload_With_SHA",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_And_Process_SVGs": {
      "main": [
        [
          {
            "node": "Check_If_Has_SVGs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check_If_Has_SVGs": {
      "main": [
        [
          {
            "node": "Extract_Media_Assets1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Create_Images_Directory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Media_Assets1": {
      "main": [
        [
          {
            "node": "Check_File_SHA1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Direct_Upload_Content1": {
      "main": [
        [
          {
            "node": "Format_Upload_Body1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check_File_SHA1": {
      "main": [
        [
          {
            "node": "Direct_Upload_Content1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GitHub Upload3": {
      "main": [
        [
          {
            "node": "Prepare_Section_For_Vectorization1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extarct items1": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store1": {
      "main": [
        [
          {
            "node": "Extarct items1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI3": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store1",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_Section_For_Vectorization1": {
      "main": [
        [
          {
            "node": "Pinecone Vector Store1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Section_Document_Loader1": {
      "ai_document": [
        [
          {
            "node": "Pinecone Vector Store1",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Create_Drive_Folder": {
      "main": [
        [
          {
            "node": "Create_Drive_Folder_API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create_Drive_Folder_API": {
      "main": [
        [
          {
            "node": "Copy_Doc_to_Drive_Folder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Copy_Doc_to_Drive_Folder": {
      "main": [
        [
          {
            "node": "Upload_PNGs_to_Drive",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upload_PNGs_to_Drive": {
      "main": [
        [
          {
            "node": "Fetch_And_Upload_To_Drive",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create_Images_Directory": {
      "main": [
        [
          {
            "node": "HTTP Request2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GitHub Upload4": {
      "main": [
        [
          {
            "node": "Merge_Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save_PNG": {
      "main": [
        [
          {
            "node": "Upload_Image",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upload_Image": {
      "main": [
        [
          {
            "node": "Check_File_SHA",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge_Images": {
      "main": [
        [
          {
            "node": "Update_Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update_Content": {
      "main": [
        [
          {
            "node": "Extract_Media_Assets1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check_File_SHA": {
      "main": [
        [
          {
            "node": "Format_Upload_Body",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_And_Upload_To_Drive": {
      "main": [
        [
          {
            "node": "Send a text message4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_Upload_Body": {
      "main": [
        [
          {
            "node": "GitHub Upload4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format_Upload_Body1": {
      "main": [
        [
          {
            "node": "GitHub Upload3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate_Metadata_Files": {
      "main": [
        [
          {
            "node": "Upload_Metadata_Files_Loop",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Replace Me2": {
      "main": [
        [
          {
            "node": "Check_Metadata_File_SHA",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check_Metadata_File_SHA": {
      "main": [
        [
          {
            "node": "Upload_Metadata_To_GitHub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upload_Metadata_Files_Loop": {
      "main": [
        [
          {
            "node": "Merge_Metadata_Results",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Replace Me2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upload_Metadata_To_GitHub": {
      "main": [
        [
          {
            "node": "Upload_Metadata_Files_Loop",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge_Metadata_Results": {
      "main": [
        [
          {
            "node": "Getting Sha2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request2": {
      "main": [
        [
          {
            "node": "Save_PNG",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Extract_Media_Assets1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_For_TOC_Generation": {
      "main": [
        [
          {
            "node": "TOC_Generator_Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Identify_Section_to_Update": {
      "main": [
        [
          {
            "node": "Fetch_Current_Document_State",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Current_Document_State": {
      "main": [
        [
          {
            "node": "Fetch_User_Repos_For_Update1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Section_from_GitHub": {
      "main": [
        [
          {
            "node": "List GitHub Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "List GitHub Files": {
      "main": [
        [
          {
            "node": "Find_Technical_Doc_JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Document_JSON": {
      "main": [
        [
          {
            "node": "Extract Specific Section",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Regenerate_Section_Agent": {
      "main": [
        [
          {
            "node": "Wait1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Regenerate_Section_Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Updating Existing Document": {
      "main": [
        [
          {
            "node": "Identify_Section_to_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_JSON_Directly": {
      "main": [
        [
          {
            "node": "Fetch_Document_JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Specific Section": {
      "main": [
        [
          {
            "node": "Extract_Section_MD_URL",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser1": {
      "ai_outputParser": [
        [
          {
            "node": "Regenerate_Section_Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Create Google Doc1": {
      "main": [
        [
          {
            "node": "Format Google Doc1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Google Docs Requests1": {
      "main": [
        [
          {
            "node": "Create Google Doc1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Google Doc1": {
      "main": [
        [
          {
            "node": "Generate Document Link1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Document Link1": {
      "main": [
        [
          {
            "node": "Send a text message5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_Agent_Input": {
      "main": [
        [
          {
            "node": "Regenerate_Section_Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge_Updated_Section_into_Document": {
      "main": [
        [
          {
            "node": "Prepare_JSON_File_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait1": {
      "main": [
        [
          {
            "node": "Fetch_MD_File_SHA",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get_Latest_Repo_Config": {
      "main": [
        [
          {
            "node": "Fetch_Section_from_GitHub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Find_Technical_Doc_JSON": {
      "main": [
        [
          {
            "node": "Fetch_JSON_Directly",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract_Section_MD_URL": {
      "main": [
        [
          {
            "node": "Prepare_Agent_Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_MD_File_SHA": {
      "main": [
        [
          {
            "node": "Get_MD_File_Details",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_MD_File_Update": {
      "main": [
        [
          {
            "node": "Update_MD_on_GitHub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get_MD_File_Details": {
      "main": [
        [
          {
            "node": "Prepare_MD_File_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_JSON_File_Update": {
      "main": [
        [
          {
            "node": "Update_json_on_GitHub1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update_MD_on_GitHub": {
      "main": [
        [
          {
            "node": "Merge_Updated_Section_into_Document",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update_json_on_GitHub1": {
      "main": [
        [
          {
            "node": "Prepare_CHANGELOG_Update",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_User_Repos_For_Update1": {
      "main": [
        [
          {
            "node": "Get_Latest_Repo_Config",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare_CHANGELOG_Update": {
      "main": [
        [
          {
            "node": "Fetch_Current_CHANGELOG",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch_Current_CHANGELOG": {
      "main": [
        [
          {
            "node": "Merge_CHANGELOG_Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge_CHANGELOG_Content": {
      "main": [
        [
          {
            "node": "Update_CHANGELOG_on_GitHub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update_CHANGELOG_on_GitHub": {
      "main": [
        [
          {
            "node": "Pass_Through_CHANGELOG_Update_Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pass_Through_CHANGELOG_Update_Data": {
      "main": [
        [
          {
            "node": "Prepare Google Docs Requests1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "e7114dbc-70d5-48f4-b3c7-143b2a2e77b7",
  "meta": {
    "instanceId": "f7532c2ff2234e46fba7e01be81afb2d8b821580db0c43aceafdd617b351baf1"
  },
  "id": "pdQ9EIg9OL8hexvv",
  "tags": []
}
